{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "linear_regression_what_makes_us_happy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/master/machine_learning/lesson%201%20-%20linear%20regression/examples/linear-regression-deep-dive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgtcQi5cPcFU",
        "colab_type": "text"
      },
      "source": [
        "# Regression\n",
        "<figure>\n",
        "<img src='https://media.makeameme.org/created/brace-yourself-regression-599599.jpg' width='50%' height='50%'></img>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Perhaps the most natural machine learning task to wrap our heads around is *regression*--a set of methods for modeling the relationship between one or more independent variables (i.e., $x$) and a dependent variable (i.e., $y$). Regression problems pop up whenever we want to output a *numeric* value. \n",
        "\n",
        "Most applications of regression fall into one of the following two broad categories:\n",
        "- *inference* - to explain the relationship between the inputs and outputs (most common).\n",
        "- *prediction* - to predict numeric outputs given inputs (most common in machine learning). \n",
        "\n",
        "A few everyday examples of regression include predicting prices (of homes, stocks, etc.), predicting length of stay (for patients in the hospital), and demand forecasting (for retail sales). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoeVWX-5j7Gt",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression\n",
        "<figure>\n",
        "<img src='https://learningstatisticswithr.com/book/lsr_files/figure-html/regression1a-1.png' width='60%'></img>\n",
        "</figure>\n",
        "\n",
        "\n",
        "*Linear regression* is probably the simplest and most popular regression method. It is called \"linear\" regression because we **assume** that the relationship between the independent variables $x$ and the dependent variable  $y$ is linear--that is, $y$ can be expressed as a *weighted sum* of the elements in $x$, plus some *noise* in the data. In mathematical terms this can be expressed as: $$y = wx + b$$\n",
        "where $w$ represents the learnable *weights* and $b$ the *bias* (i.e., you may recognize it as the *intercept*). The weights determine the influence of each feature on the prediction and the bias tells us what the predicted value would be if all the features $x$ values were 0. Given features of a training dataset  $X$  and corresponding (known) labels  $y$ , the goal of linear regression is to find the weight vector $w$  and the bias term  $b$  that given features of a new data sample from the dataset  $X$, the sample's label will (in expectation) be predicted with the lowest *error*.\n",
        "\n",
        "To motivate the linear regression approach, suppose that we wish to estimate the prices of houses (in dollars) based on their area (in square feet). To actually fit a model for *predicting* house prices, we need to get our hands on a dataset consisting of sales for which we know the sale price and area for each home. In machine learning terminology, the dataset is called a *training dataset* or *training set*, and each row (the data corresponding to one sale) is called a *sample*. The thing we are trying to predict (price) is called a *label* (or *target*). The independent variables (only one in this case--area), upon which the predictions are based, are called *features*. \n",
        "\n",
        "Generally, we will use  $n$  to denote the total number of samples in our dataset. We index a sample by $i$, denoting each sample as  $x^{(i)}=[x^{(i)}_{1}]^{⊤}$  ($x^{(i)}_{1}$ represents the area) and the corresponding label as $y^{(i)}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lV-loKm6kLV",
        "colab_type": "text"
      },
      "source": [
        "## Linear Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM4R7LoM6kJo",
        "colab_type": "text"
      },
      "source": [
        "To make the above linear regression formula more concrete, let's translate it to our house prices example: \n",
        "$$\\text{price} = w_{\\text{area}}\\cdot{area} + b $$\n",
        "where $w_{\\text{area}}$ is the learnable *weight* and $b$ is the *bias* (or *intercept*).\n",
        "\n",
        "The goal is to choose the weight  $w$  and the bias  $b$  such that on average, the predictions made according to our model *best fit* the true prices observed in the data. \n",
        "\n",
        "Before we can go about searching for the best *parameters*  $w$  and  $b$, we will need two more things: (i) a way to measure the quality of the model; and (ii) a procedure for updating the model parameters to improve its accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTuHWKk3loN6",
        "colab_type": "text"
      },
      "source": [
        "# Loss Function\n",
        "<figure>\n",
        "<img src='https://d2l.ai/_images/fit_linreg.svg\n",
        "' width='60%'></img><figcaption>Calculating loss: measuring the distance between the predicion and real value</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Before we build our model, we need to determine a measure of fitness. The *loss function* quantifies the distance between the *true* and *predicted* value of the *target*. The loss will usually be a non-negative number where smaller values are better and perfect predictions incur a loss of  0 . The most popular loss function in regression problems is the *sum of squared errors* (SSE). When our prediction for an example  $i$  is  $\\hat{y}^{(i)}$  and the corresponding true label is  $y^{(i)}$ , the squared error is given by:\n",
        "$$\n",
        "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.\n",
        "$$\n",
        "\n",
        "The constant  1/2  makes no real difference but makes some future math more convenient, cancelling out when we take the *derivative* of the loss (don't worry if you don't know about derivatives yet). To make things more concrete, consider the example above where we plot a regression problem, the blue line corresponds to the prediction vs true value. \n",
        "\n",
        "To measure the quality of a model on the entire dataset, we simply *average* (or equivalently, sum) the losses on the training set.\n",
        "\n",
        "$$\n",
        "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
        "$$\n",
        "\n",
        "When training the model, we want to find parameters ( $w^{∗}$,$b^{∗}$ ) that minimize the total loss across all training examples:\n",
        "\n",
        "$$\n",
        "\\mathbf{w}^*, b^* = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  L(\\mathbf{w}, b).\n",
        "$$\n",
        "\n",
        "But how do actualy find the best parameters to minimize the total loss? We'll use *gradient descent*--a fundemental concept in modern machine learning, particularly *deep learning*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHW5a943sDqk",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent\n",
        "\n",
        "<figure>\n",
        "<img src='https://media0.giphy.com/media/O9rcZVmRcEGqI/source.gif' width='100%'></img><figcaption>Gradient descent: finding the best model parameters</figcaption>\n",
        "</figure>\n",
        "\n",
        "The key technique for optimizing nearly any deep learning model, and we can use for linear models too, consists of *iteratively* reducing the error by updating the parameters in the *direction* that incrementally *lowers* the loss function. This algorithm is called *gradient descent*. In general, we can find acceptable parameter values after many interations of reducing the loss.\n",
        "\n",
        "The most naive application of gradient descent consists of taking the derivative of the true loss, which is an average of the losses computed on every single example in the dataset. In practice, this can be extremely slow. We must pass over the entire dataset before making a single update. Thus, we will often settle for sampling a random *batch* of samples every time we need to compute the update, this method is called *stochastic gradient descent*.\n",
        "\n",
        "\n",
        "At a high level, the *stochastic gradient descent* method consists of feeding a random batch of samples to the model, computing the derivative (gradient) of the average loss with respect to the batch samples and the model's current parameter values. Finally, we update the model parameters by multiplying the gradient by a predetermined value called the *learning rate* $ > 0$ and substract the resulting output from the current parameter values.  \n",
        "\n",
        "Let's summarize the steps of *stochastic gradient descent*: \n",
        "1. We initialize the values of the model parameters, typically with random values.\n",
        "2. We iteratively sample random batches from the data (many times), updating the parameters in the direction of the negative gradient.\n",
        "3. After many iterations, we hope that the estimated model parameters ($\\hat{w}, \\hat{b}$, the \"hat\" symbol denotes estimates) can produce acceptable predictions (close enough to the true values).\n",
        "\n",
        "Linear regression can actually be solved using a simpler method than stochastic gradient descent, but the stochastic gradient descent algorithm is so fundemental to deep learning that we will use it for linear regression too. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFv_ek5F8b1D",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression: What makes us happy?\n",
        "Now let's apply the linear regression method to a real-world problem--predicting happiness given features corresponding to a country's population. To fit a model, the process involves several steps: \n",
        "\n",
        "1. Find a dataset related to our question. \n",
        "2. Explore the dataset - clean the data and visualize it (if possible).\n",
        "3. Prepare data for a *model*.\n",
        "4. Build a model. \n",
        "5. Train the model using an algorithm such as stochastic gradient descent.\n",
        "6. Evaluate the quality of our model.\n",
        "7. Draw conclusions. \n",
        "\n",
        "For step 1, we found the World Happiness (https://www.kaggle.com/unsdsn/world-happiness) dataset. The dataset contains information about the state of global happiness with happiness scores and rankings for nearly every country on earth. Pretty cool right! Next, we explore the dataset and define our $x$ and $y$ variables. Then, we build a linear regression model. Following, we train the model using stochastic gradient descent. Finally we evaluate the model and draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QeOZ9rN8b1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the libraries we be need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA78zSFaOlje",
        "colab_type": "text"
      },
      "source": [
        "## 1. Explore + Visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmr-AHsN8b1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "9d43b2b2-1345-4483-c52f-91767968abb3"
      },
      "source": [
        "# load the dataset into a dataframe\n",
        "data_url = 'https://raw.githubusercontent.com/BreakoutMentors/Data-Science-and-Machine-Learning/master/datasets/world-happiness/2019.csv'\n",
        "happy2019 = pd.read_csv(data_url)\n",
        "happy2019.head() # view the first 5 rows of the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall rank</th>\n",
              "      <th>Country or region</th>\n",
              "      <th>Score</th>\n",
              "      <th>GDP per capita</th>\n",
              "      <th>Social support</th>\n",
              "      <th>Healthy life expectancy</th>\n",
              "      <th>Freedom to make life choices</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Perceptions of corruption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Finland</td>\n",
              "      <td>7.769</td>\n",
              "      <td>1.340</td>\n",
              "      <td>1.587</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>7.600</td>\n",
              "      <td>1.383</td>\n",
              "      <td>1.573</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.252</td>\n",
              "      <td>0.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Norway</td>\n",
              "      <td>7.554</td>\n",
              "      <td>1.488</td>\n",
              "      <td>1.582</td>\n",
              "      <td>1.028</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.271</td>\n",
              "      <td>0.341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Iceland</td>\n",
              "      <td>7.494</td>\n",
              "      <td>1.380</td>\n",
              "      <td>1.624</td>\n",
              "      <td>1.026</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>7.488</td>\n",
              "      <td>1.396</td>\n",
              "      <td>1.522</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.557</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Overall rank Country or region  ...  Generosity  Perceptions of corruption\n",
              "0             1           Finland  ...       0.153                      0.393\n",
              "1             2           Denmark  ...       0.252                      0.410\n",
              "2             3            Norway  ...       0.271                      0.341\n",
              "3             4           Iceland  ...       0.354                      0.118\n",
              "4             5       Netherlands  ...       0.322                      0.298\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2arfDeOvX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a70c443-e137-4f32-a85d-20b2605e23f5"
      },
      "source": [
        "# how many rows and columns are in the dataset\n",
        "happy2019.shape # looks like 156 rows and 9 columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQXvyqba3kwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9774d6dd-141b-4d4b-987e-f7e6dad16c3e"
      },
      "source": [
        "# visualize a scatter plot of GDP per capita and happiness score \n",
        "happy2019.plot.scatter(x='GDP per capita',\n",
        "                      y='Score');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7QcVZ0v8O+v+zwSkpjEJKIkHCET0JswJMhRlEBuSNRBiDAOKA7iY0aN44C4dIaHl4ui3LkjoteZMXE0i+UsvQqCYRAEdeCSZGJ4RAImIYk8jhESgmPIkQAnQp+c7t/9o6pP6nSqu6uqa1ftqvp+1srinO7qrt1Fn/3b+7cfJaoKIiIqnlLaBSAionQwABARFRQDABFRQTEAEBEVFAMAEVFBMQAQERWU0QAgIp8Rke0isk1EbhKRcSbPR0REwRkLACIyE8ClAPpV9QQAZQDvN3U+IiIKx3QKqAvAeBHpAnAEgGcNn4+IiALqMvXGqrpHRL4KYBeAlwHcrap3t3rN9OnT9ZhjjjFVJCKi3Hn44Yf3qeqMKK81FgBEZCqAcwEcC2A/gB+JyEWq+v2G45YDWA4AfX192LRpk6kiERHljog8HfW1JlNAbwfwW1V9TlUPAvh3AKc2HqSqq1S1X1X7Z8yIFMSIiCgCkwFgF4C3isgRIiIAlgL4tcHzERFRCMYCgKpuBLAawCMAHnXPtcrU+YiIKBxjYwAAoKpfAPAFk+cgIqJouBKYiKigGACIyAqDQxVs2b0fg0OVtItSGEZTQEREQdy+eQ+uuHUrukslHKzV8JXzTsQ5C2amXazcYw+AiFI1OFTBFbduxSsHa3ipMoJXDtZw+a1b2RNIAAMAEaXqmedfRndpbFXUXSrhmedfTqlExcEAQESpmjV1PA7WamMeO1irYdbU8SmVqDgYAIgoVdMm9uIr552Icd0lTOrtwrjuEr5y3omYNrE37aLlHgeBiSh15yyYiYVzpuOZ51/GrKnjWfknhAGAiKwwbWJvy4p/cKjCABEzBgAish6niZrBMQAispqJaaJcdOZgD4CIrFafJvoKDs0Uqk8TjZIKYm/iEPYAiMhqs6aOx3C1OuaxqNNEuehsLAYAIrLahoF9qOmh38sCXLx4TtvX+aV5uOhsLKaAiMha9Rb7weqhCFBV4Nvrf4OV6waapm+apXm46Gws9gCIyFp+LXYAGKpUm6ZvWqV5uOhsLPYAiMhafi12L7/B4HaDxlx0dgh7AERkLW+LfUJP+bDn/dI3QdI80yb2Yv7RUwpd+QPsARCR5eot9u3PvogHdu7Ddzb8Fj3l8mhuv7ESrweNyxvGAIpe2fthACAi620Y2Dc6qAsIli+ajQtP6WtaqTPNEwxTQESUmCgrcBsHdSsjNaxcN9D2dUzztMceABElIsoK3MGhCtY+thdlkTGPd7ISmA5hACAi47yt+PrsnMtv3YqFc6Y3rcTrAaMswIFhzt03gSkgIjIu7Apcb8DwVv49ZSn83P04sQdARMaFXYH7zPMvH5b2AYCRmuLuS0/HnCMnGSln0bAHQJQhWd3GOOwK3FlTx2N4pHrY4zUFnn3hFdPFLQz2AIgyIuvbGIeZmjltYi8+dvps/Ot/7vR5Vn0eoyjYAyDKgCxuY+zXWwkzNfNjp89Gd7lh9k9ZMO+oybGXtagYAIgyIGvbGN++eQ8WXrcGF92wEQuvW4M7Nu8J/R7TJvbia++dj96uEo7oKaO3q4SvvXc+B39jxBQQUQZkaRvjKFM+m8nait6s3bieAYAoA7K0v02UWzi2qjinTey18nM2yuIYjbEAICJvAHCz56HZAD6vqv9k6pxEeZaV1nDY3kqaFWdcLfY4ez1JMhYAVPVxAAsAQETKAPYAuM3U+YiKIAut4TC9lTQrzjgDT9w3rk9KUimgpQB+o6pPJ3Q+IkpR0N5KkIrTRF497sCTpTEar6QCwPsB3JTQuYjIAkF6K+0qTlPpobhb7Fkao/EyHgBEpAfAOQA+1+T55QCWA0BfX5/p4hCRRZpVnACw/om9uHz1FlRGNPb0kIkWe1bGaLyS6AG8C8Ajqvp7vydVdRWAVQDQ39/PJX5EBdNYcW4Y2IeF161BSQSVkbFVQlx5dVMt9iyM0XglEQD+Ekz/EFEL9YrTm5v3066VHma8IIst9rgZDQAiMgHAOwB8wuR5iMguUQdu/XLzAHBEdxk1aMtWepTxgqy12ONmNACo6gEA00yeg4js0snArV9uvrerhG998GTMO+pVLReSRZnVk7WVu3HjXkBEFJtON63z2zb6+vNPxKLjZ7SsoKPslRTHfkVZx60giCg2cUyvjJKbDzurJ6srd+PGHgARxSau6ZVhto2uHx/mhjNZ213VFPYAiCg27aZXmsy5h+k5ZHXlbtwYAIgoVs0q4iQ2fQs6qyerK3fjxgBARLFrrIhtzLlzHQADABElwNbdMou+DoCDwERkHHPudmIAIMoBvxuw2yTsLB1KBlNARBmXlVsR+uXci74SN20MAEQZZuPgaivenHtWAleeMQVElGFZXdDU6ZYRFA8GAKIMy+rgalYDV94wABBlWFYHV7MauPKGYwBEGZfFBU1BV+JykNgsBgAqvDxUMp0uaErjGrQLXBwkNo8BgAqNlUy616BZ4Mra7Kas4hgAFRZnoth7DdoNEtu+8C2MND8LewBUWLbuT5OkJK5BlPRSq0HiPPXa0v4s7AFQYXEmCjChp4zKSHXMY3Feg6i3XWw2uwmAlT2WKGzofbEHQIVl857wSQzK1lufpZIAVUVvWSAlie0adJrH9xsk3rJ7f256bTb0QBkAqNBsnEJpMi1QDywTesqjlXOdiuCuS07DnCMnxXKuOCq4xkHiPPXabPgsTAFRodk2BdRkWsCbjjnrGxugNR3zfG+5hAPD1SavDs9EBWfDwre4Bm1t+CzsAVBhpT0A58dUWsAvHdMo7tZnY4ptuFrFxYvndPy+afba4v7OpN0DZQ+ACsmGATg/ptICftMqx3WX0FOWWFqfzVrF5yyYifuuWIKPL5oNQLBq/c7Ag8GtWtrTJvZi/tFTEm/5m/jOpPFZ6tgDoNxqld6xYQDOj6mBab/AAgA/vfR0HBiuBmp9Nl7P+u/b9ryAa+/a0bJV/M11A6iM1FAZCTYYXKTeWZoYACiX2lUgNgzANWMiLdAssAQd8G28nu/rn4VbNj2DrpJgqOKMGzSb6RO24rR1FbDN35moGAAod4JUIDZOAW1sYcddlqiBxe96fu+BXU2Pb6zcw1actra0bfzOdIoBgDIpjvROHC3tuGYRJZXyiBJY/K5nK6+MjGBCT3nMOcNUnDa3tNMetI0bAwBlTpzpnU5a2nFV2iZSHnFOb202ftCMoIRlKzaMuR5hKk7bW9omemdpYQCgTLElvRNnpR13yiNqYGoWNPyu5/v6Z+Hmh3ajMqKHvc9wtQZU/f+/BP08eWtp24oBgDIlyfROJ+UI0wKPM+URNTC1Cxp+1/PTS4/HjRt3YcXaAZRF8MeDYxeRlUU6ytvnqaVtK6PrAERkioisFpHHROTXIvI2k+ej/Aub3jE1v7rdbpVhNkCLuiLUb558lHvtBp3f3ng9p03sxaeWHof7r1yCb33wZPR2jT3vgeEqtj37QsvPkLY8bSsdhekewD8D+Lmqni8iPQCOMHw+yjlb8sPNygEgUgs8bI+lWYs9Sm+i0xTUtIm9WHT8DHx+2Vxc9eNtY5679s4dOHPea61sydu41iBpxgKAiEwGsAjARwBAVYcBDJs6HxWHLfnhuHerDJryaJfmCRsg40pBnTBzMib2lkfXBQB2TN/0Y+tag6SZ7AEcC+A5AP8mIvMBPAzg06p6wHuQiCwHsBwA+vr6DBaH8sSW/HAau1W2a7GHDZCtejNbdu8PHGRnTR2PkYYN5myZvtnI1rUGSTM5BtAF4E0A/lVVTwJwAMCVjQep6ipV7VfV/hkzZhgsDpF5SezwGCTIhB3/qO/Z8/2PnYL7rlgCBULfyMWG3S2DsnmtQZJE9fBpXLG8schrATyoqse4v58O4EpVPbvZa/r7+3XTpk1GykMUVidz6U1vM33H5j2Htdjb5a+DlmlwqIKF160Zc6+Acd0l3HfFksNe5/eerc4T9niTolxDG4nIw6raH+W1xlJAqvpfIrJbRN6gqo8DWApgh6nzUX7YsEd/pwOEplNUcQ0a+wmaHmn2ns0+u9/xCqQ2EGvLWFKajPUAAEBEFgC4AUAPgJ0A/kpVn292PHsAZMPMjDAt4CwI+3mCHB/He/Z2CQAZ3SG03XuQv056AEbXAajqZje/f6Kq/nmryp/Ilj36o8ylt1mUz3Px4jno7Wp+r4Cw7+l3fFlKKJckVLkoXlwJTNZIamZGuxRT3gYIw3webw8MECxfNBsXntJ32HUKe438jq9qDdCxASDL1zmLeEcwskYSFW+QVbpZms0SRNDP09gDq4zUsHLdwOhz3hWzYa+R3/HXnz8f15+fn+ucRUbHAMLiGACZnJkRJW/tdwesrA4Ytiv/lt37cdENG/FSZWT0sUm9Xfj4otn45roB3/8nYa+JTbOA8sLKWUBEUZicmRE2xeSdzWLD4HSn2s1M8uuBDVerWLnWuZ2j34pZv/dsVaH7HW/Lor4iYgqIrGNqE7eoKSYTg9M2bkLml6a55Izj0FNuHLwVrH1sr2/Zw26ER+liD4Ayo9NUQdSN5GzZrz8JjT0wAKPjAHUHhqu45ifb8T9v33ZYOoj762QLAwBlQlyVZqsUU7MAY8N+/Umqp2Tq1+Pqs+fi2rt2oCyCA8PORm/1Dd+8Zef+OtnDAEDWi7vS9Ms5twowcW5BHbSSTHtgtPF6XL1sLnrLJVzzk+1Nd/vM2/TZImAAIOuZblkGCTBxDU4HqSTTThH5XY9r79yBOy85reVun7bcq4GCYwAg65luWQYNMHHMVmlXSdqQImp2PQ4MV9tW8NxfJ1sCBwARGQ+gz93YjSgxjZXmcLWKixfPie39k05dtKokgwQj0+mhVtdj/tFT2lbwnNaZHYGmgYrIuwFsBvBz9/cFInKHyYIRedX3q//4otkABKvW74xtmmEaK3+bTXVtF4y80yxP/fK9+Ma9T8Y+lbTd9TA1TZeSF2glsIg8DGAJgHXuzV0gIo+q6p/GWRiuBKZWTO/SmfbAa12z1dB+nx8AertKuP78+McJbLke1FoSK4EPquoLImM2brJnDwkyzobKwPRgsC2pi2YpIr/PDwCVkZqRcQJbrgeZEzQAbBeRCwGUReQ4AJcCuN9cscgmac9KqSvSNEPvXPz6fXn9Pn9dp4HQhgAflzx9FtOCBoBPAbgKQAXAjQD+A8D/MlUosocNs1LqijbN0C/wfuW8E3HZ6i2ojMR383VbAnwc8vRZktA2AIhIGcBdqnoGnCBABWLb6s6sTzMMc19ev8B73xVLcP+VS3Hjxl1YsXYAPeXOAqFNAb5TefosSWkbAFS1KiI1EZmsqi8kUSiyh41pl6zmpuO6L+/8o6fgU0uPw4Wn9HUcCFudp/58VgKtbY2VLAiaAhoC8KiI3APgQP1BVb3USKnIGkVLu5gStnUaJPDGEQibnWfbnhdwwaoHYrkHQFJsbKzYLmgA+Hf3HxVQ1tMuNohyL4IwgTdqpex3nvrmb37BasPAPmtz7GyshBcoAKjqd0WkB8Dx7kOPq+pBc8Ui22Q17WKLKK3ToIG304HPxvM88/zLKMvhN2vf/uyL1ufY2VgJJ+hK4MUAngSwEsA3ATwhIosMlosyKskbndh4U5Vmpk3sxftOnjXmsff1zxqzvYPfZ2m36jaum9V4z7Ntzwuj2z7XOcFL3ZvFH+IdL7AFVyoHFzQF9DUA76zvAyQixwO4CcDJpgpG2ZPkFLysTfcbHKrgloefGfPYLZuewaeXHh85rTI4VMHax/b6ttajDnwODlVw7V07Dnv86rPnYt5Rk5ljz5mgt4Ts9m4Cp6pPAOg2UyTKIhO3TUzyXKZ7E/UxAK/GtIr3swz8/qWm5RkcquBf7n0Sp375Xlzzk+2+rfWolbJfOSf0lnHCzMmp7JlEZgXtAWwSkRsAfN/9/QMAuGkPjUpyCl7WbtE4OFTBCy8PY7jaPK3i/Sy1ag1nfWMDesuH7wX0g427sGLNkxiuOgvBKiOH3nNCTxlV1Y4qZb+ximpNRwMKc+z5EjQAfBLAxXC2gACAX8AZCyACkOwUvKDnCjIzxvTiIW9wqSnQVQLGd3eNVux+aZXhGoBaDcMjh8rz0isj+NKdO1AZ8d8KYkJvGV989zyc8cbXdFTuIDNpOCEgP4IGgC4A/6yq/wcYXR3MbwCNSnIKXpBzBW3Vm+y5+AWX3q4SVn7gTZh31KtG3//qs+fiqh9va/o+ZRF88c4dowHBT7WmHVf+dWzlF0fQAHAvgLfDWRAGAOMB3A3gVBOFomxKsuJod3P3oK16kz0Xv+DSUy5h8vjuMeU4YeZkTOwtj7nX7pjyVGvo6SpheMT/PL1dEnuwZSu/GIIOAo9T1XrlD/fnI8wUibIsySl4zc7VbMDVb7pi48Bmb5fEdrexoMFl1tTxh91rF3By+uO6S/jCu+f5Pt9TFvzdO47H/VcutXoGFNkraA/ggIi8SVUfAQAR6Qdg1+RfIlfYVn29N/GDjbuwcu0AVq3fiZXrBjoeDA6aFvNdjbtsLk44avJo72bSuC7PLTFruOSMObjwlD620qkjQe8I9mYAPwTwrPvQ6wBcoKoPx1kY3hEs+2zZJ6bZXbWaMXm3sTA7gLY6zpZrS3Yxdkcwt+LfraoPicgbAXwCwF/AuTfwbwMU7CkALwGoAhiJWkjKBpsWZ4UdjzA5GBw0n97uuDB5eQYLCqJdCujbcAZ/AeBtAP4HnJvDLACwCsD5Ac5xhqrui1xCyoQo0ylNV1JhKsw87SRpUyAmu7UbBC6r6h/cny8AsEpVb1XVqwHEM1JGuRBm4BVwKqmF163BRTdsxMLr1uCOzXuSKGZTeVnlmuSKbMq+dj2Asoh0qeoIgKUAlod4LeDcOP5uEVEA31bVVRHLSZZr1oKe0FMevaetd+MzG3eVzMP8d94UhcJoV4nfBOA/RWQfnFk/vwAAEZkDIMjdwU5T1T0i8hoA94jIY6q63nuAiCyHG1j6+vrClp9iEEcqxm8my/tOnoVlKzYcloqwuZJqTBtlLZeep1QWmdcyAKjqP4jIvXBm/dyth6YMleCMBbSkqnvc/+4VkdsAvAXA+oZjVsEZT0B/f3/7KUkUSrsKLM58sbcFPaGnjGUrNvi28rNSSWUxl86bolAYQe4J/KDPY0+0e52ITABQUtWX3J/fCeBLkUpJkbSrwEykYuot6C2797e8p63tlZStaaog8pDKomQEXQgWxZEAbhNnr/IuADeq6s8Nno88glRgJlMx7Vr5tldSNqepguBWDhSEsQCgqjsBzDf1/tRakArMZCom7l0lk87FZyVNRdQJkz0ASlGQCsx0vjiuVn5cufgwQSQrufSsDVKTXQJtBZEUbgURr6DbIdhcicS1RUPUIGLztcniIDXFz9hWEJRtQVvgNueL48jFdzKga+u1yfIgNdmDASDnbK3AgoojF2/TgG69R3FwpIqnBv+IBUdPwZwjJ4V+H5s+E2UXAwABMJvq6PS9L148ByvWPomecjlSLt6WAd16ymakWoP35l4felsfvnTun4Z6L1s+E2VbLgKAzXnaLDCZS+7kvb2vBQTLF82OtAe+DQO63pRNo+89sAsfeusxoXoCNnwmyr7MBwAOhHXGZC65k/f2e+3KdQO48JRo24WYWncQtPHhl7Lx2rx7f+hUkO1rKch+mQ4ASQ6E5bWXYTKX3Ml7myhX3OMhYRoffikbrwVHT4lUhqyP8VC6gt4T2EphtyCOyratiweHKtiye38sW/yazCV38t6257jDbrvs3W66q+Gv7kNv64s0EEzUqUz3AJKoJGybbhd3ystkLrmT97Ytx93YA4zSQ/GmbDqdBUQUh0wHgCQqCZum2wUNRmHTVSZzyZ28ty05br+gu3DO9EiND2/Kpv/YacbKXJfX1CXFI9MBADBfSaSdivD+AQcJRlF7CCb35ekkT512jrtZ0L3viiWjjY+yCA5Wa7j67LlWVbKcIEHtZD4AAGYriTRTEY1/wFcvm9syGCWRrgpbqWS9Bdoq6J6zYCZeemUEX7xzB3q6Srj2rh2YNK7LikrWttQl2SkXAcC0KL2MTis+vz/ga+/cgavPnotr79rhG4xMp6vCVCqDQxX8YOMurGxYwGVD5RhGqx7g4FAF1961A8MjNQyPOM95r0eawc+m1CXZiwEgoDC9jDi63s3+gE+YORn3XbHEt2Ixna4KWqncvnkPLl+9FRV3uWtlxKkds9gCbdUDbHXTmw0D+4ylX4IElrRTl5QNDACuuFprcXW9W/0BNwtGptNVQSqV+uevjBw+5z2rLdBmPcBm12NCT9lY+iVo48K2WVRkJwYAxDtYFlfXO+ofcL2y2v7siwAU846aHOlzRC1TqxWvWW6B+gXdZtfjwHDVSPolbOPClllUZK/CB4C4B8uidL2b9T6i/gGbTD+0K1OzFa+9XWKsBZpmrt3vegwOVVqOG0Qta5TGRdqzqMhuhQ8AcQ+WhW25t+t9tPsDbqxQkpj90apMjZ9/uFrDJWfMibSJWxAmpjp2Os212Xeg08DMvD7FrfABwMQfVdCWe6eVtV/l9/ppE1Kf/ZFU6sFEsIsroDReAwCjdzaLWlbm9SluhQ8Apv6ognS9O+l9DPz+JVz2oy0YruqYCuXOS06zopWYROoh7t5b3AHFew1azRjK4upoyofCBwAgvT+qqL2P2zfvwWWrt2K4OvZ+zt2lEg4MVwvTSoy792Zy7nycZWVen+LCAOBK448qSu+j3kod9plmWa9Q5h89pRCtxLh7byZz7EzfkI0YAFIWtvfRbJplT3nsLJuitBLj7r11evvJJMtK1CkGAAuEqaxnTR2P4Wp1zGM9XSX89FOnFXZb4TiCXVy3n2ynKIGZsiHTN4Qpog0D+1DzpP67SsBXzz+xsJV/HBpv7lIZqWHluoGO3zOum/YQmcIeQIbUK6qDnsHfcqmEhXOmp1iq7It78JfbMFNWsAeQIX63wOwpx38LzLjZ3hqOc/A37K0iidLEAGCJIJVkFleC2nY/ZT/1GTrjukuY1NuFcd2lyIO/Sd2nmigOTAFZIK87PGbppiRxzdDJYpCm4mIASFmed3jM2k1J4pihk7UgTcVmPACISBnAJgB7VHWZ6fNlTZ53eLSlNZz0bqFZCtJUbEn0AD4N4NcAXpXAuTLHlkrSBBtaw2nNyMlKkKZiMxoARGQWgLMB/AOAz5o8V1i23Ky8XkletnoLylJCVfOVMkizNZylMQiiNJjuAfwTgMsBWLVKybZ52gpAFahCodr28MxJqzWctTEIoqQZmwYqIssA7FXVh9sct1xENonIpueee85UcUbZNk97cKiCv7tlM4arispIDcNVxWdv2cx54zHIc3qNKA4m1wEsBHCOiDwF4IcAlojI9xsPUtVVqtqvqv0zZswwWByHbfO0tz/7Iho39hypwb2nL3Uizvn9RHlkLAWkqp8D8DkAEJHFAP5eVS8ydb6g7GsVNsv55DAXlALOyCFqrnArgW1rFc47ajK6yzLmse6yYN5Rk1MpTx5Nm9iL+UdPYeVP1CCRhWCqug7AuiTOFYRNrcJpE3vxtffOx2Wrt6JcElRriuvPZ5qCiMwr7Epgm+Zp2xSQ/NgyZZaI4lWIAJCFCsymgORl25RZIopP7gMAK7DouJCKKN9yPQhs25z/rLFtyiwRxSvXAYAVWGfsmzJLRHHKdQAoWgUW9523bJsyS0TxyvUYgA27USbF1FiH7TOUiCi6XAcAoBgVmOnBWltnKBFRZ3IfAID8VGDNprNy10siiqIQASAPWqV4ijbWQUTxyPUgcF60m87KwVoiioI9gAwIkuIpwlgHEcWLASADgqZ48jLWQa1lYWsTygamgDIg7ymeuNcv5Nntm/dg4XVrcNENG7HwujW4Y/OetItEGcYeQEbkNcXDvZqC495MFDf2ADIkbzc24V5N4XBrE4obA0CMmMoIhxVaOJzuS3FjAIhJnLnZogQSVmjh5H0siJLHMYAYxJmbLVJOvEh7NcUlr2NBlA4GgBjEtRVDJ4Ekq1MDWaGFx+m+FBcGgBjElcqIGkiy3mtghUaUDo4BxCCu3GyUQMKZNEQUFXsAMYkjlRElJ86dQIkoKgaAGMWRyggbSEzOpMnquAIRBcMAYKGwgeTixXOwYu2T6CmXY5tJk/VxBSJqjwEgw7yVNCBYvmg2Ljylr+PKn1sOEBUDB4EzqnHwtzJSw8p1A7G8N1foEhUDA0BGmaykuUKXqBgYADLKZCXNLQeIiiGXYwBFmL1iehsFrtAlyr/cBYAizV4xXUlzhS5RvhkLACIyDsB6AL3ueVar6hdMnQ8o5uwVVtJEFJXJMYAKgCWqOh/AAgBnishbDZ6Ps1eIiEIw1gNQVQUw5P7a7f5TU+cDOHuFiCgMo7OARKQsIpsB7AVwj6puNHk+zl4hIgrO6CCwqlYBLBCRKQBuE5ETVHWb9xgRWQ5gOQD09fV1fE7OXiEiCiaRdQCquh/AWgBn+jy3SlX7VbV/xowZsZwvbzdPJyIywVgAEJEZbssfIjIewDsAPGbqfEREFI7JFNDrAHxXRMpwAs0tqnqnwfPlUhEWtRFROkzOAtoK4CRT718ERVrURkTJ415AluKtHonINAYAS3FRGxGZxgBgKS5qIyLTGAAsxUVtRGRa7nYDzRMuaiMikxgALMfdPonIFKaAiIgKigGAiKigGACIiAqKAYCIqKAYAIiICkqcG3fZQUSeA/B0xJdPB7AvxuIkgWVORhbLDGSz3CxzMrxlfr2qRtpL36oA0AkR2aSq/WmXIwyWORlZLDOQzXKzzMmIq8xMARERFRQDABFRQeUpAKxKuwARsMzJyGKZgWyWm2VORixlzs0YABERhZOnHgAREYVgfQAQkTNF5HERGRCRK32e7xWRm93nN4rIMZ7nPuc+/riI/JlFZf6siOwQka0icq+IvN7zXFVENrv/7kiqzAHL/RERec5Tvo95nlieK/8AAAf8SURBVPuwiDzp/vuwRWX+uqe8T4jIfs9zqVxrEfmOiOwVkW1NnhcR+Rf3M20VkTd5nkvrOrcr8wfcsj4qIveLyHzPc0+5j28WkU0WlXmxiLzg+Q583vNcy+9VimW+zFPebe53+NXuc+Gvs6pa+w9AGcBvAMwG0ANgC4C5Dcf8LYBvuT+/H8DN7s9z3eN7ARzrvk/ZkjKfAeAI9+dP1svs/j5k8bX+CIAVPq99NYCd7n+nuj9PtaHMDcd/CsB3LLjWiwC8CcC2Js+fBeBnAATAWwFsTPM6ByzzqfWyAHhXvczu708BmG7hdV4M4M5Ov1dJlrnh2HcDWNPJdba9B/AWAAOqulNVhwH8EMC5DcecC+C77s+rASwVEXEf/6GqVlT1twAG3PdLvcyqulZV/+j++iCAWQmUq50g17qZPwNwj6r+QVWfB3APgDMNldMrbJn/EsBNCZSrJVVdD+APLQ45F8D31PEggCki8jqkd53blllV73fLBFjynQ5wnZvp5G+hIyHL3PH32fYAMBPAbs/vz7iP+R6jqiMAXgAwLeBrTQh73o/Cae3VjRORTSLyoIj8uYkCNhG03Oe5Xf3VInJ0yNfGLfB53TTbsQDWeB5O61q30+xzpXWdw2r8TiuAu0XkYRFZnlKZmnmbiGwRkZ+JyDz3Meuvs4gcASf43+p5OPR15g1hUiQiFwHoB/DfPQ+/XlX3iMhsAGtE5FFV/U06JTzMTwDcpKoVEfkEnJ7XkpTLFNT7AaxW1arnMZuvdSaJyBlwAsBpnodPc6/zawDcIyKPuS3dtD0C5zswJCJnAfgxgONSLlNQ7wZwn6p6ewuhr7PtPYA9AI72/D7Lfcz3GBHpAjAZwGDA15oQ6Lwi8nYAVwE4R1Ur9cdVdY/7350A1gE4yWRhPdqWW1UHPWW9AcDJQV9rSJjzvh8N3eUUr3U7zT5XWtc5EBE5Ec734lxVHaw/7rnOewHchmRSsW2p6ouqOuT+/FMA3SIyHZZfZ1er73Pw65zEwEYHAyJdcAa6jsWhwZh5DcdcjLGDwLe4P8/D2EHgnUhmEDhImU+CM8h0XMPjUwH0uj9PB/Akkht8ClLu13l+fg+AB92fXw3gt275p7o/v9qGMrvHvRHOAJnYcK3dcx6D5oOTZ2PsIPAv07zOAcvcB2ec7dSGxycAmOT5+X4AZ1pS5tfWvxNwKstd7jUP9L1Ko8zu85PhjBNM6PQ6J/KBOrwYZwF4wq0wr3If+xKcljMAjAPwI/fL90sAsz2vvcp93eMA3mVRmf8fgN8D2Oz+u8N9/FQAj7pfuEcBfNSya/2PALa75VsL4I2e1/61+/9gAMBf2VJm9/drAHy54XWpXWs4LbffATgIJ7/8UQB/A+Bv3OcFwEr3Mz0KoN+C69yuzDcAeN7znd7kPj7bvcZb3O/OVRaV+RLP9/lBeIKX3/fKhjK7x3wEzgQX7+siXWeuBCYiKijbxwCIiMgQBgAiooJiACAiKigGACKigmIAICIqKAYAso6IHCkiN4rITndZ+wMi8h73ufoOjr9yd2tcLyLLPK+9RkT2eHZLPCe9TxKOiPxURKa4//427fJQ/jEAkFXcjfx+DGC9qs5W1ZPhLPDzbi72C1U9SVXfAOBSACtEZKnn+a+r6gIA7wXwHRGJ7XvubtVs5O9GVc9S1f0ApsDZ5ZbIKAYAss0SAMOq+q36A6r6tKp+w+9gVd0MZ+HXJT7P/RrACJyVvqPcXsL/dXsWT4rIxz3PXSYiD7kb3n3RfewYt7fxPQDbMHabAIjIm9098LeIyC9FZJL7ml+IyCPuv1PdYxe7vZa73Pf8Vj2guPu5TwfwZQB/4vZirheRieLcN+IRd7/3RHampPzjZnBkm3lwNukK4xEAlzU+KCKnAKgBeM7nNSfC2WZhAoBfichdAE6AsxnYW+Csxr1DRBbB2SLgOAAfVmd7Zu85egDcDOACVX1IRF4F4GUAewG8Q1VfEZHj4Kzw7Hdf9hY496t4GsDPAfwFnK3M664EcILbi6nvcfUeVX3RDRAPisgdylWc1CEGALKaiKyEs7PksKq+udlhDb9/xt1p9SU4FbNfRXm7qr4M4GURWQunUj4NwDsB/Mo9ZiKcin8XgKcbK3/XGwD8TlUfApwNxtxyT4CTmloAoArgeM9rfqnOBnQQkZvc865GcwLgf7vBqAZna+IjAfxXi9cQtcUAQLbZDuC8+i+qerHb6m11i7uTAPza8/vXVfWrbc7TGBQUTkX7j6r6be8T4txm9ECb92v0GTj7Pc2Hk2p9pc25W/kAgBkATlbVgyLyFJw9sIg6wjEAss0aODdq+aTnsSOaHexuQXw1nM3TwjhXRMaJyDQ4twZ8CMB/APhrEZnovvdMd2/1Vh4H8DoRebP7mkmebcl/p6o1AB+Ec5vBureIyLFu7v8CABsa3vMlAJM8v08GsNet/M8A8HoQxYA9ALKKqqp7d66vi8jlcPL3BwBc4TnsdBH5FZzAsBfApap6b8hTbYWzo+l0ANeq6rMAnhWR/wbgAWcyEoYAXAQnhdOsvMMicgGAb4jIeDj5/7cD+CaAW0XkQ3Dy/N4exEMAVgCY45bhtob3HBSR+8S5MfjPAFwH4Cci8iicntBjIT8rkS/uBkqFIyLXwLkhfLs0kYlzLwbw96q6rN2xRKYxBUREVFDsARARFRR7AEREBcUAQERUUAwAREQFxQBARFRQDABERAXFAEBEVFD/HyH5SrkwdqAcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy1530ik8b1T",
        "colab_type": "text"
      },
      "source": [
        "The relationship between GDP per capita and happiness Score seems relatively linear. Let's build a linear model to predict happiness score using the GDP per capita feature. Before we do, we need to prepare the training and test dataset our model will use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEf5NMjYkGCB",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_zSR0HP9CHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ea6d050a-b502-493f-dd54-74c8aed791c9"
      },
      "source": [
        "# define the x and y variables \n",
        "x_col = 'GDP per capita'\n",
        "y_col = 'Score'\n",
        "\n",
        "# split the dataset into a training set and a test set.\n",
        "# we will use the test set in the final evaluation of our model.\n",
        "train = happy2019.sample(frac=0.8, random_state=0)\n",
        "test = happy2019.drop(train.index)\n",
        "\n",
        "# separate the x (features) and y (labels) in the train/test datasets\n",
        "train_features = train[x_col].values.reshape(-1, 1)\n",
        "test_features = test[x_col].values.reshape(-1, 1)\n",
        "\n",
        "train_labels = train[y_col].values.reshape(-1, 1)\n",
        "test_labels = test[y_col].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "print('train features shape:', train_features.shape)\n",
        "print('train labels shape:', train_labels.shape)\n",
        "\n",
        "print('test features shape:', test_features.shape)\n",
        "print('test labels shape:', test_labels.shape)\n",
        "\n",
        "print('first 5 test labels:\\n', test_labels[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train features shape: (125, 1)\n",
            "train labels shape: (125, 1)\n",
            "test features shape: (31, 1)\n",
            "test labels shape: (31, 1)\n",
            "first 5 test labels:\n",
            " [[7.246]\n",
            " [6.726]\n",
            " [6.444]\n",
            " [6.354]\n",
            " [6.3  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fnwk72hSBj",
        "colab_type": "text"
      },
      "source": [
        "The above code returns a training and test dataset. The GDP per capita variable represents the  *features* data and the happiness Score represents the *labels*. There aretwo datasets--a *training dataset* and a *test dataset*. The `train_features` and `train_labels` arrays represent the features and labels of the training dataset, each containing 125 rows and 1 column. The `test_features` and `test_labels` arrays represent the features and labels of the test dataset, each containing 31 rows and 1 column.  \n",
        "\n",
        "Now that we have the *features* and *labels* separated, we are ready to build our model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qod9zI2I4iw",
        "colab_type": "text"
      },
      "source": [
        "## 2. Building a model\n",
        "\n",
        "Before we model the relationship between happiness Score and GDP per capita, let's write what we know about single-variable linear regression. In short, single-variable linear regression tries to find a function that best fits our data (i.e., between an $x$ and $y$ variable). It is defined by the following formula: \n",
        "$$\n",
        "y = wx + b\n",
        "$$\n",
        "\n",
        "We can translate this function to our problem to model the relationship between GDP per capita ($x$) and happiness Score ($y$) as follows:\n",
        "\n",
        "$$ \n",
        "\\text{score} = w_{\\text{GDP per capita}} \\cdot \\text{GDP per capita} + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlaNcYLMJz9n",
        "colab_type": "text"
      },
      "source": [
        "Coding linear regression from scratch can be tedious: we'd need to manually define the parameters (weights and bias), compute gradients, and update the parameters. Fortunately, there are amazing open source libraries we can use to make this process a bit easier. Specifically, we'll use [Tensorflow](https://www.tensorflow.org/) to build and evaluate our linear regression model. We will use the `Sequential` class to define a container for the *layers* of our model. Given input data, a `Sequential` object passes it through the first layer, which transforms it, and then passes it to the second layer, and so on. We don't really need to use this model structure for linear regression (as you saw last lesson). Nonetheless, nearly every model we build in this series will depend on the `Sequential` class and Tensorflow, so we will use it from here on out.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNFNhNUAtBhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "6434b131-a26d-48e8-8b05-b70d89577231"
      },
      "source": [
        "# build the linear model \n",
        "model = keras.Sequential([\n",
        "            layers.Input((1,)), # the input layer (corresponds to GDP per capita)\n",
        "            layers.Dense(1) # the weight\n",
        "        ])\n",
        "\n",
        "print('model summary')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model summary\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4JD6_eLv3IX",
        "colab_type": "text"
      },
      "source": [
        "<!-- TODO: fix figure to one node -->\n",
        "<figure>\n",
        "<img src='https://d2l.ai/_images/singleneuron.svg' width='50%'></img><figcaption>Linear Regression: a single-layer neural network</figcaption>\n",
        "</figure>\n",
        "\n",
        "The model we defined above is a linear model, we could also call it a single-layer *fully-connected* neural network. We defined it using the `Dense` class. Note that we passed two arguments into the `Sequential` class. The first one specifies the input feature dimension, which is 1 (GDP per capita), and the second one is the output feature dimension, which is a single scalar and therefore 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLfbaRI5Dbk",
        "colab_type": "text"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "After defining the model, we need to configure the *loss function*. We will use the mean squared loss, which returns the averaged loss over samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyPXRk6j1ErK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = keras.losses.MeanSquaredError() #   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrT8n3sg2jMf",
        "colab_type": "text"
      },
      "source": [
        "### Optimization Algorithm\n",
        "Now that we have a loss function, we need to define an *opimization algorithm*. Specifically, we will use *stochastic gradient descent* to optimize our model. In other words, we use *stochastic gradient descent* to update the model parameters. We also define the *learning rate* as 0.01. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k1zwXU53RX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwlua-hq3gjz",
        "colab_type": "text"
      },
      "source": [
        "### Metrics\n",
        "Now that we have the loss function and the optimizer, we will define the *metrics* to report about our model. Specifically, we will track the *mean absolute error* and the *mean squared  error* metrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bPOmT7q3f7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = [keras.metrics.MeanAbsoluteError(), keras.metrics.MeanSquaredError()] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsJ_KerI4TEb",
        "colab_type": "text"
      },
      "source": [
        "### Glue Everything Together\n",
        "Now we need to put it all together. We will use Tensorflow's `compile` method to glue the model, loss function, optimizer, and metrics together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRMfKWQ84xDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=loss_fn,\n",
        "              optimizer=optimizer,\n",
        "              metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9EvNw5L5m66",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train the model\n",
        "Now that we have a model, it's time to train it. We will train the model for 100 *epochs* (i.e., iterations), and record the training and validation metrics in the `history` object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL64Vo7K6eNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "389b0656-6ceb-4fcf-c7d9-6a8de69f08ce"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 18.0072 - mean_absolute_error: 4.1718 - mean_squared_error: 18.0072 - val_loss: 15.7463 - val_mean_absolute_error: 3.8792 - val_mean_squared_error: 15.7463\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 13.3876 - mean_absolute_error: 3.5771 - mean_squared_error: 13.3876 - val_loss: 11.7084 - val_mean_absolute_error: 3.3242 - val_mean_squared_error: 11.7084\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.0635 - mean_absolute_error: 3.0954 - mean_squared_error: 10.0635 - val_loss: 8.7165 - val_mean_absolute_error: 2.8411 - val_mean_squared_error: 8.7165\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.5847 - mean_absolute_error: 2.6676 - mean_squared_error: 7.5847 - val_loss: 6.5600 - val_mean_absolute_error: 2.4311 - val_mean_squared_error: 6.5600\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.7716 - mean_absolute_error: 2.3053 - mean_squared_error: 5.7716 - val_loss: 4.9589 - val_mean_absolute_error: 2.0720 - val_mean_squared_error: 4.9589\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 4.4157 - mean_absolute_error: 1.9917 - mean_squared_error: 4.4157 - val_loss: 3.8266 - val_mean_absolute_error: 1.7717 - val_mean_squared_error: 3.8266\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.4358 - mean_absolute_error: 1.7321 - mean_squared_error: 3.4358 - val_loss: 2.9920 - val_mean_absolute_error: 1.5098 - val_mean_squared_error: 2.9920\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.7026 - mean_absolute_error: 1.5036 - mean_squared_error: 2.7026 - val_loss: 2.3973 - val_mean_absolute_error: 1.3105 - val_mean_squared_error: 2.3973\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1668 - mean_absolute_error: 1.3153 - mean_squared_error: 2.1668 - val_loss: 1.9597 - val_mean_absolute_error: 1.1892 - val_mean_squared_error: 1.9597\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7622 - mean_absolute_error: 1.1513 - mean_squared_error: 1.7622 - val_loss: 1.6452 - val_mean_absolute_error: 1.1112 - val_mean_squared_error: 1.6452\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4630 - mean_absolute_error: 1.0175 - mean_squared_error: 1.4630 - val_loss: 1.4204 - val_mean_absolute_error: 1.0438 - val_mean_squared_error: 1.4204\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2418 - mean_absolute_error: 0.9145 - mean_squared_error: 1.2418 - val_loss: 1.2632 - val_mean_absolute_error: 0.9864 - val_mean_squared_error: 1.2632\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0801 - mean_absolute_error: 0.8418 - mean_squared_error: 1.0801 - val_loss: 1.1536 - val_mean_absolute_error: 0.9476 - val_mean_squared_error: 1.1536\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9615 - mean_absolute_error: 0.7895 - mean_squared_error: 0.9615 - val_loss: 1.0778 - val_mean_absolute_error: 0.9208 - val_mean_squared_error: 1.0778\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8757 - mean_absolute_error: 0.7469 - mean_squared_error: 0.8757 - val_loss: 1.0277 - val_mean_absolute_error: 0.8989 - val_mean_squared_error: 1.0277\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8119 - mean_absolute_error: 0.7149 - mean_squared_error: 0.8119 - val_loss: 0.9889 - val_mean_absolute_error: 0.8775 - val_mean_squared_error: 0.9889\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7599 - mean_absolute_error: 0.6911 - mean_squared_error: 0.7599 - val_loss: 0.9637 - val_mean_absolute_error: 0.8642 - val_mean_squared_error: 0.9637\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7217 - mean_absolute_error: 0.6754 - mean_squared_error: 0.7217 - val_loss: 0.9474 - val_mean_absolute_error: 0.8570 - val_mean_squared_error: 0.9474\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6945 - mean_absolute_error: 0.6644 - mean_squared_error: 0.6945 - val_loss: 0.9370 - val_mean_absolute_error: 0.8505 - val_mean_squared_error: 0.9370\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6732 - mean_absolute_error: 0.6580 - mean_squared_error: 0.6732 - val_loss: 0.9307 - val_mean_absolute_error: 0.8448 - val_mean_squared_error: 0.9307\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6567 - mean_absolute_error: 0.6533 - mean_squared_error: 0.6567 - val_loss: 0.9267 - val_mean_absolute_error: 0.8391 - val_mean_squared_error: 0.9267\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6430 - mean_absolute_error: 0.6505 - mean_squared_error: 0.6430 - val_loss: 0.9242 - val_mean_absolute_error: 0.8347 - val_mean_squared_error: 0.9242\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6347 - mean_absolute_error: 0.6496 - mean_squared_error: 0.6347 - val_loss: 0.9227 - val_mean_absolute_error: 0.8309 - val_mean_squared_error: 0.9227\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6279 - mean_absolute_error: 0.6474 - mean_squared_error: 0.6279 - val_loss: 0.9214 - val_mean_absolute_error: 0.8276 - val_mean_squared_error: 0.9214\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6217 - mean_absolute_error: 0.6458 - mean_squared_error: 0.6217 - val_loss: 0.9214 - val_mean_absolute_error: 0.8258 - val_mean_squared_error: 0.9214\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6168 - mean_absolute_error: 0.6448 - mean_squared_error: 0.6168 - val_loss: 0.9203 - val_mean_absolute_error: 0.8246 - val_mean_squared_error: 0.9203\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6131 - mean_absolute_error: 0.6437 - mean_squared_error: 0.6131 - val_loss: 0.9202 - val_mean_absolute_error: 0.8236 - val_mean_squared_error: 0.9202\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6084 - mean_absolute_error: 0.6429 - mean_squared_error: 0.6084 - val_loss: 0.9195 - val_mean_absolute_error: 0.8224 - val_mean_squared_error: 0.9195\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6053 - mean_absolute_error: 0.6417 - mean_squared_error: 0.6053 - val_loss: 0.9183 - val_mean_absolute_error: 0.8211 - val_mean_squared_error: 0.9183\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6027 - mean_absolute_error: 0.6408 - mean_squared_error: 0.6027 - val_loss: 0.9173 - val_mean_absolute_error: 0.8198 - val_mean_squared_error: 0.9173\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6002 - mean_absolute_error: 0.6397 - mean_squared_error: 0.6002 - val_loss: 0.9171 - val_mean_absolute_error: 0.8186 - val_mean_squared_error: 0.9171\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5973 - mean_absolute_error: 0.6389 - mean_squared_error: 0.5973 - val_loss: 0.9168 - val_mean_absolute_error: 0.8175 - val_mean_squared_error: 0.9168\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5951 - mean_absolute_error: 0.6383 - mean_squared_error: 0.5951 - val_loss: 0.9136 - val_mean_absolute_error: 0.8157 - val_mean_squared_error: 0.9136\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5930 - mean_absolute_error: 0.6372 - mean_squared_error: 0.5930 - val_loss: 0.9126 - val_mean_absolute_error: 0.8145 - val_mean_squared_error: 0.9126\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5913 - mean_absolute_error: 0.6369 - mean_squared_error: 0.5913 - val_loss: 0.9093 - val_mean_absolute_error: 0.8127 - val_mean_squared_error: 0.9093\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5893 - mean_absolute_error: 0.6356 - mean_squared_error: 0.5893 - val_loss: 0.9075 - val_mean_absolute_error: 0.8112 - val_mean_squared_error: 0.9075\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5873 - mean_absolute_error: 0.6347 - mean_squared_error: 0.5873 - val_loss: 0.9066 - val_mean_absolute_error: 0.8099 - val_mean_squared_error: 0.9066\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5853 - mean_absolute_error: 0.6340 - mean_squared_error: 0.5853 - val_loss: 0.9041 - val_mean_absolute_error: 0.8082 - val_mean_squared_error: 0.9041\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5837 - mean_absolute_error: 0.6335 - mean_squared_error: 0.5837 - val_loss: 0.9021 - val_mean_absolute_error: 0.8066 - val_mean_squared_error: 0.9021\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5819 - mean_absolute_error: 0.6326 - mean_squared_error: 0.5819 - val_loss: 0.9002 - val_mean_absolute_error: 0.8052 - val_mean_squared_error: 0.9002\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5799 - mean_absolute_error: 0.6317 - mean_squared_error: 0.5799 - val_loss: 0.8975 - val_mean_absolute_error: 0.8036 - val_mean_squared_error: 0.8975\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5786 - mean_absolute_error: 0.6311 - mean_squared_error: 0.5786 - val_loss: 0.8975 - val_mean_absolute_error: 0.8023 - val_mean_squared_error: 0.8975\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5764 - mean_absolute_error: 0.6307 - mean_squared_error: 0.5764 - val_loss: 0.8960 - val_mean_absolute_error: 0.8009 - val_mean_squared_error: 0.8960\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5747 - mean_absolute_error: 0.6298 - mean_squared_error: 0.5747 - val_loss: 0.8937 - val_mean_absolute_error: 0.7992 - val_mean_squared_error: 0.8937\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5726 - mean_absolute_error: 0.6290 - mean_squared_error: 0.5726 - val_loss: 0.8900 - val_mean_absolute_error: 0.7972 - val_mean_squared_error: 0.8900\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5708 - mean_absolute_error: 0.6280 - mean_squared_error: 0.5708 - val_loss: 0.8877 - val_mean_absolute_error: 0.7956 - val_mean_squared_error: 0.8877\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5697 - mean_absolute_error: 0.6277 - mean_squared_error: 0.5697 - val_loss: 0.8851 - val_mean_absolute_error: 0.7941 - val_mean_squared_error: 0.8851\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5687 - mean_absolute_error: 0.6272 - mean_squared_error: 0.5687 - val_loss: 0.8845 - val_mean_absolute_error: 0.7927 - val_mean_squared_error: 0.8845\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5660 - mean_absolute_error: 0.6259 - mean_squared_error: 0.5660 - val_loss: 0.8831 - val_mean_absolute_error: 0.7913 - val_mean_squared_error: 0.8831\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5650 - mean_absolute_error: 0.6257 - mean_squared_error: 0.5650 - val_loss: 0.8822 - val_mean_absolute_error: 0.7901 - val_mean_squared_error: 0.8822\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5631 - mean_absolute_error: 0.6247 - mean_squared_error: 0.5631 - val_loss: 0.8780 - val_mean_absolute_error: 0.7882 - val_mean_squared_error: 0.8780\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5616 - mean_absolute_error: 0.6238 - mean_squared_error: 0.5616 - val_loss: 0.8762 - val_mean_absolute_error: 0.7867 - val_mean_squared_error: 0.8762\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5601 - mean_absolute_error: 0.6232 - mean_squared_error: 0.5601 - val_loss: 0.8729 - val_mean_absolute_error: 0.7851 - val_mean_squared_error: 0.8729\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5583 - mean_absolute_error: 0.6221 - mean_squared_error: 0.5583 - val_loss: 0.8702 - val_mean_absolute_error: 0.7834 - val_mean_squared_error: 0.8702\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5572 - mean_absolute_error: 0.6213 - mean_squared_error: 0.5572 - val_loss: 0.8678 - val_mean_absolute_error: 0.7818 - val_mean_squared_error: 0.8678\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5558 - mean_absolute_error: 0.6209 - mean_squared_error: 0.5558 - val_loss: 0.8650 - val_mean_absolute_error: 0.7801 - val_mean_squared_error: 0.8650\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5543 - mean_absolute_error: 0.6198 - mean_squared_error: 0.5543 - val_loss: 0.8622 - val_mean_absolute_error: 0.7786 - val_mean_squared_error: 0.8622\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5537 - mean_absolute_error: 0.6193 - mean_squared_error: 0.5537 - val_loss: 0.8590 - val_mean_absolute_error: 0.7770 - val_mean_squared_error: 0.8590\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5510 - mean_absolute_error: 0.6180 - mean_squared_error: 0.5510 - val_loss: 0.8568 - val_mean_absolute_error: 0.7755 - val_mean_squared_error: 0.8568\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5502 - mean_absolute_error: 0.6170 - mean_squared_error: 0.5502 - val_loss: 0.8556 - val_mean_absolute_error: 0.7742 - val_mean_squared_error: 0.8556\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5493 - mean_absolute_error: 0.6174 - mean_squared_error: 0.5493 - val_loss: 0.8528 - val_mean_absolute_error: 0.7728 - val_mean_squared_error: 0.8528\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5480 - mean_absolute_error: 0.6164 - mean_squared_error: 0.5480 - val_loss: 0.8500 - val_mean_absolute_error: 0.7712 - val_mean_squared_error: 0.8500\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5464 - mean_absolute_error: 0.6156 - mean_squared_error: 0.5464 - val_loss: 0.8486 - val_mean_absolute_error: 0.7698 - val_mean_squared_error: 0.8486\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5446 - mean_absolute_error: 0.6147 - mean_squared_error: 0.5446 - val_loss: 0.8478 - val_mean_absolute_error: 0.7684 - val_mean_squared_error: 0.8478\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5431 - mean_absolute_error: 0.6140 - mean_squared_error: 0.5431 - val_loss: 0.8439 - val_mean_absolute_error: 0.7666 - val_mean_squared_error: 0.8439\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5422 - mean_absolute_error: 0.6134 - mean_squared_error: 0.5422 - val_loss: 0.8440 - val_mean_absolute_error: 0.7658 - val_mean_squared_error: 0.8440\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5412 - mean_absolute_error: 0.6126 - mean_squared_error: 0.5412 - val_loss: 0.8433 - val_mean_absolute_error: 0.7644 - val_mean_squared_error: 0.8433\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5397 - mean_absolute_error: 0.6123 - mean_squared_error: 0.5397 - val_loss: 0.8411 - val_mean_absolute_error: 0.7631 - val_mean_squared_error: 0.8411\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5384 - mean_absolute_error: 0.6115 - mean_squared_error: 0.5384 - val_loss: 0.8393 - val_mean_absolute_error: 0.7619 - val_mean_squared_error: 0.8393\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5376 - mean_absolute_error: 0.6112 - mean_squared_error: 0.5376 - val_loss: 0.8364 - val_mean_absolute_error: 0.7603 - val_mean_squared_error: 0.8364\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5368 - mean_absolute_error: 0.6106 - mean_squared_error: 0.5368 - val_loss: 0.8327 - val_mean_absolute_error: 0.7587 - val_mean_squared_error: 0.8327\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5350 - mean_absolute_error: 0.6091 - mean_squared_error: 0.5350 - val_loss: 0.8307 - val_mean_absolute_error: 0.7572 - val_mean_squared_error: 0.8307\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5340 - mean_absolute_error: 0.6088 - mean_squared_error: 0.5340 - val_loss: 0.8278 - val_mean_absolute_error: 0.7556 - val_mean_squared_error: 0.8278\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5325 - mean_absolute_error: 0.6077 - mean_squared_error: 0.5325 - val_loss: 0.8268 - val_mean_absolute_error: 0.7545 - val_mean_squared_error: 0.8268\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5312 - mean_absolute_error: 0.6070 - mean_squared_error: 0.5312 - val_loss: 0.8245 - val_mean_absolute_error: 0.7530 - val_mean_squared_error: 0.8245\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5301 - mean_absolute_error: 0.6064 - mean_squared_error: 0.5301 - val_loss: 0.8224 - val_mean_absolute_error: 0.7514 - val_mean_squared_error: 0.8224\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5294 - mean_absolute_error: 0.6059 - mean_squared_error: 0.5294 - val_loss: 0.8204 - val_mean_absolute_error: 0.7500 - val_mean_squared_error: 0.8204\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5276 - mean_absolute_error: 0.6048 - mean_squared_error: 0.5276 - val_loss: 0.8186 - val_mean_absolute_error: 0.7486 - val_mean_squared_error: 0.8186\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5265 - mean_absolute_error: 0.6041 - mean_squared_error: 0.5265 - val_loss: 0.8167 - val_mean_absolute_error: 0.7473 - val_mean_squared_error: 0.8167\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5261 - mean_absolute_error: 0.6041 - mean_squared_error: 0.5261 - val_loss: 0.8150 - val_mean_absolute_error: 0.7461 - val_mean_squared_error: 0.8150\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5249 - mean_absolute_error: 0.6032 - mean_squared_error: 0.5249 - val_loss: 0.8136 - val_mean_absolute_error: 0.7449 - val_mean_squared_error: 0.8136\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5238 - mean_absolute_error: 0.6024 - mean_squared_error: 0.5238 - val_loss: 0.8117 - val_mean_absolute_error: 0.7435 - val_mean_squared_error: 0.8117\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5226 - mean_absolute_error: 0.6017 - mean_squared_error: 0.5226 - val_loss: 0.8107 - val_mean_absolute_error: 0.7425 - val_mean_squared_error: 0.8107\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5218 - mean_absolute_error: 0.6012 - mean_squared_error: 0.5218 - val_loss: 0.8096 - val_mean_absolute_error: 0.7415 - val_mean_squared_error: 0.8096\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5213 - mean_absolute_error: 0.6004 - mean_squared_error: 0.5213 - val_loss: 0.8085 - val_mean_absolute_error: 0.7405 - val_mean_squared_error: 0.8085\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5202 - mean_absolute_error: 0.6002 - mean_squared_error: 0.5202 - val_loss: 0.8063 - val_mean_absolute_error: 0.7390 - val_mean_squared_error: 0.8063\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5193 - mean_absolute_error: 0.5997 - mean_squared_error: 0.5193 - val_loss: 0.8026 - val_mean_absolute_error: 0.7373 - val_mean_squared_error: 0.8026\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5187 - mean_absolute_error: 0.5992 - mean_squared_error: 0.5187 - val_loss: 0.8002 - val_mean_absolute_error: 0.7360 - val_mean_squared_error: 0.8002\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5176 - mean_absolute_error: 0.5979 - mean_squared_error: 0.5176 - val_loss: 0.8000 - val_mean_absolute_error: 0.7351 - val_mean_squared_error: 0.8000\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5166 - mean_absolute_error: 0.5975 - mean_squared_error: 0.5166 - val_loss: 0.7980 - val_mean_absolute_error: 0.7338 - val_mean_squared_error: 0.7980\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5155 - mean_absolute_error: 0.5968 - mean_squared_error: 0.5155 - val_loss: 0.7977 - val_mean_absolute_error: 0.7328 - val_mean_squared_error: 0.7977\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5157 - mean_absolute_error: 0.5971 - mean_squared_error: 0.5157 - val_loss: 0.7946 - val_mean_absolute_error: 0.7315 - val_mean_squared_error: 0.7946\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5134 - mean_absolute_error: 0.5954 - mean_squared_error: 0.5134 - val_loss: 0.7929 - val_mean_absolute_error: 0.7305 - val_mean_squared_error: 0.7929\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5129 - mean_absolute_error: 0.5950 - mean_squared_error: 0.5129 - val_loss: 0.7919 - val_mean_absolute_error: 0.7295 - val_mean_squared_error: 0.7919\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5118 - mean_absolute_error: 0.5945 - mean_squared_error: 0.5118 - val_loss: 0.7905 - val_mean_absolute_error: 0.7287 - val_mean_squared_error: 0.7905\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5114 - mean_absolute_error: 0.5941 - mean_squared_error: 0.5114 - val_loss: 0.7888 - val_mean_absolute_error: 0.7275 - val_mean_squared_error: 0.7888\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5104 - mean_absolute_error: 0.5935 - mean_squared_error: 0.5104 - val_loss: 0.7877 - val_mean_absolute_error: 0.7264 - val_mean_squared_error: 0.7877\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5096 - mean_absolute_error: 0.5931 - mean_squared_error: 0.5096 - val_loss: 0.7850 - val_mean_absolute_error: 0.7260 - val_mean_squared_error: 0.7850\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5087 - mean_absolute_error: 0.5920 - mean_squared_error: 0.5087 - val_loss: 0.7831 - val_mean_absolute_error: 0.7254 - val_mean_squared_error: 0.7831\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5084 - mean_absolute_error: 0.5919 - mean_squared_error: 0.5084 - val_loss: 0.7807 - val_mean_absolute_error: 0.7253 - val_mean_squared_error: 0.7807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xv6IaPv8FcV",
        "colab_type": "text"
      },
      "source": [
        "We get to ~0.6578 validation mean squared error after training for 100 epochs on the training dataset. Let's check the model's training progress using the stats stored in the history object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ioic77M8XrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "0da0ea53-9779-4bf3-a9d3-03bcb3d3f4b7"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.511392</td>\n",
              "      <td>0.594100</td>\n",
              "      <td>0.511392</td>\n",
              "      <td>0.788785</td>\n",
              "      <td>0.727546</td>\n",
              "      <td>0.788785</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.510397</td>\n",
              "      <td>0.593477</td>\n",
              "      <td>0.510397</td>\n",
              "      <td>0.787663</td>\n",
              "      <td>0.726424</td>\n",
              "      <td>0.787663</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.509648</td>\n",
              "      <td>0.593146</td>\n",
              "      <td>0.509648</td>\n",
              "      <td>0.784980</td>\n",
              "      <td>0.725982</td>\n",
              "      <td>0.784980</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.508688</td>\n",
              "      <td>0.591959</td>\n",
              "      <td>0.508688</td>\n",
              "      <td>0.783129</td>\n",
              "      <td>0.725446</td>\n",
              "      <td>0.783129</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.508433</td>\n",
              "      <td>0.591855</td>\n",
              "      <td>0.508433</td>\n",
              "      <td>0.780717</td>\n",
              "      <td>0.725311</td>\n",
              "      <td>0.780717</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  mean_absolute_error  ...  val_mean_squared_error  epoch\n",
              "95  0.511392             0.594100  ...                0.788785     95\n",
              "96  0.510397             0.593477  ...                0.787663     96\n",
              "97  0.509648             0.593146  ...                0.784980     97\n",
              "98  0.508688             0.591959  ...                0.783129     98\n",
              "99  0.508433             0.591855  ...                0.780717     99\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSZuns88fhs",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize it too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuNpvE5C8eOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "75828c8b-4c79-47ce-a375-80322755ae47"
      },
      "source": [
        "hist.plot.line(x='epoch', y='val_mean_squared_error');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqDbYQc-b1m",
        "colab_type": "text"
      },
      "source": [
        "From the plot we can see that our model *converged* around the 20th epoch. In other words, the most optimal parameters (weights and bias)were found ofter 20 training iterations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de62RpCv_ion",
        "colab_type": "text"
      },
      "source": [
        "## 5. Evaluate the model\n",
        "Now that we trained our model, it's time to evaluate it by using the *test* dataset, which we did not use when training the model. This gives us a sense of how well our model predicts unseen data, which is the case when we use it in the real world. We will use the `evaluate` method to test the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn9i35lI_h6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "4a5f5827-912e-445e-ed8c-e62c6c97f16e"
      },
      "source": [
        "loss, mae, mse = model.evaluate(test_features, test_labels)\n",
        "print('Test set Mean Absolute Error: ', round(mae, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3837 - mean_absolute_error: 0.5160 - mean_squared_error: 0.3837\n",
            "Test set Mean Absolute Error:  0.516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oex24IXB8Ku",
        "colab_type": "text"
      },
      "source": [
        "The average (absolute) error is around +/- 0.516 units for happiness Score. Is this good? We'll leave that decision up to you. Let's also visualize the prediction and real happiness Score values using data in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfYGBlJOCgkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "95328791-b9e1-4b4f-9fee-623bd9349e46"
      },
      "source": [
        "test_predictions = model.predict(test_features).flatten()\n",
        "\n",
        "ax = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [Happiness Score]')\n",
        "plt.ylabel('Predictions [Happiness Score]')\n",
        "lims = [0, max(test_labels) + 1] # [0, 31]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5c_PyRzDdL9",
        "colab_type": "text"
      },
      "source": [
        "It looks like our model predicts reasonably well. Let's take a look at the error distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XijR03DrET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9a61cfc6-8534-48ca-b294-1a563c35be2b"
      },
      "source": [
        "error = test_predictions.reshape(-1, 1) - test_labels\n",
        "plt.hist(error, bins = 10)\n",
        "plt.xlabel(\"Prediction Error [Happiness Score]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATQElEQVR4nO3dfbRldX3f8fcHBkWBCoQrxYfxQqV5aNqAHa3xKYLRpWJ9iERjFW2X6ahJXTGpabFmudRmJVqb6EpMNCOx4NKqVWFVM1bkYRBcVWBAHgaIiZIh1VLBxBghaGT49o/9u3Dmzr13zsy9+965v3m/1jrr7rP3Pvv3Pfvc+7n7/M7ev5OqQpLUn0PWugBJ0jgMeEnqlAEvSZ0y4CWpUwa8JHVqw1oXMOm4446r2dnZtS5DktaNa6655ttVNbPQsgMq4GdnZ9m+fftalyFJ60aS2xZbZheNJHXKgJekThnwktQpA16SOmXAS1KnDHhJ6tSop0km2Ql8D9gF3FtVm8ZsT5L0gNU4D/60qvr2KrQjSZpgF40kdWrsI/gCPp+kgD+qqi3zV0iyGdgMsHHjxpHL6cvs2VvXpN2d7zhjTdqFg/M5S/tr7CP4p1TV44DnAL+c5GnzV6iqLVW1qao2zcwsOJyCJGk/jBrwVfXN9vMO4ALgCWO2J0l6wGgBn+SIJEfNTQPPAnaM1Z4kaXdj9sEfD1yQZK6d/15VnxuxPUnShNECvqpuBX5qrO1LkpbmaZKS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekTo0e8EkOTfKVJH8ydluSpAesxhH8rwC3rEI7kqQJowZ8kkcBZwDnjNmOJGlPG0be/nuA/wActdgKSTYDmwE2btw4cjnS+jJ79ta1LmHV7XzHGWtdQjdGO4JP8jzgjqq6Zqn1qmpLVW2qqk0zMzNjlSNJB50xu2ieDDw/yU7gY8DpST48YnuSpAmjBXxVvamqHlVVs8AvAJdW1SvGak+StDvPg5ekTo39ISsAVXUZcNlqtCVJGngEL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SerUaAGf5PAkVyW5PslNSd42VluSpD1tGHHbPwBOr6q7khwGfDHJ/6qqL4/YpiSpGS3gq6qAu9rdw9qtxmpPkrS7Ufvgkxya5DrgDuCiqrpyzPYkSQ8Ys4uGqtoFnJLkaOCCJD9ZVTsm10myGdgMsHHjxjHLGcXs2VvXugStAl9nrUerchZNVf0NsA149gLLtlTVpqraNDMzsxrlSNJBYcyzaGbakTtJHgI8E/jTsdqTJO1uqoBP8uRp5s1zArAtyQ3A1Qx98H+y7yVKkvbHtH3wvw88bop596uqG4BT97MuSdIyLRnwSX4aeBIwk+TXJhb9A+DQMQuTJC3P3o7gHwQc2dY7amL+3wJnjlWUJGn5lgz4qvoC8IUk51bVbatUkyRpBUzbB//gJFuA2cnHVNXpYxQlSVq+aQP+E8D7gXOAXeOVI0laKdMG/L1V9b5RK5EkrahpL3T6TJJfSnJCkmPnbqNWJklalmmP4F/Vfv76xLwCTlrZciRJK2WqgK+qE8cuRJK0sqYK+CSvXGh+VX1oZcuRJK2UabtoHj8xfTjwDOBawICXpAPUtF00r5+830aJ/NgoFUmSVsT+Dhd8N2C/vCQdwKbtg/8MD3yf6qHAjwP/Y6yiJEnLN20f/H+dmL4XuK2qvjFCPZKkFTJVF00bdOxPGUaUPAb4+zGLkiQt37Tf6PQS4Crg54GXAFcmcbhgSTqATdtF82bg8VV1BwzftwpcDHxyrMIkScsz7Vk0h8yFe/NX+/BYSdIamPYI/nNJLgQ+2u6/FPjsOCVJklbC3r6T9bHA8VX160l+DnhKW/Ql4CNjFydJ2n97O4J/D/AmgKo6HzgfIMk/bcv+5ajVSZL229760Y+vqhvnz2zzZkepSJK0IvYW8EcvsewhK1mIJGll7S3gtyf5t/NnJvlF4JpxSpIkrYS99cG/Abggyct5INA3AQ8CXjRmYZKk5Vky4KvqW8CTkpwG/GSbvbWqLh29MknSskw7Hvw2YNvItUiSVpBXo0pSpwx4SeqUAS9JnTLgJalTBrwkdWq0gE/y6CTbktyc5KYkvzJWW5KkPU07XPD+uBf491V1bZKjgGuSXFRVN4/YpiSpGe0Ivqpur6pr2/T3gFuAR47VniRpd2Mewd8vySxwKnDlAss2A5sBNm7cuBrlaJlmz9661iWoYwfj79fOd5wxynZH/5A1yZHAp4A3VNXfzl9eVVuqalNVbZqZmRm7HEk6aIwa8EkOYwj3j7QvDJEkrZIxz6IJ8MfALVX1u2O1I0la2JhH8E8GzgJOT3Jduz13xPYkSRNG+5C1qr4IZKztS5KW5pWsktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE6NFvBJPpjkjiQ7xmpDkrS4MY/gzwWePeL2JUlLGC3gq+py4K/H2r4kaWkb1rqAJJuBzQAbN27c7+3Mnr11pUqSpC6s+YesVbWlqjZV1aaZmZm1LkeSurHmAS9JGocBL0mdGvM0yY8CXwJ+NMk3krx6rLYkSXsa7UPWqnrZWNuWJO2dXTSS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktSpUQM+ybOTfDXJ15KcPWZbkqTdjRbwSQ4F/gB4DvATwMuS/MRY7UmSdjfmEfwTgK9V1a1V9ffAx4AXjNieJGnChhG3/Ujg/0zc/wbwL+avlGQzsLndvSvJV5fZ7nHAt5e5jfXOfeA+APcBrJN9kHcu6+GPWWzBmAE/laraAmxZqe0l2V5Vm1Zqe+uR+8B9AO4DcB+M2UXzTeDRE/cf1eZJklbBmAF/NXBykhOTPAj4BeDTI7YnSZowWhdNVd2b5N8BFwKHAh+sqpvGam/CinX3rGPuA/cBuA/gIN8Hqaq1rkGSNAKvZJWkThnwktSpdR/wSX4+yU1J7kuy6OlQPQ+bkOTYJBcl+fP285hF1tuV5Lp26+ID7729rkkenOTjbfmVSWZXv8rxTPH8/3WSOyde919cizrHlOSDSe5IsmOR5Unye20f3ZDkcatd41pZ9wEP7AB+Drh8sRUOgmETzgYuqaqTgUva/YXcU1WntNvzV6+8cUz5ur4a+E5VPRZ4N7C8S0oOIPvwe/3xidf9nFUtcnWcCzx7ieXPAU5ut83A+1ahpgPCug/4qrqlqvZ29Wvvwya8ADivTZ8HvHANa1lN07yuk/vmk8AzkmQVaxxT77/XU6mqy4G/XmKVFwAfqsGXgaOTnLA61a2tdR/wU1po2IRHrlEtYzi+qm5v0/8POH6R9Q5Psj3Jl5P08E9gmtf1/nWq6l7gu8CPrEp145v29/rFrWvik0kevcDy3vX+97+oNR+qYBpJLgb+4QKL3lxV/3O161kLS+2DyTtVVUkWO/f1MVX1zSQnAZcmubGqvr7SteqA8hngo1X1gySvYXg3c/oa16RVsi4Cvqp+dpmbWPfDJiy1D5J8K8kJVXV7e+t5xyLb+Gb7eWuSy4BTgfUc8NO8rnPrfCPJBuBhwF+tTnmj2+vzr6rJ53oO8F9Woa4Dzbr/+99fB0sXTe/DJnwaeFWbfhWwx7uaJMckeXCbPg54MnDzqlU4jmle18l9cyZwafVzdd9en/+8vubnA7esYn0Hik8Dr2xn0zwR+O5El2bfqmpd34AXMfSp/QD4FnBhm/8I4LMT6z0X+DOGI9Y3r3XdK7wPfoTh7Jk/By4Gjm3zNwHntOknATcC17efr17rulfoue/xugJvB57fpg8HPgF8DbgKOGmta17l5//bwE3tdd8G/Nha1zzCPvgocDvww5YFrwZeC7y2LQ/D2UZfb7/7m9a65tW6OVSBJHXqYOmikaSDjgEvSZ0y4CWpUwa8JHXKgJekThnwHZoYNXJHkk8keegytnVukjPb9DlLDdKW5OlJnjRx/7VJXrm/bU9sZzbJPRMjIl63Ettdor2dSW6cG500yWWTI5W2ehYcuXCZ7b49yXIv6tvXNp/YRtm8LsktSd46cnvbkty11MivWjnr4kpW7bN7quoUgCQfYTgn+HfnFibZUMO4LPukqvY21OzTgbuA/93Wf/++trGEr889p8UkObSqdi12f5HHhOGbze6bt+i0qvr2/pe776rqLavZXnMe8JKqur6NTvmjy93gUvu9qk5rV1FrFXgE378rgMe2o+sr2jjwNyc5NMm7klzdBqJ6Ddw/dvZ72xjjFwMPn9vQ5JFsG4f82iTXJ7kkwzjrrwV+tR0NPjXJW5O8sa1/Shvk7IYkF6SNWd+2+c4kVyX5syRP3Zcn144GfyfJ9cBPL3D/19o7mR1J3tAeM9ue34cYhpve7wG42rauaPvi2rl3MG1/X55ka2vr/UkOmaj53Rm+x+CSJDNt/uS7pZ1J3ta2eWOSH2vzj8gw/vlVSb6S5AVt/j9p865r+/jktu7W9hrtSPLSBZ7CwxkuEqKqdlXVzW17Ryb5b63tG5K8uM1/WZu3I8n9Qy8vsN9fMVHPH7V/Hlpta32llbeVvwF3tZ8bGIYteB3D0fXdwIlt2WbgN9r0g4HtwIkMY+tfxPBF6Y8A/gY4s613GcPVsTMMo/PNbWvuytm3Am+cqOP++8ANwM+06bcD75nY5u+06ecCFy/wfGaBe4DrJm5PbcuK4QiU+feBf85w5eIRwJEMV3Se2rZ3H/DERfbfTuC4ifuXAV+daPtmYEdb9lDg8DZ9MrC9TT8d+D5wUtuXF03sxwJe3qbfAry3TZ87sc5O4PVt+pd44Irk3wJe0aaPZriK9Qjg9ye2+SDgIcCLgQ9MPI+HLfBc3wJ8B7gAeM3Ec3nn3GvU7h/Tfh/+sr3+G4BLgRcusN9/nGGQs8Pa/T8EXjlvfx40V5Ou5c0j+D49JMl1DKH9l8Aft/lXVdVftOlnMYzPcR1wJcNwBycDT2MYfXBXVf1fhj/i+Z4IXD63rapaaixukjwMOLqqvtBmndfamXN++3kNQ/gu5Ov1wJdWnFJVV7T5u4BPTaw3ef8pwAVVdXdV3dXamXuHcFsNY4NP6+VzbTP8I5pzGPCBJDcyDIkw+RnFVTWM1b6L4XL6p7T59wEfb9Mfnpg/30L75VnA2e11u4xhKIaNwJeA/5TkPzKMGnoPwz+3Z7Z3SE+tqu/Ob6Cq3s7wT/vzwL8CPtcW/SzD5f1z630HeDxwWVXdWUMX30d44HWc3O/PYPjnenWr8xkM/+i0yuyD79P9ffBzhq5m7p6cxXCEeOG89SbDa7X8oP3cxb7/Tn6/du/vnX9/MXfvfZWp/CrDGEg/xdDl+f2JZfPHAVlsXJDF5i+0XwK8uPb8kptbklwJnAF8NslrqurSDF9P91zgN5Nc0gJ998aHIaPfl+QDwJ1J9me8/Mn9HuC8qnrTfmxHK8gj+IPXhcDrkhwGkOQfJzmC4asPX9r66E8ATlvgsV8GnpbkxPbYY9v87wFHzV+5HTl+Z6J//SzgC/PXG8EVwAuTPLQ9txe1eSvpYcDtNXxIexZDd8ycJ2QY6fEQ4KXAF9v8QxhGtoThqPmLTO9C4PVp/7GTnNp+ngTcWlW/x9At98+SPAL4u6r6MPAuYI/vIk1yxty2GN7B7WLolrsI+OWJ9Y5hGKztZ5Ic1/rUX8bCr+MlwJlJHt4ee2ySx+zDc9QK8Qj+4HUOw9v+a9sf+J0MX/V3AcMXQtzM0L3zpfkPrKo7k2wGzm/hdQfwTIZ+10+2D/5eP+9hrwLen+GUzVuBf7OP9f6j9nZ/zgdbmC2qqq5Nci5DMMHQj/2VrOwXb/8h8KkMp21+jt3fGVwNvBd4LMNIjhe0+XczhP9vMOy7hT78XMx/Bt4D3ND2/V8AzwNeApyV5IcM3+r1WwxdKu9Kch/DSIuvW2B7ZwHvTvJ3wL0MXVG7kvwm8AcZTgfdBbytqs7P8MXe2xiO0rfWAl+4U1U3t+f2+VbjDxn+Wdy2D89TK8DRJKV5kuxk+BBwv0+TTPJ0hg+Yn7fAsruq6sj9r3B9y3Ca5Buravta19I7u2ikPd0JXBIvxllxSbYxfOD6w7Wu5WDgEbwkdcojeEnqlAEvSZ0y4CWpUwa8JHXKgJekTv1/MCyxkz1DztgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij1MDhAbEpZ6",
        "colab_type": "text"
      },
      "source": [
        "The histogram shows that the errors aren't quite *Normally distributed* (also called *gaussian*), but we might expect that because the number of samples is very small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd6RuVz5FDZM",
        "colab_type": "text"
      },
      "source": [
        "## 6. Draw Conclusions\n",
        "We built a single-layer fully-connected neural network model to predict happiness Score given a country's GDP per capita. The model converged after about 20 epochs of training, and it achieved an average (absolute) error of +/- 0.516. We expect that a *deeper* model or more data samples or features could lead to better results on unseen data.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTQXVOX3GITZ",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "In this lesson we took a deeper dive into regression, translating traditional linear  regression into a single-layer fully-connected neural network. We covered several important techniques to handle regression problems:\n",
        "- Introduced *loss functions* and *optimization algorithms*.\n",
        "- Demonstrated preparing data for a model.\n",
        "- Used Tensorflow to build and train a model. \n",
        "- Showed how to evaluate a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOUYOD8VExr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}