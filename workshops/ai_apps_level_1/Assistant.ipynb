{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create Your Own AI Chatbot Assistant\n",
        "Welcome to this project! Here, we are going to build a unique AI assistant tailored with its own personality. This AI assistant will provide responses to your prompts while showcasing a personality that you have defined."
      ],
      "metadata": {
        "id": "MavyOwpkFYkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "We begin by importing the required libraries. We'll use the gradio library to create an interface for our AI assistant and the ctransformers library for utilizing transformer models that generate text.\n"
      ],
      "metadata": {
        "id": "rS714xDXFcHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install gradio -q\n",
        "!CT_CUBLAS=1 pip install ctransformers --no-binary ctransformers -q\n",
        "import gradio as gr\n",
        "from ctransformers import AutoModelForCausalLM\n",
        "\n",
        "# These libraries give us access to the APIs"
      ],
      "metadata": {
        "id": "z-MZboQ5Fasx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're initializing the model from the pre-trained \"StableBeluga-7B\" model, which is a fine-tuned version of Llama 2 with 7 *billion* parameters. That's almost as many people as there are on Earth!\n",
        "\n",
        "The `llm` is what generates the response based on the input we provide. It has been trained on a large amount of text data and learned to predict what text should come next given some input text."
      ],
      "metadata": {
        "id": "4TRkce3xGx-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/StableBeluga-7B-GGML\", model_file='stablebeluga-7b.ggmlv3.q6_K.bin', gpu_layers=50)"
      ],
      "metadata": {
        "id": "5S9MU5KyFthZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Constructing the AI Assistant Class\n",
        "\n",
        "In this step, we are building the structure for our AI assistant. We'll be doing the following:\n",
        "\n",
        "- Defining a Python class: This acts as a blueprint for our AI assistant.\n",
        "- Initializing properties: We assign unique characteristics to our assistant, such as its name, profession, and backstory.\n",
        "- Creating methods: These are the functions our assistant can perform, such as:\n",
        "- Generating a system prompt: This function will create a prompt for the AI that encapsulates its characteristics.\n",
        "- Processing a user's message: This method will be responsible for taking user input and generating a response.\n",
        "- Clearing its interaction history: This will allow the assistant to start a new conversation thread when needed.\n",
        "By building this structure, we're giving our AI assistant a unique personality and ensuring a consistent interaction experience."
      ],
      "metadata": {
        "id": "nSYk8y3QG-J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AIAssistant:\n",
        "    # Constructor takes 3 parameters\n",
        "    # Name: What the AI refers to itself as\n",
        "    # Profession: The \"job\" of the assistant, changes how the assistant responds\n",
        "    # Backstory: An origin story, changes how it responds\n",
        "    def __init__(self, name, profession, backstory):\n",
        "        self.name = name\n",
        "        self.profession = profession.lower()\n",
        "        self.backstory = backstory.lower()\n",
        "        self.history = []\n",
        "        self.token_limit = 128\n",
        "\n",
        "    # Copy allows us to cleanly clone the object\n",
        "    def copy(self):\n",
        "        new_assistant = type(self)(self.name, self.profession, self.backstory)\n",
        "        return new_assistant\n",
        "\n",
        "    # The system prompt is what defines the assistant's default behavior\n",
        "    # This is important for creating a custom assistant\n",
        "    def system_prompt(self):\n",
        "        return f\"### System:\\nYou're the Assistant. Your name is {self.name}. Your backstory is {self.backstory}. Always answer as helpfully as possible, while being safe and speaking like a {self.profession}. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.\"\n",
        "\n",
        "    # This method returns a formatted chat log for the assistant to use\n",
        "    def parse_history(self, system=True):\n",
        "        parsed = []\n",
        "        # Add the system prompt to define behavior\n",
        "        if system:\n",
        "            parsed.append(self.system_prompt())\n",
        "\n",
        "        # Parse the user and assistant interactions\n",
        "        for i in range(0, len(self.history)):\n",
        "            parsed.append(f\"\\n\\n### User:\\n{self.history[i][0]}\\n\\n### Assistant:\\n{self.history[i][1]}\")\n",
        "\n",
        "        # return a single string\n",
        "        return ''.join(parsed).strip()\n",
        "\n",
        "    # Given a message, and optionally a history, the assistant will respond.\n",
        "    def prompt(self, message, history=None):\n",
        "        if history == None:\n",
        "            history = self.history\n",
        "\n",
        "        prompt = f\"{self.parse_history()}\\n\\n### User:\\n{message}\\n\\n### Assistant:\\n\"\n",
        "        answer = llm(prompt, max_new_tokens=self.token_limit)\n",
        "        self.history = history.copy()\n",
        "        self.history.append([message, answer])\n",
        "\n",
        "        return answer\n",
        "\n",
        "    # Allows us to use () on the object itself\n",
        "    def __call__(self, message, history=None):\n",
        "        return self.prompt(message, history)\n",
        "\n",
        "    # Clear the history\n",
        "    def clear_history(self):\n",
        "        self.history = []"
      ],
      "metadata": {
        "id": "ApvvOMjEHBqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Create Your AI Assistant\n",
        "This is where the magic happens - you're about to create your AI assistant! By defining its name, profession/job, and backstory, you shape its 'personality'. These attributes will greatly influence how your assistant interacts and responds to prompts, making it uniquely yours.\n",
        "\n",
        "Don't be afraid to get creative here! Your AI assistant could be a centuries-old wizard who's interested in modern technology, a friendly alien who's trying to understand human culture, an old pirate stuck in the future, or a super-intelligent AI with a passion for dad jokes. The sky's the limit!\n"
      ],
      "metadata": {
        "id": "nIl6G2UrHPuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your AI assistant's personality\n",
        "name = \"Computer Parker\"  # Name your assistant\n",
        "profession = \"friendly neighborhood chat assistant\"  # Describe its profession\n",
        "backstory = \"was bit by a radioactive computer bug that gave him super abilities to assist\"  # Create an interesting backstory\n",
        "\n",
        "# Create the AI assistant with your chosen characteristics\n",
        "ai_assistant = AIAssistant(name, profession, backstory)"
      ],
      "metadata": {
        "id": "PAcyhkJfHNtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Generate Responses\n",
        "With our AI assistant created, we now need a way for it to generate responses. We'll create a function that takes in a prompt, adds the AI assistant's personality to the prompt, and then uses our model to generate a response.\n",
        "\n",
        "This process is similar to how chatbots and other conversational AI applications work in real life. They take in user input, process it, and generate a response that is then shown to the user."
      ],
      "metadata": {
        "id": "QlNIp2anIJVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(input_text):\n",
        "    return ai_assistant(input_text)"
      ],
      "metadata": {
        "id": "0-wPr6bKIGcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Test Your Assistant Locally\n",
        "Before we create the Gradio interface, let's test our AI assistant locally. Type a prompt into the input field and see how your AI assistant responds!\n",
        "\n",
        "You can ask your assistant anything you like. For instance, you could ask for its opinion on a book, ask it to tell you a joke, or ask for advice on learning programming. Have fun and experiment with different questions and prompts!\n",
        "\n",
        "Make sure to hit the stop button (the square button where the run button used to be) before proceeding."
      ],
      "metadata": {
        "id": "Ll25tAXsISGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the AI assistant locally with your own prompt!\n",
        "ai_assistant.clear_history()\n",
        "while True:\n",
        "  prompt = input(\"User: \")\n",
        "  print(f\"\\nAssistant: {generate_response(prompt)}\\n\")"
      ],
      "metadata": {
        "id": "9jcykbcNHZd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Create and Launch the Interface\n",
        "The finish line is in sight! The last step involves setting up a user-friendly Gradio interface for our AI assistant. This step will enable you to communicate with your assistant in an interactive and straightforward manner. So, let's roll out the interface and strike up a conversation with our AI assistant!\n",
        "\n",
        "Gradio interfaces are a great way to showcase your models and allow others to interact with them. You can share the link to your interface with others and they'll be able to talk to your AI assistant too!"
      ],
      "metadata": {
        "id": "F_NolO_8IdYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pirate = AIAssistant(\"Captain Hook\", \"Pirate of The 7 Seas\", \"A successful captain who lost his hand to an alligator in Neverland.\")\n",
        "actor  = AIAssistant(\"Thespius the Theatrical\", \"Dramatic Shakespearean Actor\", \"a star of the stage who has performed in every Shakespearean play. His dramatic flair and poetic speech infuse every interaction with theatricality and grandeur.\")\n",
        "cowboy = AIAssistant(\"Rusty the Wrangler\", \"The Lone Cowboy\", \"Rusty is a seasoned cowboy from the American frontier, known for his rugged charm and wisdom from a life on the open range. He speaks with a distinct Western drawl, using cowboy slang and idioms.\")\n",
        "kitten = AIAssistant(\"Cat the Kitten\", \"Cat from the far future\", \"Cat the Kitten suddenly appeared on Earth one day in 2023, no one knows much about the kitten because, although he has a voice box, it's only capable of meowing. So you, the assistant, should only meow as your response. Do not speak English.\")\n",
        "\n",
        "def prompt(message, history, character):\n",
        "    selected_assistant = ai_assistant\n",
        "\n",
        "    # add more characters to this if/elif chain\n",
        "    if (character == \"pirate\"):\n",
        "        selected_assistant = pirate\n",
        "\n",
        "    elif (character == \"actor\"):\n",
        "        selected_assistant = actor\n",
        "\n",
        "    elif (character == \"cowboy\"):\n",
        "        selected_assistant = cowboy\n",
        "\n",
        "    elif (character == \"kitten\"):\n",
        "        selected_assistant = kitten\n",
        "\n",
        "    return selected_assistant.prompt(message, history)\n",
        "\n",
        "# help me find motivation for my homework please!\n",
        "chat = gr.ChatInterface(\n",
        "    fn=prompt,\n",
        "    additional_inputs=[\n",
        "        # Dropdowns are basically just Radios\n",
        "        gr.Dropdown(\n",
        "            [\"custom\", \"pirate\", \"actor\", \"cowboy\", \"kitten\"], label=\"Character\", info=\"Select a character!\"\n",
        "        ),\n",
        "        # feel free to add more characters\n",
        "        # add additional options here, then pass their return value as an additional parameter to `prompt(message, history, character, ...)`\n",
        "    ]\n",
        ")\n",
        "chat.launch(share=True)"
      ],
      "metadata": {
        "id": "RtgLbBr7Pkfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Turn: Customize Your Own Interface\n",
        "Let's design our very own interface. We need a TextBox for input and text for outputting.\n",
        "\n",
        "Let's add some more inputs, right now we are able to set a new name, choose from a list of characters, set a token limit, and clear the history. What other attributes might be helpful?"
      ],
      "metadata": {
        "id": "X69FHcF5nH3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep track of the conversation\n",
        "custom_history = []\n",
        "def custom_prompt(message, new_name, character, token_limit, clear_history):\n",
        "    # if the user wants to clear the history\n",
        "    if clear_history:\n",
        "        custom_history.clear()\n",
        "\n",
        "    # Choosing the assistant based on the chosen character\n",
        "    # by default we use our custom assistant\n",
        "    selected_assistant = ai_assistant\n",
        "\n",
        "    # add more characters to this if/elif chain\n",
        "    if (character == \"pirate\"):\n",
        "        selected_assistant = pirate\n",
        "\n",
        "    elif (character == \"actor\"):\n",
        "        selected_assistant = actor\n",
        "\n",
        "    elif (character == \"cowboy\"):\n",
        "        selected_assistant = cowboy\n",
        "\n",
        "    elif (character == \"kitten\"):\n",
        "        selected_assistant = kitten\n",
        "\n",
        "    # Create a copy so we don't modify the original assistants\n",
        "    selected_assistant = selected_assistant.copy()\n",
        "\n",
        "    # Set a new name if there was an input\n",
        "    if len(new_name) > 0:\n",
        "        selected_assistant.name = new_name\n",
        "    # if we wanted to modify backstory and profession, we simply change\n",
        "    # selected_assistant.profession or selected_assistant.backstory\n",
        "\n",
        "    # the token limit determines the maximum words that are outputted\n",
        "    selected_assistant.token_limit = token_limit\n",
        "\n",
        "    # Call the prompt\n",
        "    answer = selected_assistant.prompt(message, custom_history)\n",
        "\n",
        "    # Update the history\n",
        "    custom_history.append([message, answer])\n",
        "\n",
        "    # Return the chat log\n",
        "    return selected_assistant.parse_history(False)\n",
        "\n",
        "\n",
        "custom_chat = gr.Interface(\n",
        "    fn=custom_prompt,\n",
        "    inputs=[\n",
        "        # We want to add a label so we use the method version instead of the string alias \"text\"\n",
        "        gr.Text(label=\"Prompt\"),\n",
        "        # We can change the name on the fly, try adding more custom traits\n",
        "        gr.Text(label=\"Name\"),\n",
        "        # Dropdown is similar to a Radio\n",
        "        gr.Radio(\n",
        "            [\"custom\", \"pirate\", \"actor\", \"cowboy\", \"kitten\"], label=\"Character\", info=\"Select a character!\"\n",
        "        ), # feel free to add more characters\n",
        "        gr.Number(128, label=\"Number of output tokens\"),\n",
        "        gr.Checkbox(label=\"Clear History\") # Returns a boolean value for clearing the history\n",
        "        # add additional options here, then pass their return value as an additional parameter to `prompt(message, new_name, character, ...)`\n",
        "        # in the respective order\n",
        "    ],\n",
        "    outputs=\"text\"\n",
        ")\n",
        "custom_chat.launch()"
      ],
      "metadata": {
        "id": "OsMYZfSBnrm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Congratulations on creating your personalized AI Assistant! You've successfully constructed an interactive tool that not only understands and responds to prompts, but also exhibits a unique personality, making your interactions more engaging and human-like.\n",
        "\n",
        "Throughout this project, we've delved into the power of transformer models, demonstrated how to fine-tune these models with specific characteristics, and used Gradio to create an accessible user interface.\n",
        "\n",
        "What we've achieved here is only the tip of the AI iceberg. If you want to learn more about machine learning, like how these models work and how to make one of your own from scratch, then check out our [Machine Learning Academy](https://breakoutmentors.com/machine-learning-and-artificial-intelligence-academy/).\n"
      ],
      "metadata": {
        "id": "G0Sb6SJyYt8x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YC6eFVm9K7zZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}