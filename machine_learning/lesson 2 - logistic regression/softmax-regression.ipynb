{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification-Logistic_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTiLakQHS23G01h9j7hOKO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/master/machine_learning/lesson%202%20-%20logistic%20regression/softmax-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIsgQYlKKVna",
        "colab_type": "text"
      },
      "source": [
        "# Classification: Softmax Regression\n",
        "In the previos lesson [logistic regression](https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/master/machine_learning/lesson%202%20-%20logistic%20regression/logistic-regression.ipynb), we learned about logistic regression and how it can be used to construct a logistic regression classifier to distinguish between two categorical values (e.g., whether a photo is of a dog or a cat). Logistic regression is great when we want are working with only two categorical values. \n",
        "\n",
        "In practice, we are often more interested in differentiating between many categorical values (e.g., more than 2 classes):\n",
        "- Is this image of a cat, a dog, or a chicken?\n",
        "- Is this song in the genre of hip hop, pop, funk, rock, etc.?\n",
        "- What brand of clothing does this t-shirt belong to?\n",
        "\n",
        "When we want to distinguish between many classes (called *multi-class classification*), we can use a classification technique called softmax regression.\n",
        "\n",
        "In this notebook, we will learn the foundations of softmax regression and demonstrate how to solve multi-class classification problems using an example--building a softmax regression classifier to distinguish 10 handwritten digit (0-9). The ideas we introduce here will build on previous material and continue to lay out the fundamental concepts used in deep learning and neural networks, which we will cover in future lessons. Here is the lesson roadmap:\n",
        "1. Review: representing categorical data\n",
        "2. Introduction to softmax regression\n",
        "3. Building a softmax regression classifier: recognize 10 handwritten digits from the MNIST dataset \n",
        "4. Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OYk2h2X2gqE",
        "colab_type": "text"
      },
      "source": [
        "# Review: representing categorical data\n",
        "<figure>\n",
        "  <img src='https://envato-shoebox-0.imgix.net/2718/a008-795b-4376-972d-ed9cbad8ac4f/2015_227_003_0063_A_2018_07_19.jpg?auto=compress%2Cformat&fit=max&mark=https%3A%2F%2Felements-assets.envato.com%2Fstatic%2Fwatermark2.png&markalign=center%2Cmiddle&markalpha=18&w=700&s=e3fbeb220008b297bee64675504ae70c' width='50%'>\n",
        "  <figcaption>Representing data: a Shina Inu, Retriever, and Lab</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "To motivate our understanding of softmax regression, let's consider the example where we want to distinguish 3 different dog breeds--(golden) retrievers, labs, and shiba inus, given $2 \\times 2$ grayscale images. We can represent each pixel value with a single scalar (number), giving us four features  $x_1,x_2,x_3,x_4$. Further, we know that each image belongs to one among the categories \"retriever\", \"lab\", \"shina inu\".\n",
        "\n",
        "To make the categorical labels useful, we need to convert it into a numerical representation.  \n",
        "\n",
        "There are two general ways to represent the categorical data in numeric terms. The first way is to choose choose $y \\in \\{1, 2, 3\\}$, where the integers represent {retriever, lab, shina inu} repectively. But, as you learned previously, the second way is better: *one-hot encoding*. As a refresher, a one-hot encoding is a vector with as many components as we have categories. The component corresponding to particular sample's category is set to 1 and all other components are set to 0. So in our case, this translates to:\n",
        "\n",
        "$$\n",
        "y \\in \\{ (1, 0, 0), (0, 1, 0), (0, 0, 1) \\},\n",
        "$$\n",
        "\n",
        "where $y$ would be a three-dimensional vector representing the dog breeds, with $(1, 0, 0)$ corresponding to \"retriever\", (0, 1, 0) to \"lab\", and (0, 0, 1) to \"shiba inu\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGvK59PbdliB",
        "colab_type": "text"
      },
      "source": [
        "# Intro to softmax regression\n",
        "<figure>\n",
        "  <img src='https://d2l.ai/_images/softmaxreg.svg' width='70%'>\n",
        "  <figcaption>Softmax regression is a single-layer neural network | Source: <a href='https://d2l.ai/_images/softmaxreg.svg'>Dive Into Deep Learning</a></figcaption>\n",
        "</figure>\n",
        "\n",
        "Now that we have a healthy understanding of classification techniques like *one-hot encoding* and logistic regression, let's dive into the softmax regression.\n",
        "\n",
        "Softmax regression is perhaps the most common machine learning algorithm. It is a special case of logistic regression where the labels ($y$) is categorical in nature but there are many categories rather than simply two. It is called \"softmax\" regression because it uses a *logit* function, called the *softmax* function, to estimate the *conditional probability* of a given class among many classes (i.e., more than 2). Unlike linear and logistic regression, softmax regression requires a model with multiple outputs, one per class. \n",
        "\n",
        "To address multi-class classification with softmax regression classifiers, we will need as many linear functions as we have outputs. Each output will correspond to its own linear function. In our case, since we have 4 features and 3 possible output categories, we will need 12 scalars to represent the weights, ( $w$  with subscripts) and 3 scalars to represent the biases ($b$ with subscripts). We compute these three *logits*, $o_1,o_2$, and $o_3$, for each input:\n",
        "\n",
        "\\begin{split}\\begin{aligned}\n",
        "o_1 &= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\\\\n",
        "o_2 &= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\\\\n",
        "o_3 &= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.\n",
        "\\end{aligned}\\end{split}\n",
        "\n",
        "\n",
        "We can depict this calculation with the neural network diagram shown above. Just as in linear regression, softmax regression is also a *single-layer neural network*. And since the calculation of each output, $o_1,o_2$, and $o_3$, depends on all inputs, $x_1, x_2, x_3$, and $x_4$, the output layer of softmax regression can also be described as *fully-connected* layer.\n",
        "\n",
        "To express the model more compactly, we can use linear algebra notation. In vector form, we arrive at  $\\mathbf{o} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} $, a form better suited both for mathematics, and for writing code. Note that we have gathered all of our weights into a  $3 \\times 4$  matrix and that for a given example $\\mathbf{x}$, our outputs are given by a *matrix-vector product* of our weights by our inputs plus our biases  $b$. From the above describtion, hopefully softmax regression feels suprisingly familiar to you, since it shares many of the techniques used by linear and logistic regression methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g-jZSRRPbT1",
        "colab_type": "text"
      },
      "source": [
        "## The softmax operation\n",
        "\n",
        "<figure>\n",
        "  <img src='https://deepnotes.io/public/images/softmax.png' width='50%'>\n",
        "  <figcaption>Single-layer softmax regression neural network | Source: <a href='https://deepnotes.io/'>deepnotes.io</a></figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "The main approach of softmax regression is to interpret the outputs of our model as probabilities. We will *optimize* our parameters to produce probabilities that *maximize the likelihood* of the observed data, just like logistic regression. Then, we generate predictions using a threshold (which we define), for example, choosing the *argmax* of the predicted probabilities. The *argmax* defines a given sample's predicted class based on the category with the highest probability value.\n",
        "\n",
        "Put formally, we would like outputs  $\\hat{y}_k$  that we can interpret as the probability that a given item belongs to class $k$. Then, we can choose the class with the largest output value as our prediction  $\\text{argmax}_k y_k $. For example, if $\\hat{y}_1 , \\hat{y}_2$, and $\\hat{y}_3$  are  $0.1, 0.8$, and $0.1$, respectively, then we predict category $2$, which (in our example) represents \"lab\".\n",
        "\n",
        "To interpret our outputs as probabilities, we must guarantee two things:\n",
        "1. They will be nonnegative.\n",
        "2. Given an input sample, the total of all the class probabilities sum up to 1.\n",
        "\n",
        "To transform our logits such that they become nonnegative and sum to $1$, while maintaining that the model remains differentiable (for gradient descent), we first exponentiate each logit (ensuring non-negativity) and then divide by their sum (ensuring that they sum to $1$). \n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathrm{softmax}(\\mathbf{o})\\quad \\text{where}\\quad\n",
        "\\hat{y}_i = \\frac{\\exp(o_i)}{\\sum_j \\exp(o_j)}.\n",
        "$$\n",
        "\n",
        "Now we can guarantee $\\hat{y}_1+\\hat{y}_2+\\hat{y}_3 = 1$  with  $0≤\\hat{y}_i≤1$ for all $i$ . Thus, we can interpret $\\hat{y}$ as a proper probability distribution. Note that the softmax operation does not change the ordering among the logits, and thus we can still pick out the most likely class by:\n",
        "\n",
        "$$\n",
        "\\hat{\\imath}(\\mathbf{o}) = \\operatorname*{argmax}_i o_i = \\operatorname*{argmax}_i \\hat y_i.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlHdxlqHWwBF",
        "colab_type": "text"
      },
      "source": [
        "## A note on the loss function\n",
        "The loss function for softmax regression is called categorical *cross-entropy*. A detailed description of cross-entropy is beyond the scope of this lesson. However, it's worth a quick summary. \n",
        "\n",
        "At a high level, cross-entropy is a measure of the difference between two probability distributions. It measures the amount of information (also called *bits*) needed to encode the data given our model. The goal is to predict the correct labels most of the time (via *maximum likelihood estimation*), while minimizing the *suprise* (entropy) required to communicate the labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOgrQdxJVdEK",
        "colab_type": "text"
      },
      "source": [
        "## Summary: Softmax Regression\n",
        "\n",
        "To summarize softmax regression:\n",
        "- Category labels ($y$) are converted to discrete integer values and represented using multi-dimensional vectors (e.g., dimensions $=$ # of classes $k$).\n",
        "- The *softmax* logit function maps input features ($\\mathbf{x}$) to probabilities and guarantees that they are nonnegative and sum up to 1.\n",
        "- A category prediction is determined by the threshold function, such as *argmax*, which selects the class with the highest probability among all $k$ classes.   \n",
        "- Softmax regression classifiers try to *maximize the likelihood* of the observed data, like logistic regression.\n",
        "- Categorical *cross-entorpy* is the loss function for softmax regression.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H1mvTcvaRUp",
        "colab_type": "text"
      },
      "source": [
        "# Softmax Regression: build a classifier to recognize handwritten digits\n",
        "\n",
        "Now that we know about the fundamentals of softmax regression, let's apply this method to a real-world problem--distinguishing between 10 handwritten digits (0-9) given the MNIST dataset--a dataset of grayscale handwritten digits. In this section, we will demonstrate in an end-to-end fashion the process of creating a softmax regression classifier: from building, to training, and finally evaluating the model to solve the handwritten digit classification task. This process involves several steps:\n",
        "\n",
        "1. Find, load, and prepare a dataset for the model.\n",
        "2. Build the model.\n",
        "3. Train the model using an algorithm such as stochastic gradient descent.\n",
        "4. Evaluate the quality of our model.\n",
        "5. Draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZcA1hmu_nSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "989aeddc-59d0-4979-8349-f202a309a256"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print('Tensorflow version:', tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1yKY66dhryV",
        "colab_type": "text"
      },
      "source": [
        "## 1. Finding and preparing the dataset\n",
        "For step 1, we found the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The dataset contains 70k grayscale images of handwritten digits at a resolution of $28 \\times 28$ pixels. Our goal is to build a classification model to take one of these images as input and predict the most likely digit contained in the image (along with a relative confidence about the prediction):\n",
        "\n",
        "<figure><img src=\"https://i.imgur.com/ITrm9x4.png\" width=\"65%\"><figcaption><em>Source: <a href=\"https://deeplearning.mit.edu/\">MIT Deep Learning</a></em></figcaption></figure>\n",
        "\n",
        "\n",
        "Loading the dataset will return four NumPy arrays:\n",
        "* The `train_features` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
        "* The `test_features` and `test_labels` arrays are the *test set*--the data the model is tested on.\n",
        "\n",
        "The images are $28\\times28$ NumPy arrays (i.e., the x variables), with pixel values ranging between 0 and 255. The *labels* (i.e., $y$) are an array of integers, ranging from 0 to 9. We will use *one-hot encoding* (the technique we learned about in the logistic regression lesson) to convert these labels to vectors (i.e., arrays with mostly 0s and a 1 at the index that corresponds to the data sample's digit category). We also need to *normalize* the input images between 0 and 1. This is achieved by dividing the features of each image by 255 (i.e., the max pixel value). Normalizing the data encourages our model to learn more generalizable features and helps it perform better on outside data. The final data processing step is \"flattening\" the $28\\times28$ image pixel matrices into 784 image pixel arrays. We reshape the image matrices into arrays because our model expects the input to be a vector/array with 784 features (i.e., values). \n",
        "\n",
        "Now, let's load the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3vusptMadti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "2bb436f0-303d-40a4-84a2-d65045faebd0"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (-1, 28*28) # this will be used to reshape the 28x28 image pixel matrices into 784 pixel vectors \n",
        "\n",
        "# the data, split between train and test sets\n",
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the images to the [0, 1] range\n",
        "train_features = train_features.astype(\"float32\") / 255\n",
        "test_features = test_features.astype(\"float32\") / 255\n",
        "\n",
        "# Flatten the images.\n",
        "train_features = train_features.reshape(input_shape)\n",
        "test_features = test_features.reshape(input_shape)\n",
        "\n",
        "print(\"train_features shape:\", train_features.shape)\n",
        "print(\"test_features shape:\", test_features.shape)\n",
        "\n",
        "print(train_features.shape[0], \"train samples\")\n",
        "print(test_features.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors (one-hot encoding)\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_features shape: (60000, 784)\n",
            "test_features shape: (10000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWAdKomCblCS",
        "colab_type": "text"
      },
      "source": [
        "Let's display the first 5 images from the *training set* and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMlEgpzNbjQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f96fa3f2-6ada-4804-d80b-44e2fdb61c59"
      },
      "source": [
        "plt.figure(figsize=(10,2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_features[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(np.argmax(train_labels[i]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB8P1GFcifvd",
        "colab_type": "text"
      },
      "source": [
        "## 3. Build the model\n",
        "Now that the data is ready, we can build the softmax classifier. We will use Tensorflow to define a simple softmax regression model (single-layer fully-connected neural network) to predict the class of each image (a digit between 0 and 9). Given a sample with a corresponding set of class predictions, our model will select the class with the highest prediction value using *argmax*. \n",
        "\n",
        "We also define the loss function, optimization algorithm, and metrics and \"glue\" them together with the model using the `compile` method. We will use *binary cross-entropy* loss, *stochastic gradient descent*, and track the *accuracy* metric.\n",
        "\n",
        "Notice that the `Dense` layer contains 10 *neurons* instead of 1, which is different from the logistic regression lesson (1 neuron). This is because we need to calculate probabilities for 10 classes (digits 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic4-QSbL5u94",
        "colab_type": "code",
        "outputId": "34df1b72-5a93-4b20-8862-0beb370974e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# build the linear model \n",
        "model = keras.Sequential([\n",
        "            layers.Input((train_features.shape[-1],)), # the input layer (corresponds to the features)\n",
        "            layers.Dense(10, activation='softmax'), # the output layer with the softmax function (this layer contains the weights and a bias term)\n",
        "        ], name='softmax_regression_model')\n",
        "\n",
        "print('model summary')\n",
        "print(model.summary())\n",
        "\n",
        "# define the loss function, optimization algorithm, and metrics for the model\n",
        "# and \"glue\" them all together\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model summary\n",
            "Model: \"softmax_regression_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UraXf-5skCxm",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train the model\n",
        "No it's time to train the model. We will train it for 100 *epochs* (iterations) with a *batch size* of 2048 (the number of training examples to evaluate prior to doing gradient descent), and record the training and validation metrics in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKw1OPoRmaXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62e1ddc4-d416-42da-96ba-b6506db1a841"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=epochs, validation_split=0.1,\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3702 - accuracy: 0.8983 - val_loss: 0.3048 - val_accuracy: 0.9190\n",
            "Epoch 2/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3667 - accuracy: 0.8993 - val_loss: 0.3021 - val_accuracy: 0.9200\n",
            "Epoch 3/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8999 - val_loss: 0.2995 - val_accuracy: 0.9205\n",
            "Epoch 4/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3605 - accuracy: 0.9008 - val_loss: 0.2976 - val_accuracy: 0.9207\n",
            "Epoch 5/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3578 - accuracy: 0.9014 - val_loss: 0.2950 - val_accuracy: 0.9208\n",
            "Epoch 6/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3552 - accuracy: 0.9020 - val_loss: 0.2931 - val_accuracy: 0.9212\n",
            "Epoch 7/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.9026 - val_loss: 0.2910 - val_accuracy: 0.9227\n",
            "Epoch 8/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.9032 - val_loss: 0.2894 - val_accuracy: 0.9222\n",
            "Epoch 9/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.9036 - val_loss: 0.2876 - val_accuracy: 0.9228\n",
            "Epoch 10/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.9038 - val_loss: 0.2862 - val_accuracy: 0.9232\n",
            "Epoch 11/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.9044 - val_loss: 0.2847 - val_accuracy: 0.9233\n",
            "Epoch 12/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3426 - accuracy: 0.9048 - val_loss: 0.2834 - val_accuracy: 0.9235\n",
            "Epoch 13/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3409 - accuracy: 0.9052 - val_loss: 0.2820 - val_accuracy: 0.9243\n",
            "Epoch 14/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.9061 - val_loss: 0.2807 - val_accuracy: 0.9248\n",
            "Epoch 15/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.9064 - val_loss: 0.2793 - val_accuracy: 0.9248\n",
            "Epoch 16/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.9069 - val_loss: 0.2782 - val_accuracy: 0.9245\n",
            "Epoch 17/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.9069 - val_loss: 0.2772 - val_accuracy: 0.9257\n",
            "Epoch 18/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.9075 - val_loss: 0.2763 - val_accuracy: 0.9248\n",
            "Epoch 19/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.9080 - val_loss: 0.2752 - val_accuracy: 0.9248\n",
            "Epoch 20/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.9082 - val_loss: 0.2744 - val_accuracy: 0.9255\n",
            "Epoch 21/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.9084 - val_loss: 0.2732 - val_accuracy: 0.9257\n",
            "Epoch 22/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3284 - accuracy: 0.9089 - val_loss: 0.2725 - val_accuracy: 0.9255\n",
            "Epoch 23/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.9091 - val_loss: 0.2717 - val_accuracy: 0.9257\n",
            "Epoch 24/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.9091 - val_loss: 0.2709 - val_accuracy: 0.9252\n",
            "Epoch 25/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.9091 - val_loss: 0.2701 - val_accuracy: 0.9253\n",
            "Epoch 26/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.9099 - val_loss: 0.2692 - val_accuracy: 0.9257\n",
            "Epoch 27/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.9099 - val_loss: 0.2686 - val_accuracy: 0.9258\n",
            "Epoch 28/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3223 - accuracy: 0.9101 - val_loss: 0.2678 - val_accuracy: 0.9262\n",
            "Epoch 29/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.9103 - val_loss: 0.2670 - val_accuracy: 0.9263\n",
            "Epoch 30/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.9106 - val_loss: 0.2664 - val_accuracy: 0.9268\n",
            "Epoch 31/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.9110 - val_loss: 0.2660 - val_accuracy: 0.9268\n",
            "Epoch 32/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.9113 - val_loss: 0.2652 - val_accuracy: 0.9270\n",
            "Epoch 33/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.9117 - val_loss: 0.2645 - val_accuracy: 0.9268\n",
            "Epoch 34/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.9118 - val_loss: 0.2642 - val_accuracy: 0.9267\n",
            "Epoch 35/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.9119 - val_loss: 0.2636 - val_accuracy: 0.9268\n",
            "Epoch 36/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.9120 - val_loss: 0.2628 - val_accuracy: 0.9270\n",
            "Epoch 37/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.9121 - val_loss: 0.2625 - val_accuracy: 0.9280\n",
            "Epoch 38/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.9125 - val_loss: 0.2621 - val_accuracy: 0.9273\n",
            "Epoch 39/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.9126 - val_loss: 0.2614 - val_accuracy: 0.9287\n",
            "Epoch 40/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3129 - accuracy: 0.9128 - val_loss: 0.2609 - val_accuracy: 0.9283\n",
            "Epoch 41/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.9131 - val_loss: 0.2606 - val_accuracy: 0.9278\n",
            "Epoch 42/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.9134 - val_loss: 0.2603 - val_accuracy: 0.9285\n",
            "Epoch 43/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3110 - accuracy: 0.9135 - val_loss: 0.2596 - val_accuracy: 0.9287\n",
            "Epoch 44/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.9136 - val_loss: 0.2592 - val_accuracy: 0.9293\n",
            "Epoch 45/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.9140 - val_loss: 0.2587 - val_accuracy: 0.9297\n",
            "Epoch 46/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.9142 - val_loss: 0.2583 - val_accuracy: 0.9293\n",
            "Epoch 47/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.9140 - val_loss: 0.2579 - val_accuracy: 0.9288\n",
            "Epoch 48/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.9144 - val_loss: 0.2575 - val_accuracy: 0.9295\n",
            "Epoch 49/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.9147 - val_loss: 0.2571 - val_accuracy: 0.9297\n",
            "Epoch 50/50\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.9147 - val_loss: 0.2566 - val_accuracy: 0.9290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQz-BI1kBXx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLbub2CrohPz",
        "colab_type": "code",
        "outputId": "ad6d96b6-8e44-468b-cd73-12e47dc699f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "# create a dataframe to store the history \n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.tail())\n",
        "\n",
        "# visualize the mean squared error over the training process\n",
        "hist.plot.line(x='epoch', y='val_accuracy');"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        loss  accuracy  val_loss  val_accuracy  epoch\n",
            "45  0.309180  0.914185  0.258287      0.929333     45\n",
            "46  0.308598  0.914019  0.257859      0.928833     46\n",
            "47  0.308062  0.914370  0.257513      0.929500     47\n",
            "48  0.307546  0.914667  0.257053      0.929667     48\n",
            "49  0.306998  0.914685  0.256569      0.929000     49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGnpAbVjzhQm",
        "colab_type": "text"
      },
      "source": [
        "As the above plot suggests, our model has not converged to the optimal parameters yet after training for 50 epochs (iterations). This suggests the accuracy may improve with more training (more epochs). Further, the validation accuracy peaks around ~93%.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWuWW0tcvV7_",
        "colab_type": "text"
      },
      "source": [
        "## 5. Evaluate the model\n",
        "Now that we trained our model, it's time to evaluate it using the test dataset, which we did not use when training the model. This gives us a sense of how well our model predicts unseen data, which is the case when we use it in the real world. We will use the `evaluate` method to test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cVnmxZB0h2_",
        "colab_type": "code",
        "outputId": "b3911b8e-3a64-4080-f527-32567d017f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_features, test_labels)\n",
        "print('Test set accuracy: {}%'.format(round(accuracy, 4)*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.9181\n",
            "Test set accuracy: 91.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAUOCBHefcEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "909e342f-4bbf-490a-b915-9fd925d163ca"
      },
      "source": [
        "print('training set distribution of digit classes:', np.sum(train_labels, axis=0))\n",
        "print('test set distribution of digit classes:', np.sum(test_labels, axis=0))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set distribution of digit classes: [5923. 6742. 5958. 6131. 5842. 5421. 5918. 6265. 5851. 5949.]\n",
            "test set distribution of digit classes: [ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92XmHVgW0xLg",
        "colab_type": "text"
      },
      "source": [
        "Wow! Our softmax classifier fit the MNIST digit data pretty well, correctly predicting the unseen handwritten digits around 91% to 92% of the time. Since the dataset is fairly balanced (i.e., the digit classes are close to equally represented), we can be relatively confident that the test set accuracy score provides a good estimate for how the model will perform on similar unseen handwritten digit data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDoNhPh367sZ",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "\n",
        "- We use *one-hot encoding* to represent categorical data.\n",
        "- Softmax regression is probably the popular classification technique and it is a foundational algorithm for classification methods in deep learning (neural networks). \n",
        "- The *softmax* logit function maps the input features to a probability distribution that guarantees the values are nonnegative and sum up to 1.\n",
        "- Softmax regression classifiers try to *maximize the likelihood* of the observed data, like logistic regression.\n",
        "- Categorical *cross-entorpy* is the loss function for softmax regression.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mITAGLVCRsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}