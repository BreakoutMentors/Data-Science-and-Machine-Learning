{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+z/3ON8yd151BXUYlmlwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/machine_learning/lesson%204%20-%20ML%20Apps/Gradio/ML_Object_Recognition_using_Pretrained_Transformers_Gradio_App_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install    \\\n",
        "    'beautifulsoup4==4.9.3' \\\n",
        "    'bs4==0.0.1'    \\\n",
        "    'requests-file==1.5.1'  \\\n",
        "    'torch>=1.10.1'    \\\n",
        "    'transformers==4.26.0'   \\\n",
        "    'validators==0.18.2'    \\\n",
        "    'timm>=0.5.4'   \\\n",
        "    'gradio'\n"
      ],
      "metadata": {
        "id": "Y-aum9DFNXdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zGr2dNjkLdLL"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, validators\n",
        "import torch\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from transformers import AutoFeatureExtractor, DetrForObjectDetection, YolosForObjectDetection\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# colors for visualization\n",
        "COLORS = [\n",
        "    [0.000, 0.447, 0.741],\n",
        "    [0.850, 0.325, 0.098],\n",
        "    [0.929, 0.694, 0.125],\n",
        "    [0.494, 0.184, 0.556],\n",
        "    [0.466, 0.674, 0.188],\n",
        "    [0.301, 0.745, 0.933]\n",
        "]\n",
        "\n",
        "def make_prediction(img, feature_extractor, model):\n",
        "    inputs = feature_extractor(img, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    img_size = torch.tensor([tuple(reversed(img.size))])\n",
        "    processed_outputs = feature_extractor.post_process(outputs, img_size)\n",
        "    return processed_outputs[0]\n",
        "\n",
        "def fig2img(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize_prediction(pil_img, output_dict, threshold=0.7, id2label=None):\n",
        "    keep = output_dict[\"scores\"] > threshold\n",
        "    boxes = output_dict[\"boxes\"][keep].tolist()\n",
        "    scores = output_dict[\"scores\"][keep].tolist()\n",
        "    labels = output_dict[\"labels\"][keep].tolist()\n",
        "    if id2label is not None:\n",
        "        labels = [id2label[x] for x in labels]\n",
        "\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    colors = COLORS * 100\n",
        "    for score, (xmin, ymin, xmax, ymax), label, color in zip(scores, boxes, labels, colors):\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=color, linewidth=3))\n",
        "        ax.text(xmin, ymin, f\"{label}: {score:0.2f}\", fontsize=15, bbox=dict(facecolor=\"yellow\", alpha=0.5))\n",
        "    plt.axis(\"off\")\n",
        "    return fig2img(plt.gcf())\n",
        "\n",
        "\n",
        "def detect_objects(model_name,url_input,image_input,threshold):\n",
        "    \n",
        "    #Extract model and feature extractor\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "    \n",
        "    if 'detr' in model_name:\n",
        "        \n",
        "        model = DetrForObjectDetection.from_pretrained(model_name)\n",
        "        \n",
        "    elif 'yolos' in model_name:\n",
        "    \n",
        "        model = YolosForObjectDetection.from_pretrained(model_name)\n",
        "    \n",
        "    if validators.url(url_input):\n",
        "        image = Image.open(requests.get(url_input, stream=True).raw)\n",
        "        \n",
        "    elif image_input:\n",
        "        image = image_input\n",
        "    \n",
        "    #Make prediction\n",
        "    processed_outputs = make_prediction(image, feature_extractor, model)\n",
        "    \n",
        "    #Visualize prediction\n",
        "    viz_img = visualize_prediction(image, processed_outputs, threshold, model.config.id2label)\n",
        "    \n",
        "    return viz_img   \n",
        "        \n",
        "def set_example_image(example: list) -> dict:\n",
        "    return gr.Image.update(value=example[0])\n",
        "\n",
        "def set_example_url(example: list) -> dict:\n",
        "    return gr.Textbox.update(value=example[0])\n"
      ],
      "metadata": {
        "id": "RDmSGINRMG_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"\"\"<h1 id=\"title\">Object Detection App with DETR and YOLOS</h1>\"\"\"\n",
        "\n",
        "description = \"\"\"\n",
        "Links to HuggingFace Models:\n",
        "- [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)  \n",
        "- [hustvl/yolos-small](https://huggingface.co/hustvl/yolos-small)\n",
        "- [hustvl/yolos-tiny](https://huggingface.co/hustvl/yolos-tiny)\n",
        "\"\"\"\n",
        "\n",
        "models = [\"facebook/detr-resnet-50\",'hustvl/yolos-small','hustvl/yolos-tiny']\n",
        "urls = [\"https://c8.alamy.com/comp/J2AB4K/the-new-york-stock-exchange-on-the-wall-street-in-new-york-J2AB4K.jpg\"]\n",
        "\n",
        "twitter_link = \"\"\"\n",
        "[![](https://img.shields.io/twitter/follow/kaithedataguy?label=@kaithedataguy&style=social)](https://twitter.com/kaithedataguy)\n",
        "\"\"\"\n",
        "\n",
        "css = '''\n",
        "h1#title {\n",
        "  text-align: center;\n",
        "}\n",
        "'''\n",
        "demo = gr.Blocks(css=css)\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(title)\n",
        "    gr.Markdown(description)\n",
        "    gr.Markdown(twitter_link)\n",
        "    options = gr.Dropdown(choices=models, label='Select Object Detection Model', show_label=True)\n",
        "    slider_input = gr.Slider(minimum=0.2, maximum=1, value=0.7, label='Prediction Threshold')\n",
        "    \n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem('Image URL'):\n",
        "            with gr.Row():\n",
        "                url_input = gr.Textbox(lines=2,label='Enter valid image URL here..')\n",
        "                img_output_from_url = gr.Image(shape=(650,650))\n",
        "                \n",
        "            with gr.Row():\n",
        "                example_url = gr.Dataset(components=[url_input],samples=[[str(url)] for url in urls])\n",
        "            \n",
        "            url_but = gr.Button('Detect')\n",
        "     \n",
        "        with gr.TabItem('Image Upload'):\n",
        "            with gr.Row():\n",
        "                img_input = gr.Image(type='pil')\n",
        "                img_output_from_upload= gr.Image(shape=(650,650))\n",
        "                \n",
        "            with gr.Row(): \n",
        "                example_images = gr.Dataset(components=[img_input],\n",
        "                                            samples=[[path.as_posix()]\n",
        "                                                 for path in sorted(pathlib.Path('images').rglob('*.JPG'))])\n",
        "            img_but = gr.Button('Detect')\n",
        "\n",
        "        with gr.TabItem('Webcam'):\n",
        "            with gr.Row():\n",
        "                web_input = gr.Image(source='webcam', type='pil')\n",
        "                img_output_from_web = gr.Image(shape=(650,650))\n",
        "                \n",
        "            web_but = gr.Button('Detect')\n",
        "        \n",
        "    \n",
        "    url_but.click(detect_objects, inputs=[options, url_input, img_input, slider_input], outputs=img_output_from_url, queue=True)\n",
        "    img_but.click(detect_objects, inputs=[options, url_input, img_input, slider_input], outputs=img_output_from_upload, queue=True)\n",
        "    web_but.click(detect_objects, inputs=[options,url_input, web_input, slider_input], outputs=img_output_from_web, queue=True)\n",
        "    example_images.click(fn=set_example_image, inputs=[example_images], outputs=[img_input])\n",
        "    example_url.click(fn=set_example_url,inputs=[example_url], outputs=[url_input])\n",
        "    \n",
        "demo.launch(enable_queue=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "e86priSQQbBB",
        "outputId": "b345cfe2-1a7c-4172-b776-60e85cff7142"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://94daa643-dd89-4ca8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://94daa643-dd89-4ca8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_O0H9fIRmbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}