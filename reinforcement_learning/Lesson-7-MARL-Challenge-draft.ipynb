{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2t5fQZX6zKQ",
        "outputId": "fe20b758-858f-479e-dbb1-cdef3c3c50d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function ProcConcatVec.__del__ at 0x7d24a535fbe0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/supersuit/vector/multiproc_vec.py\", line 224, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/supersuit/vector/multiproc_vec.py\", line 239, in close\n",
            "    for pipe, proc in zip(self.pipes, self.procs):\n",
            "AttributeError: 'ProcConcatVec' object has no attribute 'pipes'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pettingzoo[classic]==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (1.23.5)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (0.28.1)\n",
            "Requirement already satisfied: chess==1.7.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (1.7.0)\n",
            "Requirement already satisfied: rlcard==1.0.5 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (1.0.5)\n",
            "Requirement already satisfied: pygame==2.3.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (2.3.0)\n",
            "Requirement already satisfied: hanabi-learning-environment==0.0.4 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[classic]==1.23.1) (0.0.4)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from hanabi-learning-environment==0.0.4->pettingzoo[classic]==1.23.1) (1.15.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from rlcard==1.0.5->pettingzoo[classic]==1.23.1) (2.3.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[classic]==1.23.1) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[classic]==1.23.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[classic]==1.23.1) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo[classic]==1.23.1) (0.0.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->hanabi-learning-environment==0.0.4->pettingzoo[classic]==1.23.1) (2.21)\n",
            "Requirement already satisfied: stable_baselines3==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable_baselines3==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable_baselines3==2.0.0) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable_baselines3==2.0.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable_baselines3==2.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable_baselines3==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable_baselines3==2.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable_baselines3==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable_baselines3==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable_baselines3==2.0.0) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable_baselines3==2.0.0) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3==2.0.0) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3==2.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable_baselines3==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable_baselines3==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: supersuit==3.9.0 in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from supersuit==3.9.0) (1.23.5)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from supersuit==3.9.0) (0.28.1)\n",
            "Requirement already satisfied: tinyscaler>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from supersuit==3.9.0) (1.2.6)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.0) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.0) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit==3.9.0) (0.0.4)\n",
            "Collecting sb3-contrib==2.0.0\n",
            "  Using cached sb3_contrib-2.0.0-py3-none-any.whl (80 kB)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sb3-contrib==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib==2.0.0) (1.3.0)\n",
            "Installing collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pettingzoo[classic]==1.23.1\n",
        "!pip install stable_baselines3==2.0.0\n",
        "!pip install supersuit==3.9.0\n",
        "!pip install sb3-contrib==2.0.0\n",
        "## Make sure to restart runtime for these packages to work!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huUnPCHg7Egb",
        "outputId": "33bba841-e526-4115-bc91-74f78e2818cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Surface(640x480x32 SW)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "import pygame\n",
        "pygame.display.set_mode((640,480))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpgW1hkh_s-M"
      },
      "source": [
        "If you recall from the previous lesson (Deep Q-learning), we were using the DQN to find the optimal path to the maze and we saw it performs really bad. That has a lot to do with the fact that a maze, unlike the most RL environment that you have seen so far, has constraints. Such as when the agent is in a certain state, some of the actions cannot be perform.\n",
        "\n",
        "[Maskable PPO](https://arxiv.org/abs/2006.14171) is one of the algorithm to tackle this type of constrained RL problem by only select the valid actions during training using an action mask.\n",
        "\n",
        "Below is the code for training 2 agents to play [Connect Four](https://pettingzoo.farama.org/environments/classic/connect_four/) using [Maskable PPO](https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html) from SB3. Feel free to look at the code and play with it (train and evaluate) !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxsimQfd9_Y6",
        "outputId": "affd0f5f-61f4-45c7-eaac-150fc48a230b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training on connect_four_v3.\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 21.7     |\n",
            "|    ep_rew_mean     | 1        |\n",
            "| time/              |          |\n",
            "|    fps             | 447      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "Model has been saved.\n",
            "Finished training on connect_four_v3.\n",
            "\n",
            "Starting evaluation vs a random agent. Trained agent will play as player_1.\n",
            "Rewards by round:  [{'player_0': 1, 'player_1': -1}]\n",
            "Total rewards (incl. negative rewards):  {'player_0': 1, 'player_1': -1}\n",
            "Winrate:  0.0\n",
            "Final scores:  {'player_0': 1, 'player_1': 0}\n",
            "Starting evaluation vs a random agent. Trained agent will play as player_1.\n",
            "Rewards by round:  [{'player_0': 1, 'player_1': -1}, {'player_0': -1, 'player_1': 1}]\n",
            "Total rewards (incl. negative rewards):  {'player_0': 0, 'player_1': 0}\n",
            "Winrate:  0.5\n",
            "Final scores:  {'player_0': 1, 'player_1': 1}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Uses Stable-Baselines3 to train agents in the Connect Four environment using invalid action masking.\n",
        "\n",
        "For information about invalid action masking in PettingZoo, see https://pettingzoo.farama.org/api/aec/#action-masking\n",
        "For more information about invalid action masking in SB3, see https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html\n",
        "\n",
        "Author: Elliot (https://github.com/elliottower)\n",
        "\"\"\"\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "\n",
        "from sb3_contrib import MaskablePPO\n",
        "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
        "from sb3_contrib.common.wrappers import ActionMasker\n",
        "\n",
        "import pettingzoo.utils\n",
        "from pettingzoo.classic import connect_four_v3\n",
        "\n",
        "\n",
        "class SB3ActionMaskWrapper(pettingzoo.utils.BaseWrapper):\n",
        "    \"\"\"Wrapper to allow PettingZoo environments to be used with SB3 illegal action masking.\"\"\"\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"Gymnasium-like reset function which assigns obs/action spaces to be the same for each agent.\n",
        "\n",
        "        This is required as SB3 is designed for single-agent RL and doesn't expect obs/action spaces to be functions\n",
        "        \"\"\"\n",
        "        super().reset(seed, options)\n",
        "\n",
        "        # Strip the action mask out from the observation space\n",
        "        self.observation_space = super().observation_space(self.possible_agents[0])[\n",
        "            \"observation\"\n",
        "        ]\n",
        "        self.action_space = super().action_space(self.possible_agents[0])\n",
        "\n",
        "        # Return initial observation, info (PettingZoo AEC envs do not by default)\n",
        "        return self.observe(self.agent_selection), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Gymnasium-like step function, returning observation, reward, termination, truncation, info.\"\"\"\n",
        "        super().step(action)\n",
        "        return super().last()\n",
        "\n",
        "    def observe(self, agent):\n",
        "        \"\"\"Return only raw observation, removing action mask.\"\"\"\n",
        "        return super().observe(agent)[\"observation\"]\n",
        "\n",
        "    def action_mask(self):\n",
        "        \"\"\"Separate function used in order to access the action mask.\"\"\"\n",
        "        return super().observe(self.agent_selection)[\"action_mask\"]\n",
        "\n",
        "\n",
        "def mask_fn(env):\n",
        "    # Do whatever you'd like in this function to return the action mask\n",
        "    # for the current env. In this example, we assume the env has a\n",
        "    # helpful method we can rely on.\n",
        "    return env.action_mask()\n",
        "\n",
        "\n",
        "def train_action_mask(env_fn, steps=10_000, seed=0, **env_kwargs):\n",
        "    \"\"\"Train a single model to play as each agent in a zero-sum game environment using invalid action masking.\"\"\"\n",
        "    env = env_fn.env(**env_kwargs)\n",
        "\n",
        "    print(f\"Starting training on {str(env.metadata['name'])}.\")\n",
        "\n",
        "    # Custom wrapper to convert PettingZoo envs to work with SB3 action masking\n",
        "    env = SB3ActionMaskWrapper(env)\n",
        "\n",
        "    env.reset(seed=seed)  # Must call reset() in order to re-define the spaces\n",
        "\n",
        "    env = ActionMasker(env, mask_fn)  # Wrap to enable masking (SB3 function)\n",
        "    # MaskablePPO behaves the same as SB3's PPO unless the env is wrapped\n",
        "    # with ActionMasker. If the wrapper is detected, the masks are automatically\n",
        "    # retrieved and used when learning. Note that MaskablePPO does not accept\n",
        "    # a new action_mask_fn kwarg, as it did in an earlier draft.\n",
        "    model = MaskablePPO(MaskableActorCriticPolicy, env, verbose=1)\n",
        "    model.set_random_seed(seed)\n",
        "    model.learn(total_timesteps=steps)\n",
        "\n",
        "    model.save(f\"{env.unwrapped.metadata.get('name')}_{time.strftime('%Y%m%d-%H%M%S')}\")\n",
        "\n",
        "    print(\"Model has been saved.\")\n",
        "\n",
        "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\\n\")\n",
        "\n",
        "    env.close()\n",
        "\n",
        "\n",
        "def eval_action_mask(env_fn, num_games=100, render_mode=None, **env_kwargs):\n",
        "    # Evaluate a trained agent vs a random agent\n",
        "    env = env_fn.env(render_mode=render_mode, **env_kwargs)\n",
        "\n",
        "    print(\n",
        "        f\"Starting evaluation vs a random agent. Trained agent will play as {env.possible_agents[1]}.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        latest_policy = max(\n",
        "            glob.glob(f\"{env.metadata['name']}*.zip\"), key=os.path.getctime\n",
        "        )\n",
        "    except ValueError:\n",
        "        print(\"Policy not found.\")\n",
        "        exit(0)\n",
        "\n",
        "    model = MaskablePPO.load(latest_policy)\n",
        "\n",
        "    scores = {agent: 0 for agent in env.possible_agents}\n",
        "    total_rewards = {agent: 0 for agent in env.possible_agents}\n",
        "    round_rewards = []\n",
        "\n",
        "    for i in range(num_games):\n",
        "        env.reset(seed=i)\n",
        "        env.action_space(env.possible_agents[0]).seed(i)\n",
        "\n",
        "        for agent in env.agent_iter():\n",
        "            obs, reward, termination, truncation, info = env.last()\n",
        "\n",
        "            # Separate observation and action mask\n",
        "            observation, action_mask = obs.values()\n",
        "\n",
        "            if termination or truncation:\n",
        "                # If there is a winner, keep track, otherwise don't change the scores (tie)\n",
        "                if (\n",
        "                    env.rewards[env.possible_agents[0]]\n",
        "                    != env.rewards[env.possible_agents[1]]\n",
        "                ):\n",
        "                    winner = max(env.rewards, key=env.rewards.get)\n",
        "                    scores[winner] += env.rewards[\n",
        "                        winner\n",
        "                    ]  # only tracks the largest reward (winner of game)\n",
        "                # Also track negative and positive rewards (penalizes illegal moves)\n",
        "                for a in env.possible_agents:\n",
        "                    total_rewards[a] += env.rewards[a]\n",
        "                # List of rewards by round, for reference\n",
        "                round_rewards.append(env.rewards)\n",
        "                break\n",
        "            else:\n",
        "                if agent == env.possible_agents[0]:\n",
        "                    act = env.action_space(agent).sample(action_mask)\n",
        "                else:\n",
        "                    # Note: PettingZoo expects integer actions # TODO: change chess to cast actions to type int?\n",
        "                    act = int(\n",
        "                        model.predict(\n",
        "                            observation, action_masks=action_mask, deterministic=True\n",
        "                        )[0]\n",
        "                    )\n",
        "            env.step(act)\n",
        "    env.close()\n",
        "\n",
        "    # Avoid dividing by zero\n",
        "    if sum(scores.values()) == 0:\n",
        "        winrate = 0\n",
        "    else:\n",
        "        winrate = scores[env.possible_agents[1]] / sum(scores.values())\n",
        "    print(\"Rewards by round: \", round_rewards)\n",
        "    print(\"Total rewards (incl. negative rewards): \", total_rewards)\n",
        "    print(\"Winrate: \", winrate)\n",
        "    print(\"Final scores: \", scores)\n",
        "    return round_rewards, total_rewards, winrate, scores\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env_fn = connect_four_v3\n",
        "\n",
        "    env_kwargs = {}\n",
        "\n",
        "    # Evaluation/training hyperparameter notes:\n",
        "    # 10k steps: Winrate:  0.76, loss order of 1e-03\n",
        "    # 20k steps: Winrate:  0.86, loss order of 1e-04\n",
        "    # 40k steps: Winrate:  0.86, loss order of 7e-06\n",
        "\n",
        "    # Train a model against itself (takes ~20 seconds on a laptop CPU)\n",
        "    train_action_mask(env_fn, steps=1000, seed=0, **env_kwargs)\n",
        "\n",
        "    # Evaluate 100 games against a random agent (winrate should be ~80%)\n",
        "    eval_action_mask(env_fn, num_games=1, render_mode=None, **env_kwargs)\n",
        "\n",
        "    # Watch two games vs a random agent\n",
        "    eval_action_mask(env_fn, num_games=2, render_mode=\"human\", **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf9LdmZF-yGa"
      },
      "source": [
        "### Mentor-Guided Challenge\n",
        "\n",
        "Since this is the challenge for the last lesson, we are going to try something different. Look at the [Atari MARL environment](https://pettingzoo.farama.org/environments/atari/) and the [SB3](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html) algorithms. Pick 1 environment and 1 algorithm of your choice to train a RL agent! Have fun!\n",
        "\n",
        "**Note**: For some environment, you might have to install certain dependencies for pettingzoo. For example, for the *Atari* environment, we did something like\n",
        "> !pip install pettingzoo[atari]==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26VDdv9v_ULe"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
