{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preparing image data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0tXCSXY37WruX2jWesoCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krmiddlebrook/intro_to_deep_learning/blob/master/machine_learning/mini_lessons/image_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwNWWpWzwuOI",
        "colab_type": "text"
      },
      "source": [
        "# Processing Image Data\n",
        "Computer vision is a field of machine learning that trains computers to interpret and understand the visual world. It is one of the most popular fields in deep learning (neural networks). In computer vision, it is common to use digital images from cameras and videos to train models to accurately identify and classify objects. \n",
        "\n",
        "Before we can solve computer vision tasks, it is important to understand how to handle  image data. To this end, we will demonstrate how to process (prepare) image data for machine learning models. \n",
        "\n",
        "We will use the MNIST digits dataset, which is provided by Kera Datasets--a collection of ready-to-use datasets for machine learning. All datasets are available through the `tf.keras.datasets` API endpoint. \n",
        "\n",
        "Here is the lesson roadmap:\n",
        "- Load the dataset\n",
        "- Visualize the data\n",
        "- Transform the data\n",
        "- Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXbAivcw2Csr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras and TensorFlow datasets\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8tRQe3hz0Xz",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset\n",
        "When we want to solve a problem with machine learning methods, the first step is almost always to find a good dataset. As we mentioned above, we will retrieve the MNIST dataset using the `tf.keras.datasets` module. \n",
        "\n",
        "The MNIST dataset contains 70k grayscale images of handwritten digits (i.e., numbers between 0 and 9). Let's load the dataset into our notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNn7bJffwtK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "69cea2aa-06f9-4403-df9b-71ad9d20f379"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f\"training set shape: {train_features.shape}\")\n",
        "print(f\"test set shape: {test_features.shape}\")\n",
        "\n",
        "print(f'dtypes of training and test set tensors: {train_features.dtype}, {test_features.dtype}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set shape: (60000, 28, 28)\n",
            "test set shape: (10000, 28, 28)\n",
            "dtypes of training and test set tensors: uint8, uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXDAMmyl2DJn",
        "colab_type": "text"
      },
      "source": [
        "We see that TensorFlow Datasets takes care of most of the processing we need to do. The `training_features` object tells us that there are 60k training images, and the `test_features` indicates there are 10k test images, so 70k total. We also see that the images are tensors of shape ($28 \\times 28$) with integers of type uint8.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2fMQh96Qq9M",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the dataset\n",
        "Now that we have the dataset, let's visualize some samples.\n",
        "\n",
        "We will use the matplotlib plotting framework to display the images. Here are the first 5 images in the training dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkc-9fzo2nHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "04c66697-5eba-4798-925a-b9745a7989b4"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(5):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(train_features[i], cmap=plt.cm.binary)\n",
        "    plt.title(int(train_labels[i]))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaTo-0HeRgL3",
        "colab_type": "text"
      },
      "source": [
        "The above images give us a sense of the data, including samples belonging to different classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7yBnog9R3z1",
        "colab_type": "text"
      },
      "source": [
        "# Transforming the data\n",
        "Before we start transforming data, let's discuss *tensors*--a key part of the machine learning (ML) process, particularly for deep learning methods. \n",
        "\n",
        "As we learned in previous lessons, data, whether it be categorical or numerical in nature, is converted to a numerical representation. This process makes the data useful for machine learning models. In deep learning (neural networks), the numerical data is often stored in objects called *tensors*. A tensor is a container that can house data in $N$ dimensions. ML researchers sometimes use the term \"tensor\" and \"matrix\" interchangeably because a matrix is a 2-dimensional tensor. But, tensors are generalizations of matrices to $N$-dimensional space. \n",
        "\n",
        "<figure>\n",
        "  <img src='https://www.kdnuggets.com/wp-content/uploads/scalar-vector-matrix-tensor.jpg' width='75%'>\n",
        "  <figcaption>A scalar, vector ($2 \\times 1$), matrix ($2 \\times 1$), and tensor ($2 \\times 2 \\times 2$) .</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5H-RbwYkRvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e5675d5-591c-48c7-a186-eb0380948e24"
      },
      "source": [
        "# a (2 x 2 x 2) tensor\n",
        "my_tensor = np.array([\n",
        "              [[1, 2], [3, 2]],\n",
        "              [[1, 7],[5, 4]]\n",
        "            ])\n",
        "\n",
        "print('my_tensor shape:', my_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_tensor shape: (2, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVDaFLJekQOx",
        "colab_type": "text"
      },
      "source": [
        "Now let's discuss how images are stored in tensors. Computer screens are composed of pixels. Each pixel generates three colors of light (red, green, and blue) and the different colors we see are due to different combinations and intensities of these three primary colors.   \n",
        "\n",
        "<figure>\n",
        "  <img src='https://www.chem.purdue.edu/gchelp/cchem/RGBColors/BlackWhiteGray.gif' width='75%'>\n",
        "  <figcaption>The colors black, white, and gray with a sketch of a pixel from each.</figcaption>\n",
        "</figure>\n",
        "\n",
        "We use tensors to store the pixel intensities for a given image. Colorized pictures have 3 different *channels*. Each channel contains a matrix that represents the intensity values that correspond to the pixels of a particular color (red, green, and blue; RGB for short). For instance, consider a small colorized $28 \\times 28$ pixel image of a dog. Because the dog image is colorize, it has 3 channels, so its tensor shape is ($28 \\times 28 \\times 3$).\n",
        "\n",
        "Let's have a look at the shape of the images in the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSiz9BYuP5A9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81c21ee9-cb47-4a9b-9d11-9b89e328bab8"
      },
      "source": [
        "train_features[0, :, :].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJQb1gXjXJVf",
        "colab_type": "text"
      },
      "source": [
        "Using the `train_features.shape` method, we can extract the image shape and see that images are in the tensor shape $28 \\times 28$. The returned shape has no 3rd dimension, this indicates that we are working with grayscale images. By grayscale, we mean the pixels don't have intensities for red, green, and blue channels but rather for one grayscale channel, which describes an image using combinations of various shades of gray. Pixel intensities range between $0$ and $255$, and in our case, they correspond to black $0$ to white $255$.  \n",
        "\n",
        "\n",
        "Now let's reshape the images into $784 \\times 1$ dimensional tensors. We call converting an image into an $n \\times 1$ tensor \"flattening\" the tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biPfqtMUUrvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c4c961d-0d5e-430d-9e92-e2cb0fc4b504"
      },
      "source": [
        "# get a subset of 5 images from the dataset\n",
        "original_shape = train_features.shape\n",
        "\n",
        "# Flatten the images.\n",
        "input_shape = (-1, 28*28)\n",
        "train_features = train_features.reshape(input_shape)\n",
        "test_features = test_features.reshape(input_shape) \n",
        "\n",
        "print(f'original shape: {original_shape}, flattened shape: {train_features.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original shape: (60000, 28, 28), flattened shape: (60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifFQTBlODdkw",
        "colab_type": "text"
      },
      "source": [
        "We flattened all the images by using the NumPy `reshape` method. Since one shape dimension can be -1, and we may not always know the number of samples in the dataset we used $(-1,784)$ as the parameters to `reshape`. In our example, this means that each $28 \\times 28$ image gets flattened into a $28 \\cdot 28 = 784$ feature array. Then the images are stacked (because of the -1) to produce a final large tensor with shape $(\\text{num samples}, 784$).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bApbf2QMNnY",
        "colab_type": "text"
      },
      "source": [
        "# Normalize the data\n",
        "Another important transformation technique is *normalization*.  We normalize data before training the model with it to encourage the model to learn generalizable features, which should lead to better results on unseen data. \n",
        "\n",
        "At a high level, normalization makes the data more, well...normal. There are various ways to normalize data. Perhaps the most common normalization approach for image data is to subtract the mean pixel value and divide by the standard deviation (this method is applied to every pixel).\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2jJsyS9D7W",
        "colab_type": "text"
      },
      "source": [
        "Before we can do any normalization, we have to cast the \"uint8\" tensors to the \"float32\" numeric type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzbWgbJu9DCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to float32 type \n",
        "train_features = train_features.astype('float32')\n",
        "test_features = test_features.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlTSmJZW9Nx1",
        "colab_type": "text"
      },
      "source": [
        "Now we can normalize the data. We should mention that you always use the training set data to calculate normalization statistics like mean, standard deviation, etc.. Consequently, the test set is always normalized with the training set statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqypdC9Kd_Xy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "73a73382-403e-4e61-a01e-87bb306db21c"
      },
      "source": [
        "# normalize the reshaped images\n",
        "mean = train_features.mean()\n",
        "std = train_features.std()\n",
        "\n",
        "train_features -= mean\n",
        "train_features /= std\n",
        "\n",
        "test_features -= mean\n",
        "test_features /= std\n",
        "\n",
        "print(f'pre-normalization mean and std: {round(mean, 4)}, {round(std, 4)}')\n",
        "print(f'normalized images mean and std: {round(train_features.mean(), 4)}, {round(train_features.std(), 4)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pre-normalization mean and std: 33.31840133666992, 78.56739807128906\n",
            "normalized images mean and std: -0.0, 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQibn2RQL452",
        "colab_type": "text"
      },
      "source": [
        "As the output above indicates, the normalized pixel values are now centered around 0 (i.e., mean = 0) and have a standard deviation of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQsBVuRfMroF",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "In this lesson we learned:\n",
        "- Keras offers ready-to-use datasets.\n",
        "- Images are represented by *tensors*\n",
        "- Tensors can be transformed (reshaped) and normalized easily using NumPy (or any other frameworks that enable tensor operations).\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtX-_iFu_FTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}