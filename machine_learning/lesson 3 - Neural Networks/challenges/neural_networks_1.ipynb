{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-networks-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJzqJPDpI+gSxFf5nQ2K8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/master/machine_learning/lesson%203%20-%20Neural%20Networks/challenges/neural_networks_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5tjTDNmgWup",
        "colab_type": "text"
      },
      "source": [
        "# Feed Forward Neural Network with Fashion-MNIST\n",
        "The goal in this challenge is to build a feed forward neural network (like the one shown in [intro to neural networks](https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/master/machine_learning/lesson%203%20-%20Neural%20Networks/Intro_to_Neural_Networks.ipynb#scrollTo=RRgYYTTyiI1_) to recognize 10 different fashion classes from the Fashion-MNIST image dataset. The classes are: t-shirt/top, trouser, pullover, dress, coat, sandal, shirt, sneaker, bag, ankle boot. Also, the classes are mutually exclusive. \n",
        "\n",
        "Use Tensorflow to build, train, and evaluate the model.\n",
        "\n",
        "Challenges:\n",
        "1. For simplicity, we load the dataset, but you will need to prepare it for the model.\n",
        "2. Build the model.\n",
        "3. Train the model.\n",
        "4. Evaluate the model.\n",
        "5. Draw conclusions. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foMBp5MTfHNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the libraries we need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow, TensorFlow Datasets, and tf.keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wV0KajHi32V",
        "colab_type": "text"
      },
      "source": [
        "We load the Fashion-MNIST dataset below using the `keras.datasets` Keras API endpoint. The dataset contains 60k $28x28$ grayscale images of 10 fashion categories, along with a test set of 10k images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMgnB6CEjKKY",
        "colab_type": "code",
        "outputId": "f5275048-ceb7-4308-f6e0-096679ab7823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# load the training/test features and labels datasets\n",
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(f\"training set shape: {train_features.shape}\")\n",
        "print(f\"test set shape: {test_features.shape}\")\n",
        "\n",
        "print(f'dtypes of training and test set tensors: {train_features.dtype}, {test_features.dtype}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set shape: (60000, 28, 28)\n",
            "test set shape: (10000, 28, 28)\n",
            "dtypes of training and test set tensors: uint8, uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci-Ml4fkjx6w",
        "colab_type": "text"
      },
      "source": [
        "We see that TensorFlow Datasets takes care of most of the processing we need to do. The `cifar_info` object tells us that there are 50k training images and 10k test images, so 60k total images. We also see that the images are tensors of shape ($32 \\times 32 \\times 3$) with integers of type uint8.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-X1Z9dTANK",
        "colab_type": "text"
      },
      "source": [
        "# 1. Prepare the data \n",
        "Now you will need to prepare the training/test datasets for the model.  \n",
        "Hints: \n",
        "- Convert the features to the \"float32\" dtype. \n",
        "- Normalize the features ($\\mathbf{x}$) by substracting the mean and dividing by the standard deviation of the pixel values. \n",
        "- Reshape the features into $784 \\times 1$ tensors.\n",
        "- One-hot encode the labels ($y$). You will probably want to use the `keras.utils.to_categorical` function to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAjCB4CrggwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5bO4KyxSoy3",
        "colab_type": "text"
      },
      "source": [
        "# 2. Build your model\n",
        "Build a model to model the relationship between the features $x$ (multiple features) and labels $y$ (Type 1).\n",
        "\n",
        "\n",
        "Hints:\n",
        "- Use the `Sequential` class to define a container for the layers of your model.\n",
        "- Construct 2 hidden layers using the `layers.Dense` function. Each hidden layer should have  16 neurons and use the sigmoid activation\n",
        "- Construct the final layer with the proper number of neurons and the correct activation function.\n",
        "- define your loss function with the `CategoricalCrossEntropy` class from Keras\n",
        "- configure the optimization algorithm with stochastic gradient descent\n",
        "- track the accuracy metric\n",
        "- glue the model, loss function, optimizer, and metrics together  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgNpVNPylBo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n",
        "model = keras.Sequential([\n",
        "        \n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxXkdszdaWOx",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train your model\n",
        "Now that you have a model, it's time to train it. Train your model for 100 epochs (i.e., iterations), and record the training and validation metrics in the history object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ixliHPbBOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jIPMBcCbQHh",
        "colab_type": "text"
      },
      "source": [
        "Visualize the accuracy metric over the training process. Hint: create a line chart with the epoch (x) and the accuracy (y).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnAzMXGIcID_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JYygMTpbJ7y",
        "colab_type": "text"
      },
      "source": [
        "# 4. Evaluate the model\n",
        "Now that the model is trained, it's time to evaluate it using the test dataset, which you did not use when training the model. This gives you a sense of how well the model predicts unseen data, which is the case when you use it in the real world. Make sure to evaluate the model and visualize it's predictions against the true values. \n",
        "\n",
        "Hints: \n",
        "- use the `evaluate` method to test the model\n",
        "- use the `predict` method to make predictions given test features. \n",
        "- visualize the predictions against the real  labels using matplotlib's pyplot API methods like `scatter` and `plot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz5dKGh2d38y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN1XYgl-d-be",
        "colab_type": "text"
      },
      "source": [
        "# 5. Draw conclusions\n",
        "Write up your conclusions about the model. Report the goal, the model design, and the results. Make sure to contextualize the model results as best you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocjwpN6aesnH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}