{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/reinforcement_learning/Lesson-1-challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPTU5EryHcHm"
      },
      "source": [
        "> # MAKE SURE YOU RUN ON **GPU**!!!: *Select* **Runtime** -> **Change Runtime Type** -> *Select* **GPU** as your hardware acclerator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZFivpDTGgjd"
      },
      "source": [
        "In this challenge, you will be introduce to the 2 popular RL packages!!! They are (drum roll, please) [**Stable Baseline3**](https://stable-baselines3.readthedocs.io/en/master/)  and [**Gymnasium**](https://gymnasium.farama.org/) !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDt3tac1H0jf"
      },
      "outputs": [],
      "source": [
        "# Load the necessary libraries\n",
        "!pip install swig cmake\n",
        "!pip install stable-baselines3==2.0.0 gymnasium[box2d]==0.28.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51mioSlllbGI"
      },
      "source": [
        "![CartPole](https://gymnasium.farama.org/_images/cart_pole.gif)\n",
        "\n",
        "We will train an agent to control this cart pole and make it **balance**!!!\n",
        "\n",
        "Go to [here](https://gymnasium.farama.org/environments/classic_control/cart_pole/) for a detail reference of the environment (action space, observation space ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F7jIzBqm9ix"
      },
      "source": [
        "## Let's begin!!!\n",
        "---\n",
        "In doing this challenge, the **documentation** for the packages and **Google search** will be really helpful!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr_pPfU1pgHp"
      },
      "source": [
        "### Define the environment (**Question 1.8**)\n",
        "\n",
        "---\n",
        "\n",
        "We are going to use the \"CartPole-v1\" environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNryvAsyoHvQ"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g7uhNiXqT4h"
      },
      "source": [
        "### Take a look at the **action space**, **observation space** and **reward range**. What does these terms mean in this game? (**Question 1.9**)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcJZ33hTrbTw"
      },
      "outputs": [],
      "source": [
        "action_space, observation_space, reward_range = #TODO\n",
        "action_space, observation_space, reward_range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqiaiZhQwQ8g"
      },
      "source": [
        "### So how do we **reset** the environment to the *initial state* and take a *random* action? (**Question 1.10**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZvspd0Ewfto"
      },
      "outputs": [],
      "source": [
        "observation, info = #TODO\n",
        "action = #TODO\n",
        "observation, reward, terminated, truncated, info = #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNNw6dnyMjoV"
      },
      "source": [
        "### Let's put what you learn above together and take **random** action in the environment until the game is over! (**Question 1.11**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-cOUkJlNBG5"
      },
      "outputs": [],
      "source": [
        "# Create the CartPole environment\n",
        "env = #TODO\n",
        "\n",
        "# Reset the environment\n",
        "observation, info = #TODO\n",
        "\n",
        "# Take a random action\n",
        "action = #TODO\n",
        "print(\"Action taken:\", action)\n",
        "\n",
        "observation, reward, terminated, truncated, info = #TODO\n",
        "\n",
        "while(not terminated or not truncated):\n",
        "  action = #TODO\n",
        "  print(\"Action taken:\", action)\n",
        "  observation, reward, terminated, truncated, info = #TODO\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcWPi9IaPfd-"
      },
      "source": [
        "### It is time to create our RL agent! (**Question 1.12**)\n",
        "\n",
        "---\n",
        "\n",
        "We will use the PPO algorithm to train our agent. If you don't know what is PPO, that is fine, this challenge is aim to let you familiarize with how these RL tool works!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52hPQeROPiP6"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "# Create the CartPole environment\n",
        "env = #TODO\n",
        "\n",
        "# Instantiate the agent\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the agent for 5 timesteps\n",
        "  #TODO\n",
        "\n",
        "# Save the trained agent\n",
        "  #TODO\n",
        "\n",
        "# delete the model from memory\n",
        "  #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUUmj5xeQkXd"
      },
      "source": [
        "Hint: Check [this](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AGdo3-E9F70"
      },
      "source": [
        "### It is time to look at our agent in action (pun intended) !! (**Question 1.13**)\n",
        "---\n",
        "Thanks to [this](https://gist.github.com/soroushmehr/74b3777ef330397ec57e5076558183d6)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9SOygy59KxN"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "model = #TODO load the model\n",
        "\n",
        "# Create the CartPole environment\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "obs = #TODO # reset the environment\n",
        "\n",
        "img = plt.imshow(env.render()) # only call this once\n",
        "\n",
        "while True:\n",
        "\n",
        "  img.set_data(env.render()) # just update the data\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "\n",
        "  action, _states = #TODO predict the action and state using the model\n",
        "  obs, rewards, terminated, info, _ = #TODO take the predicted action\n",
        "\n",
        "  if terminated:\n",
        "    break\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN5RAzg3Dyvl"
      },
      "source": [
        "### Now you know how to **train an agent** and visualize its performance!\n",
        "\n",
        "___\n",
        "\n",
        "For extra practice, find a [environment](https://gymnasium.farama.org/environments/classic_control/) that interests you and train an agent that use one of these [algorithms](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html). Keep in mind that not *all* of the *algorithm* work for *all* the *environment*!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4RsJvqCEgaM"
      },
      "outputs": [],
      "source": [
        "### YOU TRY!!!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CBhBZgKbpu2Q",
        "GZyd4wIdrmiZ",
        "SErEch1ZxNFC",
        "8VK9tntCNDKk",
        "knE1IiZsQWU9",
        "KObdsB4z9pTE"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}