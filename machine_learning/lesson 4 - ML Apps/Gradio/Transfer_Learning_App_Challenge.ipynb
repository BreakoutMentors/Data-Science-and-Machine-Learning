{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning App Challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNV6eDSMWGJ6h7Q9rT11EMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-transfer-learning/machine_learning/lesson%204%20-%20ML%20Apps/Gradio/Transfer_Learning_App_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qdAMrS4EH6c"
      },
      "source": [
        "> Note: Always open in Colab for the best learning experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXlK-84zsMZ"
      },
      "source": [
        "# Building your own Image Classification App\n",
        "\n",
        "In the last challenge, you chose a dataset and finetuned a pretrained model to use for your dataset. This is so great! Now in this challenge you are going to create an app using Gradio that uses your model to take images as input and give probabilities/predictions back to the user.\n",
        "\n",
        "[Please use the lesson associated with this lesson as a guide!](https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/machine_learning/lesson%204%20-%20ML%20Apps/Gradio/Pretrained_Model_Gradio_App.ipynb)\n",
        "\n",
        "This is the layout of this challenge:\n",
        "1. Upload the model's parameters\n",
        "2. Loading the model\n",
        "3. Getting labels of dataset\n",
        "4. Defining the Input into our model\n",
        "5. Defining the Output of our model\n",
        "6. Defining the function that uses your model\n",
        "7. Compiling the Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXjbKPEm2PBO"
      },
      "source": [
        "## Importing all the libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2t5WAPvzcrd"
      },
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "import requests\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBMmurkc2RHv"
      },
      "source": [
        "## Upload your model's parameters\n",
        "\n",
        "Google colab will provide you a prompt below to upload your model from the previous challenge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCXE69P2aGY"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVshC_4V2bKV"
      },
      "source": [
        "## Loading the Model\n",
        "\n",
        "In the code cell below, you need to repeat the process of how you loaded the pretrained model and finetuned it by replaced the Fully-Connected Layers with your own. When you load in your model's parameters with `torch.load()` function, set the parameter `map_location=torch.device('cpu')` so the model will use the cpu because we are only using it to make predictions.\n",
        "\n",
        "After you replace it, use `load_state_dict` method of your model to load your parameters. Then place your model in `eval()` mode to prevent the parameters from being changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTTdhzch39Tz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjkFA_Qm4A-O"
      },
      "source": [
        "## Getting Labels of dataset\n",
        "\n",
        "Below is a list of the classes in order of how the dataset was trained. This list of the labels that matches with the probabilities to show the class that is predicted in the `gradio.outputs.Label` output.\n",
        "\n",
        "Create a list below that contains all your labels in order of how the dataset was trained. This list is going to be used to match your labels to the probabilities of the output of your model that are displayed in the app with `gradio.outputs.Label` output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnjwMh1V50jw"
      },
      "source": [
        "labels = [] # Add labels(strings) to this list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjL4H_lX6JaD"
      },
      "source": [
        "## Defining the Input into our model\n",
        "\n",
        "You will be using the `gradio.inputs.Image` class that allows the user of your application to load in images to classify. The list below discusses the parameters you should use.\n",
        "\n",
        "The parameters of the input:\n",
        "1. **Shape (tuple)** - (width, height) shape to crop and resize image to; if None, matches input image size.\n",
        "2. **image_mode (str)** - \"RGB\" if color, or \"L\" if black and white.\n",
        "3. **source (str)** - Source of image. \"upload\" creates a box where user can drop an image file, \"webcam\" allows user to take snapshot from their webcam, \"canvas\" defaults to a white image that can be edited and drawn upon with tools.\n",
        "4. **type (str)** - Type of value to be returned by component. \"numpy\" returns a numpy array with shape (width, height, 3) and values from 0 to 255, \"pil\" returns a PIL image object, \"file\" returns a temporary file object whose path can be retrieved by file_obj.name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWzZiP1m6I32"
      },
      "source": [
        "# Define your interface input\n",
        "input_img = gr.inputs.Image(#ADD Parameters inside here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIdIMlLk6uBw"
      },
      "source": [
        "## Sample images (Optional)\n",
        "\n",
        "In the lesson, sample images were provided so the user can choose images to upload and those images were downloaded from a zip on Github just for purpose of the lesson. But if you want to add your own sample images, you need to download them from the internet and upload it to this colab notebook.\n",
        "\n",
        "If you do not want to do this, just leave the code cell below blank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWvgspGe8cxg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73uD7IMm8mIy"
      },
      "source": [
        "## Defining the Output of our model\n",
        "\n",
        "Since we are classifying images, the output of the model we have are probabilities of our classes. Gradio has an output class called `gradio.outputs.Label` that shows the label with the highest probability. The output class has a parameter called `num_top_classes` that gives the developer the choice to choose how many classes with the highest probabilities for the interface to display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_9jEQhf9mEB"
      },
      "source": [
        "output = # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUglrA759r86"
      },
      "source": [
        "## Define the function that uses your model\n",
        "\n",
        "You will create a function below called `classify_image` will take the input which is a [`PIL Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html) and you will use transforms that were used on the training images that were responsible of converting the images into tensors and then using the same means and standard deviations to normalize them. Again, the means and standard deviations are from the [ImageNet](https://www.image-net.org/) dataset since the pretrained model was trained with that dataset.\n",
        "\n",
        "The function needs to return a Python dictionary that contains the name of the classes as the keys and their matching probabilities as the values. This dictonary is what is used for the `gradio.outputs.Label` class to display the classes with their probabilities.\n",
        "\n",
        "Below are the transforms needed to transform the images, but please complete the function `classify_image`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLz-UQZTCgo-"
      },
      "source": [
        "# Defining transforms to normalize the inputted PIL image to a tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "def classify_image(img):\n",
        "    # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um1KVItuCma4"
      },
      "source": [
        "## Compiling the Interface\n",
        "\n",
        "After doing all the above steps you are ready to compile you interface with the `gradio.Interface` class. Then use the `launch()` method of your interface to launch the app in this colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us2IqJaiDQKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN9Mn47CDRCM"
      },
      "source": [
        "# Congrats! You just built an App!"
      ]
    }
  ]
}