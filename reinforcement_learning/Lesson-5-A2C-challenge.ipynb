{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/reinforcement_learning/Lesson-5-A2C-challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3TEN_0XzXz"
      },
      "source": [
        "> # MAKE SURE YOU RUN ON **GPU**!!!: *Select* **Runtime** -> **Change Runtime Type** -> *Select* **GPU** as your hardware acclerator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKMomcnRXzX1"
      },
      "source": [
        "### Use [this](https://rl-baselines3-zoo.readthedocs.io/en/master/) as the hint for the challenge !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSz_hsM9g7Ke"
      },
      "outputs": [],
      "source": [
        "!pip install cmake swig\n",
        "!pip install gymnasium[Box2D]==0.28.1\n",
        "!pip install rl_zoo3==2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZW0kJO6hWxq"
      },
      "source": [
        "In this challenge, you will try out something different. That is: using A2C to train [Car Racing](https://gymnasium.farama.org/environments/box2d/car_racing/) !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYFYpu8Hh4w5"
      },
      "source": [
        "![Car Racing](https://gymnasium.farama.org/_images/car_racing.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHaKgLv0iVbq"
      },
      "source": [
        "However, we cannot use rl zoo to train this yet since there is no training configuration created for this environment inside of rl zoo. So, we going to created one!\n",
        "\n",
        "---\n",
        "Run the command below to create a file called \"Car_Racing.yml\"!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCEewpr8hlFC"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!touch Car_Racing.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tP23WIUjRc6"
      },
      "source": [
        "Within the \"Car_Racing.yml\" , put this\n",
        "\n",
        "- normalize: normalized the input the stablize training process\n",
        "- n_envs: number environmnet to train at the same time\n",
        "- n_timesteps: train for how many time steps\n",
        "- policy: what to use as our policy neural network.\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "```yml\n",
        "CarRacing-v2:\n",
        "  n_envs: 8\n",
        "  n_steps: 5\n",
        "  gamma: 0.995\n",
        "  normalize: true\n",
        "  ent_coef: 0.00001\n",
        "  policy: \"MlpPolicy\"\n",
        "  n_timesteps: !!float 1e2\n",
        "  learning_rate: lin_0.00083\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf8Lr-51XzX3"
      },
      "source": [
        "**Question 5.1**\n",
        "\n",
        "Use rl zoo3 to train a *CarRacing-v2* agent using *a2c*.\n",
        "You can include the yml file as config by adding *-conf \"/content/Car_Racing.yml*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtze1FXSXzX3"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcCy8lpSXzX4"
      },
      "source": [
        "**Question 5.2**\n",
        "\n",
        "Use rl zoo3 to record a video of your agent playing the game for *300* iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_slhoWfXzX4"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OOzYrsyuYsq"
      },
      "outputs": [],
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQTtyikSufqP"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tccSTa7Augy_"
      },
      "outputs": [],
      "source": [
        "# Let's see your agent in action!\n",
        "show_videos(video_path='logs/videos', prefix='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhFm3ePaXzX5"
      },
      "source": [
        "**Question 5.3**\n",
        "\n",
        "What is the code to use *Optuna* to optimize the hyperparameters of your model? (Don't have to run the code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdHUnjicXzX5"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCICmuROXzX5"
      },
      "source": [
        "**Question 5.4**\n",
        "\n",
        "Train and visualize the model **A2C** using Stable Baseline3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Hahd46XzX5"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import A2C\n",
        "import gymnasium as gym\n",
        "\n",
        "# Create the CarRacing-v2 environment\n",
        "env =  #TODO\n",
        "\n",
        "# Instantiate the agent using \"MlpPolicy\"\n",
        "model = # TODO\n",
        "\n",
        "# Train the agent for 100 timesteps\n",
        "#TODO\n",
        "\n",
        "# Save the trained agent\n",
        "#TODO\n",
        "\n",
        "# delete the model from memory\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_W2wLtTXzX5"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# load the model\n",
        "# TODO\n",
        "\n",
        "# Create the CarRacing-v2 environment with \"rgb_array\" as render mode\n",
        "# TODO\n",
        "\n",
        "# reset the environment\n",
        "obs = env.reset()[0]\n",
        "\n",
        "img = plt.imshow(env.render()) # only call this once\n",
        "\n",
        "while True:\n",
        "\n",
        "  img.set_data(env.render()) # just update the data\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "\n",
        "  action, _states = model.predict(obs)  # predict the action and state using the model\n",
        "  obs, rewards, terminated, info, _ = env.step(action) # take the predicted action\n",
        "\n",
        "  if terminated :\n",
        "    break\n",
        "\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}