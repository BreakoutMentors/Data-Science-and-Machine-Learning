{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification-Logistic_Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-migration-to-pytorch/machine_learning/lesson%202%20-%20logistic%20regression/Classification_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIsgQYlKKVna"
      },
      "source": [
        "# Classification: Logistic Regression\n",
        "In the previous lessons, we learned about linear regression and how we can use it to construct a single layer linear neural network to predict a numeric value (i.e., how powerful a Pokemon is given their x features). Regression is great when we want to answer *how much?* or *how many?* questions. In practice, we are often more interested in *classification*: asking *which one?* not *how much?*\n",
        "- Is this customer more likely to *sign up* or *not* for a subscription service?\n",
        "- Does this image contain one of the following, a cat or a dog?\n",
        "- Is this song in the genre of hip hop, pop, or funk?\n",
        "\n",
        "When we want to distinguish two classes (called *binary classification*), we can use a classification technique called logistic regression.\n",
        "\n",
        "In this notebook, we will learn the foundations of logistic regression and demonstrate how to solve binary classification problems using an example--building a logistic regression model to predict whether an app on the Google Play Store is free or not. The ideas we introduce here will build on previous material and continue to lay out the fundamental concepts used in deep learning and neural networks, which we will cover in future lessons. Here is the lesson roadmap:\n",
        "1. Introduction to logistic regression\n",
        "2. From linear to logistic regression\n",
        "3. Building a logistic regression classifier: identifying free vs paid apps on the Google Play Store \n",
        "7. Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OYk2h2X2gqE"
      },
      "source": [
        "# Representing categorical data\n",
        "<figure>\n",
        "  <img src='https://envato-shoebox-0.imgix.net/2718/a008-795b-4376-972d-ed9cbad8ac4f/2015_227_003_0063_A_2018_07_19.jpg?auto=compress%2Cformat&fit=max&mark=https%3A%2F%2Felements-assets.envato.com%2Fstatic%2Fwatermark2.png&markalign=center%2Cmiddle&markalpha=18&w=700&s=e3fbeb220008b297bee64675504ae70c' width='50%'>\n",
        "  <figcaption>Representing data: a Shina Inu, Retriever, and Lab</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "Before we dive into logistic regression, let's consider how machine learning problems generally represents categorical data. \n",
        "\n",
        "Categorical features represent types of data which may be divided into groups. Examples of categorical features are dog breed, game genre, and educational level. While the latter feature may also be considered in a numerical manner by using exact values for  highest grade completed, it is often more informative to categorize such variables into a relatively small number of groups.\n",
        "\n",
        "Consider an example where we want to distinguish 3 different dog breeds--(golden) retrievers, labs, and shiba inus, given 3 features about each dog: height, weight, and fur color. The numeric features are height ($x_1$) and weight ($x_2$), while the categorical feature is fur color ($x_3$), which we determined has 3 colors: black, red, yellow (golden/light gold). To make this categorical feature useful, we need to convert it into a numerical representation. \n",
        "\n",
        "There are two general ways to represent categorical data in numeric terms. Perhaps the most natural choice to is to choose $x_3 \\in \\{1, 2, 3\\}$, where the integers represent the fur colors {black, red, yellow} repectively. This is a great way to compress and store info on a computer, but it's not great for machine learning. Fortunately, great minds got together long ago and invented a simple method to represent categorical data called *one-hot encoding*. A one-hot encoding is a vector with as many components as we have categories. The component corresponding to particular sample's category is set to 1 and all other components are set to 0. So in our case, this translates to:\n",
        "\n",
        "$$\n",
        "x_3 \\in \\{ (1, 0, 0), (0, 1, 0), (0, 0, 1) \\},\n",
        "$$\n",
        "\n",
        "where $x_3$ would be a three-dimensional vector representing the fur color feature with $(1, 0, 0)$ corresponding to \"black\", (0, 1, 0) to \"red\", and (0, 0, 1) to \"yellow\" fur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKHFYZBKd64"
      },
      "source": [
        "## Challenge: Representing categorical data\n",
        "Now that you know how to represent categorical data, consider the dog breed example above. We one-hot encoded the fur color feature $x_3$ so that all the features $x_1, x_2, x_3$ were represented by numeric values. Thus, the features ($\\mathbf{x}$) were ready to be passed as input to a machine learning model. On the other hand, are the labels $y$ (the dog bread) ready? Are they in the proper format? How should $y$ be *encoded*? Write your answer in the text cell below. \n",
        "\n",
        "Hint: currently, $y \\in \\{\\ \\text{retrievers}, \\text{labs}, \\text{shiba inus} \\}$ is a one-dimensional vector with categorical values.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trG2Tl_SP-Wl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGvK59PbdliB"
      },
      "source": [
        "# Intro to logistic regression\n",
        "<figure>\n",
        "  <img src='https://www.elie.net/static/images/images/challenges-faced-while-training-an-ai-to-combat-abuse/dog-vs-cat.jpg' width='70%'>\n",
        "  <figcaption>Classification: Cat vs Dog</figcaption>\n",
        "</figure>\n",
        "\n",
        "With a healthy understanding of categorical encoding, let's dive into the logistic regression method.\n",
        "\n",
        "Logistic regression is perhaps the simplest and most common machine learning algorithm for binary classification tasks. It is a special case of linear regression where the labels variable ($y$) is categorical in nature. It is called \"logistic\" regression because it uses a *logit* function, called the *sigmoid* function, to estimate the probability of a given class.\n",
        "\n",
        "To motivate logistic regression, let's consider a simple image classification problem--distinguish between cat and dog photos. Here, each image consists of a $2 \\times 2$ grayscale image. We can represent each pixel value with a single scalar (number), giving us four features $x_1,x_2,x_3,x_4$. Further, let's assume that each image belongs to one among the categories “cat” and “dog”. However, as we demonstrated in the previous section, we can't use the labels $y$ in its current format (\"cat\" and \"dog\"). We need to convert the labels to discrete numerical values (i.e., 0 and 1). To this end, we map each category to an integer, making $y \\in \\{0,1\\}$, where the integers represent $\\{\\text{cat}, \\text{dog}\\}$ repsectively. Notice that this is not exactly like *one-hot encoding*, where the one-dimensional vector is converted into a multi-dimensional vector with dimensions equivalent to the number of classes in the labels $y$. Instead, we used the simpler (first) method we discussed in the previous section: encoding each category as a numerical value, in this case $\\{0, 1\\}$ corresponding to $\\{\\text{cat}, \\text{dog}\\}$. When we only need to encode two categories (called binary categorization), we don't have to use one-hot encoding. However, we do need to encode the data numerically. Specifically, among the category labels, we need to assign 0 to one category and 1 to the other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwLwZ31JrZa"
      },
      "source": [
        "# From linear to logistic regression\n",
        "<figure>\n",
        "  <img src='https://miro.medium.com/max/1400/1*dm6ZaX5fuSmuVvM4Ds-vcg.jpeg' width='70%'>\n",
        "  <figcaption>Linear vs Logistic Regression | Source: Datacamp</figcaption>\n",
        "</figure>\n",
        "\n",
        "Now that we know how labels are properly *encoded*, let's demonstrate the connection between linear and logistic regression.\n",
        "\n",
        "When we are doing linear regression the equation is as follows:\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathbf{w} \\mathbf{X} + b,\\tag{1}\n",
        "$$\n",
        "\n",
        "where the linear model learns the most *optimal* parameter values for the *weights* ($\\mathbf{w}$) and *bias* term ($b$). The linear regression method is great when we want to predict continuous numerical data, but not so good when we need to distinguish between classes. \n",
        "\n",
        "To make a binary logistic classifier to distinguish between cat and dog photos, we need to convert the predictions ($\\hat{\\mathbf{y}}$) into probabilities ($\\hat{\\mathbf{p}}$). Here, each sample is assigned a corresponding probability $\\hat{p}$ that indicates the model's degree of *certainty* that it belongs to a particular class (in our case, cat or dog). Further, we set a threshold, usually 0.5, that the model will use to determine the final class prediction. For our cat ($y=0$) and dog ($y=1$) problem, a sample with a $\\hat{p}$ value greater than 0.5 would receive the \"dog\" label for example. \n",
        "\n",
        "In order to predict classes, logistic regression maps predictions ($\\hat{\\mathbf{y}}$) to probabilities ($\\hat{\\mathbf{p}}$) via the *sigmoid* logit function:\n",
        "$$\n",
        "\\tag{2}\n",
        "p = \\sigma(y) = \\frac{1}{1 + e^{-y}},\n",
        "$$\n",
        "\n",
        "which leads us to the equation for logistic regression: \n",
        "$$\n",
        "\\tag{3}\n",
        "\\hat{\\mathbf{p}} = \\sigma(\\hat{\\mathbf{y}}) = \\frac{1}{1 + e^{-(\\hat{\\mathbf{w} \\mathbf{X} + b})}}, \n",
        "$$ \n",
        "\n",
        "where the logistic model (binary classifier) learns the most *optimal* parameter values ($\\mathbf{w}$ and $b$) by producing probabilities ($\\hat{\\mathbf{p}}$) that *maximize the likelihood* of predicting the observed data. \n",
        "\n",
        "Generally, the logistic regression equation from $(3)$ is compressed:\n",
        "\n",
        "$$\n",
        "\\tag{4}\n",
        "\\hat{\\mathbf{p}} = \\sigma(\\hat{\\mathbf{y}}) = \\sigma(\\hat{\\mathbf{w} \\mathbf{X} + b}),\n",
        "$$\n",
        "\n",
        "where $\\sigma$ represents the sigmoid function (eq. $2$) in this case. Does this equation look similar to linear regression yet?\n",
        "\n",
        "To summarize logistic regression:\n",
        "- Category labels are converted to discrete integer values (e.g., 0 and 1).\n",
        "- The *sigmoid* logit function maps input features ($\\mathbf{x}$) to probabilities (i.e., a number between 0 and 1).\n",
        "- A category prediction is determined by the threshold value (usually 0.5) and the probability (i.e., in our cat/dog example, a sample with a probability greater than 0.5 is classified as a dog image).   \n",
        "- Logistic regression classifiers try to maximize *certainty*: predict a particular class with high confidence ($\\hat{p}$ closer to 1) and be correct (after thresholding, $\\hat{p} = y$), most of the time.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1yKY66dhryV"
      },
      "source": [
        "# Logistic Regression: identifying free apps on the Google Play Store\n",
        "Now that we know about the fundamentals of logistic regression, let's apply this method to a real-world problem--identifying free apps (or not) on the Google Play Store given the features corresponding to each app. In this section, we will demonstrate in an end-to-end fashion the process of creating a logistic regression classifier: from building, to training, and finally evaluating the model to solve the free (or not) Google Play Store app task. This process involves several steps:\n",
        "\n",
        "1. Find a dataset related to our question.\n",
        "2. Explore the dataset and prepare it for the model.\n",
        "3. Build the model.\n",
        "4. Train the model using an algorithm such as stochastic gradient descent.\n",
        "5. Evaluate the quality of our model.\n",
        "Draw conclusions.\n",
        "\n",
        "For step 1, we found the [Google Play Store dataset](https://www.kaggle.com/lava18/google-play-store-apps). The dataset contains approximately 10k rows, each representing an app on the Google Play Store. It provides data about the category, average rating, number of reviews, number of installs, price, and more for each app.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZcA1hmu_nSx"
      },
      "source": [
        "# import the libraries we be need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# importing PyTorch\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-p0Ri_eijre"
      },
      "source": [
        "## 2. Explore the dataset and prepare it for our model\n",
        "In this section we will focus on defining the   *features* ($\\mathbf{x}$) and *labels* ($\\mathbf{y}$) that we will use in our logistic regression classifier to indentify free apps. As you will see, this require us to do some data cleaning and preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuWvMOdXKUuh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ddbf0c90-6424-45bc-969d-3aebf57bdbf8"
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/krmiddlebrook/intro_to_deep_learning/master/datasets/googleplaystore.csv'\n",
        "apps_data = pd.read_csv(data_url)\n",
        "apps_data.head()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>App</th>\n",
              "      <th>Category</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Size</th>\n",
              "      <th>Installs</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Content Rating</th>\n",
              "      <th>Genres</th>\n",
              "      <th>Last Updated</th>\n",
              "      <th>Current Ver</th>\n",
              "      <th>Android Ver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.1</td>\n",
              "      <td>159</td>\n",
              "      <td>19M</td>\n",
              "      <td>10,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>January 7, 2018</td>\n",
              "      <td>1.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coloring book moana</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>3.9</td>\n",
              "      <td>967</td>\n",
              "      <td>14M</td>\n",
              "      <td>500,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Pretend Play</td>\n",
              "      <td>January 15, 2018</td>\n",
              "      <td>2.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.7</td>\n",
              "      <td>87510</td>\n",
              "      <td>8.7M</td>\n",
              "      <td>5,000,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>August 1, 2018</td>\n",
              "      <td>1.2.4</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sketch - Draw &amp; Paint</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>215644</td>\n",
              "      <td>25M</td>\n",
              "      <td>50,000,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Teen</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>June 8, 2018</td>\n",
              "      <td>Varies with device</td>\n",
              "      <td>4.2 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.3</td>\n",
              "      <td>967</td>\n",
              "      <td>2.8M</td>\n",
              "      <td>100,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Creativity</td>\n",
              "      <td>June 20, 2018</td>\n",
              "      <td>1.1</td>\n",
              "      <td>4.4 and up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 App  ...   Android Ver\n",
              "0     Photo Editor & Candy Camera & Grid & ScrapBook  ...  4.0.3 and up\n",
              "1                                Coloring book moana  ...  4.0.3 and up\n",
              "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ...  4.0.3 and up\n",
              "3                              Sketch - Draw & Paint  ...    4.2 and up\n",
              "4              Pixel Draw - Number Art Coloring Book  ...    4.4 and up\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWhDZORkja6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1d8f21-c602-4403-e524-710799d832f4"
      },
      "source": [
        "# check the column types and get basic info\n",
        "apps_data.info()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10841 entries, 0 to 10840\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   App             10841 non-null  object \n",
            " 1   Category        10841 non-null  object \n",
            " 2   Rating          9367 non-null   float64\n",
            " 3   Reviews         10841 non-null  object \n",
            " 4   Size            10841 non-null  object \n",
            " 5   Installs        10841 non-null  object \n",
            " 6   Type            10840 non-null  object \n",
            " 7   Price           10841 non-null  object \n",
            " 8   Content Rating  10840 non-null  object \n",
            " 9   Genres          10841 non-null  object \n",
            " 10  Last Updated    10841 non-null  object \n",
            " 11  Current Ver     10833 non-null  object \n",
            " 12  Android Ver     10838 non-null  object \n",
            "dtypes: float64(1), object(12)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcTd48JdBU13"
      },
      "source": [
        "Looks like there are some null values in the data (mainly in the Ratings feature). In addition, most of the numeric features, such as number of \"Reviews\", \"Size\", number of \"Installs\",  are labeled as *object* types instead of numeric types like *int* or *float*. We'll need to cast these features to the correct numeric types. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCJXvoEZiEvb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ce9ea2aa-c26e-4bba-c570-705abf0d16d4"
      },
      "source": [
        "# convert the Size column to an integer type using these provided functions\n",
        "\n",
        "#scaling and cleaning \"Size\" (of app) column\n",
        "def change_size(size):\n",
        "    if 'M' in size:\n",
        "        x = size[:-1]\n",
        "        x = float(x)*1000000\n",
        "        return(x)\n",
        "    elif 'k' == size[-1:]:\n",
        "        x = size[:-1]\n",
        "        x = float(x)*1000\n",
        "        return(x)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "apps_data[\"Size\"] = apps_data[\"Size\"].map(change_size)\n",
        "\n",
        "#filling Size which had NA\n",
        "apps_data.Size.fillna(method = 'ffill', inplace = True)\n",
        "apps_data.head()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>App</th>\n",
              "      <th>Category</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Size</th>\n",
              "      <th>Installs</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Content Rating</th>\n",
              "      <th>Genres</th>\n",
              "      <th>Last Updated</th>\n",
              "      <th>Current Ver</th>\n",
              "      <th>Android Ver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.1</td>\n",
              "      <td>159</td>\n",
              "      <td>19000000.0</td>\n",
              "      <td>10,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>January 7, 2018</td>\n",
              "      <td>1.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coloring book moana</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>3.9</td>\n",
              "      <td>967</td>\n",
              "      <td>14000000.0</td>\n",
              "      <td>500,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Pretend Play</td>\n",
              "      <td>January 15, 2018</td>\n",
              "      <td>2.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.7</td>\n",
              "      <td>87510</td>\n",
              "      <td>8700000.0</td>\n",
              "      <td>5,000,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>August 1, 2018</td>\n",
              "      <td>1.2.4</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sketch - Draw &amp; Paint</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>215644</td>\n",
              "      <td>25000000.0</td>\n",
              "      <td>50,000,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Teen</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>June 8, 2018</td>\n",
              "      <td>Varies with device</td>\n",
              "      <td>4.2 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.3</td>\n",
              "      <td>967</td>\n",
              "      <td>2800000.0</td>\n",
              "      <td>100,000+</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Creativity</td>\n",
              "      <td>June 20, 2018</td>\n",
              "      <td>1.1</td>\n",
              "      <td>4.4 and up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 App  ...   Android Ver\n",
              "0     Photo Editor & Candy Camera & Grid & ScrapBook  ...  4.0.3 and up\n",
              "1                                Coloring book moana  ...  4.0.3 and up\n",
              "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ...  4.0.3 and up\n",
              "3                              Sketch - Draw & Paint  ...    4.2 and up\n",
              "4              Pixel Draw - Number Art Coloring Book  ...    4.4 and up\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DwJ_fgVv98"
      },
      "source": [
        "After analyzing the data, we found that the Installs feature was defined as a object type because most rows contained string characters like \"+\" and \",\". Let's remove those characters and remove any mislabeled data rows (rows that don't contain numbers). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrLlPm9RkAv8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "983bd845-dd4f-44f2-d6ca-3c5ebe93ff41"
      },
      "source": [
        "# clean and convert the \"Installs\" column to int\n",
        "apps_data['Installs'] = apps_data['Installs'].str.replace(',', '')\n",
        "apps_data['Installs'] = apps_data['Installs'].str.replace('+', '')\n",
        "\n",
        "# remove mislabeled row\n",
        "apps_data = apps_data.loc[~apps_data['Installs'].str.contains('\\D+'), :].reset_index(drop=True)\n",
        "\n",
        "apps_data['Installs'] = apps_data['Installs'].astype(int)\n",
        "\n",
        "apps_data.head()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>App</th>\n",
              "      <th>Category</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Size</th>\n",
              "      <th>Installs</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Content Rating</th>\n",
              "      <th>Genres</th>\n",
              "      <th>Last Updated</th>\n",
              "      <th>Current Ver</th>\n",
              "      <th>Android Ver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.1</td>\n",
              "      <td>159</td>\n",
              "      <td>19000000.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>January 7, 2018</td>\n",
              "      <td>1.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coloring book moana</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>3.9</td>\n",
              "      <td>967</td>\n",
              "      <td>14000000.0</td>\n",
              "      <td>500000</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Pretend Play</td>\n",
              "      <td>January 15, 2018</td>\n",
              "      <td>2.0.0</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.7</td>\n",
              "      <td>87510</td>\n",
              "      <td>8700000.0</td>\n",
              "      <td>5000000</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>August 1, 2018</td>\n",
              "      <td>1.2.4</td>\n",
              "      <td>4.0.3 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sketch - Draw &amp; Paint</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>215644</td>\n",
              "      <td>25000000.0</td>\n",
              "      <td>50000000</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Teen</td>\n",
              "      <td>Art &amp; Design</td>\n",
              "      <td>June 8, 2018</td>\n",
              "      <td>Varies with device</td>\n",
              "      <td>4.2 and up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
              "      <td>ART_AND_DESIGN</td>\n",
              "      <td>4.3</td>\n",
              "      <td>967</td>\n",
              "      <td>2800000.0</td>\n",
              "      <td>100000</td>\n",
              "      <td>Free</td>\n",
              "      <td>0</td>\n",
              "      <td>Everyone</td>\n",
              "      <td>Art &amp; Design;Creativity</td>\n",
              "      <td>June 20, 2018</td>\n",
              "      <td>1.1</td>\n",
              "      <td>4.4 and up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 App  ...   Android Ver\n",
              "0     Photo Editor & Candy Camera & Grid & ScrapBook  ...  4.0.3 and up\n",
              "1                                Coloring book moana  ...  4.0.3 and up\n",
              "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ...  4.0.3 and up\n",
              "3                              Sketch - Draw & Paint  ...    4.2 and up\n",
              "4              Pixel Draw - Number Art Coloring Book  ...    4.4 and up\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua9AKQ3pWeor"
      },
      "source": [
        "Now we convert the Reviews feature to an integer type and remove the Price feature, since keeping it would be cheating (the model would learn that 0 means an app is free and any other value means an app is not).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SopAF7qMWc9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513cd33f-b98b-4ef6-cf6f-24e86acb94cf"
      },
      "source": [
        "# clean and convert the \"Reviews\" column to int\n",
        "# fix mislabeled row in the \"Reviews\" column\n",
        "# apps_data.loc[apps_data.Reviews.str.contains('M'), 'Reviews'] = int(apps_data.loc[apps_data.Reviews.str.contains('M'), 'Reviews'].values.tolist()[0][:-1])*1000000\n",
        "apps_data['Reviews'] = apps_data['Reviews'].astype('int')\n",
        "\n",
        "# remove price column so we don't cheat\n",
        "apps_data = apps_data.drop(columns=['Price'])\n",
        "\n",
        "# remove columns we won't be using in our analysis\n",
        "apps_data.info()\n"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10840 entries, 0 to 10839\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   App             10840 non-null  object \n",
            " 1   Category        10840 non-null  object \n",
            " 2   Rating          9366 non-null   float64\n",
            " 3   Reviews         10840 non-null  int64  \n",
            " 4   Size            10840 non-null  float64\n",
            " 5   Installs        10840 non-null  int64  \n",
            " 6   Type            10839 non-null  object \n",
            " 7   Content Rating  10840 non-null  object \n",
            " 8   Genres          10840 non-null  object \n",
            " 9   Last Updated    10840 non-null  object \n",
            " 10  Current Ver     10832 non-null  object \n",
            " 11  Android Ver     10838 non-null  object \n",
            "dtypes: float64(2), int64(2), object(8)\n",
            "memory usage: 1016.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzFGoa_NXPVJ"
      },
      "source": [
        "Looking good. Now we need to *one-hot encode* the categorical features that have more than 2 categories, in this case, Category and Content Rating. We use the `get_dummies` method from Pandas to create multi-dimensional (one-hot encoded) vectors for each feature, and concatenate the vectors to the original dataframe using the `concat` method from Pandas.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ixPQT-kUA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86c5d5f-881d-474d-dad3-3f9eaab5c322"
      },
      "source": [
        "# converting non-numeric columns to numeric columns using \"one-hot encoding\"\n",
        "catgry = pd.get_dummies(apps_data['Category'],prefix='catg',drop_first=True)\n",
        "cr = pd.get_dummies(apps_data['Content Rating'],prefix='cr',drop_first=True)\n",
        "\n",
        "frames = [apps_data,catgry,cr]\n",
        "apps_data=pd.concat(frames,axis=1)\n",
        "apps_data = apps_data.drop(['Category', 'Content Rating'], axis=1)\n",
        "apps_data.info()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10840 entries, 0 to 10839\n",
            "Data columns (total 47 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   App                       10840 non-null  object \n",
            " 1   Rating                    9366 non-null   float64\n",
            " 2   Reviews                   10840 non-null  int64  \n",
            " 3   Size                      10840 non-null  float64\n",
            " 4   Installs                  10840 non-null  int64  \n",
            " 5   Type                      10839 non-null  object \n",
            " 6   Genres                    10840 non-null  object \n",
            " 7   Last Updated              10840 non-null  object \n",
            " 8   Current Ver               10832 non-null  object \n",
            " 9   Android Ver               10838 non-null  object \n",
            " 10  catg_AUTO_AND_VEHICLES    10840 non-null  uint8  \n",
            " 11  catg_BEAUTY               10840 non-null  uint8  \n",
            " 12  catg_BOOKS_AND_REFERENCE  10840 non-null  uint8  \n",
            " 13  catg_BUSINESS             10840 non-null  uint8  \n",
            " 14  catg_COMICS               10840 non-null  uint8  \n",
            " 15  catg_COMMUNICATION        10840 non-null  uint8  \n",
            " 16  catg_DATING               10840 non-null  uint8  \n",
            " 17  catg_EDUCATION            10840 non-null  uint8  \n",
            " 18  catg_ENTERTAINMENT        10840 non-null  uint8  \n",
            " 19  catg_EVENTS               10840 non-null  uint8  \n",
            " 20  catg_FAMILY               10840 non-null  uint8  \n",
            " 21  catg_FINANCE              10840 non-null  uint8  \n",
            " 22  catg_FOOD_AND_DRINK       10840 non-null  uint8  \n",
            " 23  catg_GAME                 10840 non-null  uint8  \n",
            " 24  catg_HEALTH_AND_FITNESS   10840 non-null  uint8  \n",
            " 25  catg_HOUSE_AND_HOME       10840 non-null  uint8  \n",
            " 26  catg_LIBRARIES_AND_DEMO   10840 non-null  uint8  \n",
            " 27  catg_LIFESTYLE            10840 non-null  uint8  \n",
            " 28  catg_MAPS_AND_NAVIGATION  10840 non-null  uint8  \n",
            " 29  catg_MEDICAL              10840 non-null  uint8  \n",
            " 30  catg_NEWS_AND_MAGAZINES   10840 non-null  uint8  \n",
            " 31  catg_PARENTING            10840 non-null  uint8  \n",
            " 32  catg_PERSONALIZATION      10840 non-null  uint8  \n",
            " 33  catg_PHOTOGRAPHY          10840 non-null  uint8  \n",
            " 34  catg_PRODUCTIVITY         10840 non-null  uint8  \n",
            " 35  catg_SHOPPING             10840 non-null  uint8  \n",
            " 36  catg_SOCIAL               10840 non-null  uint8  \n",
            " 37  catg_SPORTS               10840 non-null  uint8  \n",
            " 38  catg_TOOLS                10840 non-null  uint8  \n",
            " 39  catg_TRAVEL_AND_LOCAL     10840 non-null  uint8  \n",
            " 40  catg_VIDEO_PLAYERS        10840 non-null  uint8  \n",
            " 41  catg_WEATHER              10840 non-null  uint8  \n",
            " 42  cr_Everyone               10840 non-null  uint8  \n",
            " 43  cr_Everyone 10+           10840 non-null  uint8  \n",
            " 44  cr_Mature 17+             10840 non-null  uint8  \n",
            " 45  cr_Teen                   10840 non-null  uint8  \n",
            " 46  cr_Unrated                10840 non-null  uint8  \n",
            "dtypes: float64(2), int64(2), object(6), uint8(37)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miC0TZekYaXr"
      },
      "source": [
        "Now we are ready to define the features $\\mathbf{x}$ and labels $y$. We define the labels as the Type feature and encode. Additionally, we use every feature except App, Genres, Last Updated, Current Ver, and Android Ver for the input features. Finally, we prepare the training and test datasets for the model. In this step we introduce an semi-new concept *normalization*. Specifically, we will normalize the features (of non-categorical features) using their respective mean and standard deviations.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCwfUDimoc3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e3ce3c-adba-4803-e9b8-84a7627afdd3"
      },
      "source": [
        "# select the x and y variables for the model\n",
        "x = apps_data.loc[:, ~apps_data.columns.isin(['App', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver'])].columns\n",
        "y = 'Type' \n",
        "\n",
        "apps_data = apps_data.drop(['App', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver'], axis=1)\n",
        "\n",
        "# drop rows with missing values\n",
        "apps_data = apps_data.dropna()\n",
        "\n",
        "# convert \"Type\" column to int before creating y variable\n",
        "def convert_type_to_int(type):\n",
        "  if type == 'Free':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "apps_data[y] = apps_data[y].map(convert_type_to_int)\n",
        "\n",
        "# normalize the non-categorical (not one-hot encoded) features\n",
        "norm_cols = ['Rating', 'Reviews', 'Size', 'Installs']\n",
        "\n",
        "means = apps_data[norm_cols].mean()\n",
        "std = apps_data[norm_cols].std()\n",
        "\n",
        "apps_data[norm_cols] -= means\n",
        "apps_data[norm_cols] /= std\n",
        "\n",
        "# split the dataset into a training set and a test set.\n",
        "# we will use the test set in the final evaluation of our model.\n",
        "train = apps_data.sample(frac=0.8, random_state=0)\n",
        "test = apps_data.drop(train.index)\n",
        "\n",
        "# Splitting training data into validation data\n",
        "valid = train.sample(frac=0.1, random_state=0)\n",
        "train = train.drop(valid.index) # Deleting rows sampled for validation data\n",
        "\n",
        "# separate the x (features) and y (labels) in the train/test datasets\n",
        "train_features = torch.tensor(train[x].values, dtype=torch.float)\n",
        "test_features = torch.tensor(test[x].values, dtype=torch.float)\n",
        "valid_features = torch.tensor(valid[x].values, dtype=torch.float)\n",
        "\n",
        "train_labels = torch.tensor(train[y].values.reshape(-1, 1), dtype=torch.float)\n",
        "test_labels = torch.tensor(test[y].values.reshape(-1, 1), dtype=torch.float)\n",
        "valid_labels = torch.tensor(valid[y].values.reshape(-1, 1), dtype=torch.float)\n",
        "\n",
        "\n",
        "print('train features shape:', train_features.shape)\n",
        "print('train labels shape:', train_labels.shape)\n",
        "\n",
        "print('validation features shape:', valid_features.shape)\n",
        "print('validation labels shape:', valid_labels.shape)\n",
        "\n",
        "print('test features shape:', test_features.shape)\n",
        "print('test labels shape:', test_labels.shape)\n",
        "\n",
        "print('first 5 test labels:\\n', test_labels[:5])\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train features shape: torch.Size([6744, 42])\n",
            "train labels shape: torch.Size([6744, 1])\n",
            "validation features shape: torch.Size([749, 42])\n",
            "validation labels shape: torch.Size([749, 1])\n",
            "test features shape: torch.Size([1873, 42])\n",
            "test labels shape: torch.Size([1873, 1])\n",
            "first 5 test labels:\n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DxpwDL0icOO"
      },
      "source": [
        "The above code returns a training and test dataset. For context, the `training_features` array contains about 7.5k rows (samples) and 42 columns (features). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsoZiJj3tr1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348fb22b-52b2-439e-bd31-74fe4cdd9e53"
      },
      "source": [
        "counts = np.bincount(train_labels[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples (paid apps) in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_labels)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]\n",
        "\n",
        "print('weight for free apps:', weight_for_0)\n",
        "print('weight for paid apps:', weight_for_1)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive samples (paid apps) in training data: 476 (7.06% of total)\n",
            "weight for free apps: 0.0001595405232929164\n",
            "weight for paid apps: 0.0021008403361344537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB8P1GFcifvd"
      },
      "source": [
        "## 3. Build the model\n",
        "Now that the data is ready, we can build a model. We will use PyTorch to define a simple logistic regression model (single-layer neural network) to predict the class of each app (free or not). Given a smaple with a corresponding prediction that is above 0.5, the model will assign the \"paid\" (1) category to it, otherwise it is categorized as \"free\". \n",
        "\n",
        "We also define the loss function, optimization algorithm, and metrics and \"glue\" them together with the model using the `compile` method. We will use *binary cross-entropy* loss, *stochastic gradient descent*, and track the *accuracy* metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8ykITrvlpZE",
        "outputId": "405fd643-8656-41ef-baa8-4b6c074ab013"
      },
      "source": [
        "# building logistic model\n",
        "class Logistic_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    @params\n",
        "        num_features(int): The number of features to construct the input layer of the NN\n",
        "    \"\"\"\n",
        "    # Defining Constructor\n",
        "    def __init__(self, num_features):\n",
        "        super(Logistic_Model, self).__init__()\n",
        "\n",
        "        # Defining Layers\n",
        "        self.fc1 = nn.Linear(num_features, 1)\n",
        "\n",
        "        # Define Softmax activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model\n",
        "num_features = train_features.shape[1]\n",
        "model = Logistic_Model(num_features)\n",
        "model"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Logistic_Model(\n",
              "  (fc1): Linear(in_features=42, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouH0ZFaFoXIz"
      },
      "source": [
        "# Defining Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Defining optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UraXf-5skCxm"
      },
      "source": [
        "## 4. Train the model\n",
        "No it's time to train the model. We will train it for 100 *epochs* (iterations) with a *batch size* of 2048 (the number of training examples to evaluate prior to doing gradient descent), and record the training and validation metrics in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keBa4mDOs3ov"
      },
      "source": [
        "batch_size = 2048\n",
        "\n",
        "# Defining datasets\n",
        "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
        "valid_dataset = torch.utils.data.TensorDataset(valid_features, valid_labels)\n",
        "\n",
        "# Loading datasets into dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Mx0-hns9hA",
        "outputId": "b19e8dbf-6a91-4bed-ab7f-c2d77e4e123c"
      },
      "source": [
        "# Function that takes output and returns predictions\n",
        "def getPredictions(output, threshold=0.5):\n",
        "    predictions = torch.zeros(output.shape)\n",
        "    for i in range(len(output)):\n",
        "        if output[i] < threshold:\n",
        "            predictions[i] = 0\n",
        "        else:\n",
        "            predictions[i] = 1\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    train_counts = 0\n",
        "    valid_counts = 0\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "\n",
        "    # Setting model to train mode\n",
        "    model.train()\n",
        "\n",
        "    for train_features, train_labels in train_dataloader:\n",
        "        \n",
        "        # Setting all gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate Output\n",
        "        output = model(train_features)\n",
        "            \n",
        "        # Calculate Loss\n",
        "        loss = criterion(output, train_labels)\n",
        "\n",
        "        # Calculate Gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform Gradient Descent Step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Saving loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Get Predictions\n",
        "        train_preds = getPredictions(output)\n",
        "\n",
        "        # Saving number of right predictions for accuracy\n",
        "        train_counts += train_preds.eq(train_labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "\n",
        "    # Setting model to evaluation mode, no parameters will change\n",
        "    model.eval()\n",
        "    for valid_features, valid_labels in valid_dataloader:\n",
        "        # Calculate Output\n",
        "        output = model(valid_features)\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = criterion(output, valid_labels)\n",
        "\n",
        "        # Saving loss\n",
        "        valid_loss += loss.item()\n",
        "\n",
        "        # Get Predictions\n",
        "        valid_preds = getPredictions(output)\n",
        "\n",
        "        # Saving number of right predictions for accuracy\n",
        "        valid_counts += valid_preds.eq(valid_labels).sum().item()\n",
        "\n",
        "    # Averaging and Saving Losses\n",
        "    train_loss/=len(train_dataset)\n",
        "    valid_loss/=len(valid_dataset)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    # Getting accuracies and saving them\n",
        "    train_acc = train_counts/len(train_dataset)\n",
        "    valid_acc = valid_counts/len(valid_dataset)\n",
        "    train_accuracies.append(train_acc)\n",
        "    valid_accuracies.append(valid_acc)\n",
        "\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}% \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch, train_loss, train_acc*100, valid_loss, valid_acc*100))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.000397 \tTraining Accuracy: 59.73% \tValidation Loss: 0.000802 \tValidation Accuracy: 90.65%\n",
            "Epoch: 2 \tTraining Loss: 0.000336 \tTraining Accuracy: 92.02% \tValidation Loss: 0.000695 \tValidation Accuracy: 91.72%\n",
            "Epoch: 3 \tTraining Loss: 0.000294 \tTraining Accuracy: 92.60% \tValidation Loss: 0.000618 \tValidation Accuracy: 92.26%\n",
            "Epoch: 4 \tTraining Loss: 0.000263 \tTraining Accuracy: 92.75% \tValidation Loss: 0.000562 \tValidation Accuracy: 92.52%\n",
            "Epoch: 5 \tTraining Loss: 0.000240 \tTraining Accuracy: 92.81% \tValidation Loss: 0.000519 \tValidation Accuracy: 92.52%\n",
            "Epoch: 6 \tTraining Loss: 0.000221 \tTraining Accuracy: 92.91% \tValidation Loss: 0.000486 \tValidation Accuracy: 92.52%\n",
            "Epoch: 7 \tTraining Loss: 0.000207 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000459 \tValidation Accuracy: 92.52%\n",
            "Epoch: 8 \tTraining Loss: 0.000197 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000438 \tValidation Accuracy: 92.52%\n",
            "Epoch: 9 \tTraining Loss: 0.000188 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000421 \tValidation Accuracy: 92.52%\n",
            "Epoch: 10 \tTraining Loss: 0.000181 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000407 \tValidation Accuracy: 92.52%\n",
            "Epoch: 11 \tTraining Loss: 0.000175 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000395 \tValidation Accuracy: 92.52%\n",
            "Epoch: 12 \tTraining Loss: 0.000170 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000384 \tValidation Accuracy: 92.52%\n",
            "Epoch: 13 \tTraining Loss: 0.000167 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000376 \tValidation Accuracy: 92.52%\n",
            "Epoch: 14 \tTraining Loss: 0.000161 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000368 \tValidation Accuracy: 92.52%\n",
            "Epoch: 15 \tTraining Loss: 0.000158 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000361 \tValidation Accuracy: 92.52%\n",
            "Epoch: 16 \tTraining Loss: 0.000155 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000354 \tValidation Accuracy: 92.52%\n",
            "Epoch: 17 \tTraining Loss: 0.000151 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000349 \tValidation Accuracy: 92.52%\n",
            "Epoch: 18 \tTraining Loss: 0.000149 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000344 \tValidation Accuracy: 92.52%\n",
            "Epoch: 19 \tTraining Loss: 0.000149 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000339 \tValidation Accuracy: 92.52%\n",
            "Epoch: 20 \tTraining Loss: 0.000145 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000334 \tValidation Accuracy: 92.52%\n",
            "Epoch: 21 \tTraining Loss: 0.000144 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000330 \tValidation Accuracy: 92.52%\n",
            "Epoch: 22 \tTraining Loss: 0.000143 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000326 \tValidation Accuracy: 92.52%\n",
            "Epoch: 23 \tTraining Loss: 0.000138 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000323 \tValidation Accuracy: 92.52%\n",
            "Epoch: 24 \tTraining Loss: 0.000137 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000319 \tValidation Accuracy: 92.52%\n",
            "Epoch: 25 \tTraining Loss: 0.000136 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000316 \tValidation Accuracy: 92.52%\n",
            "Epoch: 26 \tTraining Loss: 0.000137 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000313 \tValidation Accuracy: 92.52%\n",
            "Epoch: 27 \tTraining Loss: 0.000140 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000310 \tValidation Accuracy: 92.52%\n",
            "Epoch: 28 \tTraining Loss: 0.000135 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000307 \tValidation Accuracy: 92.52%\n",
            "Epoch: 29 \tTraining Loss: 0.000132 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000304 \tValidation Accuracy: 92.52%\n",
            "Epoch: 30 \tTraining Loss: 0.000129 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000301 \tValidation Accuracy: 92.52%\n",
            "Epoch: 31 \tTraining Loss: 0.000130 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000298 \tValidation Accuracy: 92.52%\n",
            "Epoch: 32 \tTraining Loss: 0.000127 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000296 \tValidation Accuracy: 92.52%\n",
            "Epoch: 33 \tTraining Loss: 0.000128 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000293 \tValidation Accuracy: 92.52%\n",
            "Epoch: 34 \tTraining Loss: 0.000125 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000291 \tValidation Accuracy: 92.52%\n",
            "Epoch: 35 \tTraining Loss: 0.000126 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000288 \tValidation Accuracy: 92.52%\n",
            "Epoch: 36 \tTraining Loss: 0.000122 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000286 \tValidation Accuracy: 92.52%\n",
            "Epoch: 37 \tTraining Loss: 0.000123 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000283 \tValidation Accuracy: 92.52%\n",
            "Epoch: 38 \tTraining Loss: 0.000121 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000281 \tValidation Accuracy: 92.52%\n",
            "Epoch: 39 \tTraining Loss: 0.000121 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000279 \tValidation Accuracy: 92.52%\n",
            "Epoch: 40 \tTraining Loss: 0.000118 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000276 \tValidation Accuracy: 92.52%\n",
            "Epoch: 41 \tTraining Loss: 0.000119 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000274 \tValidation Accuracy: 92.52%\n",
            "Epoch: 42 \tTraining Loss: 0.000117 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000272 \tValidation Accuracy: 92.52%\n",
            "Epoch: 43 \tTraining Loss: 0.000119 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000270 \tValidation Accuracy: 92.52%\n",
            "Epoch: 44 \tTraining Loss: 0.000115 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000268 \tValidation Accuracy: 92.52%\n",
            "Epoch: 45 \tTraining Loss: 0.000116 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000266 \tValidation Accuracy: 92.52%\n",
            "Epoch: 46 \tTraining Loss: 0.000113 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000264 \tValidation Accuracy: 92.52%\n",
            "Epoch: 47 \tTraining Loss: 0.000116 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000261 \tValidation Accuracy: 92.52%\n",
            "Epoch: 48 \tTraining Loss: 0.000112 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000259 \tValidation Accuracy: 92.52%\n",
            "Epoch: 49 \tTraining Loss: 0.000113 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000257 \tValidation Accuracy: 92.52%\n",
            "Epoch: 50 \tTraining Loss: 0.000114 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000255 \tValidation Accuracy: 92.52%\n",
            "Epoch: 51 \tTraining Loss: 0.000109 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000253 \tValidation Accuracy: 92.52%\n",
            "Epoch: 52 \tTraining Loss: 0.000110 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000251 \tValidation Accuracy: 92.52%\n",
            "Epoch: 53 \tTraining Loss: 0.000109 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000249 \tValidation Accuracy: 92.52%\n",
            "Epoch: 54 \tTraining Loss: 0.000108 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000247 \tValidation Accuracy: 92.52%\n",
            "Epoch: 55 \tTraining Loss: 0.000107 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000245 \tValidation Accuracy: 92.52%\n",
            "Epoch: 56 \tTraining Loss: 0.000108 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000244 \tValidation Accuracy: 92.52%\n",
            "Epoch: 57 \tTraining Loss: 0.000103 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000242 \tValidation Accuracy: 92.52%\n",
            "Epoch: 58 \tTraining Loss: 0.000104 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000240 \tValidation Accuracy: 92.52%\n",
            "Epoch: 59 \tTraining Loss: 0.000104 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000238 \tValidation Accuracy: 92.52%\n",
            "Epoch: 60 \tTraining Loss: 0.000104 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000236 \tValidation Accuracy: 92.52%\n",
            "Epoch: 61 \tTraining Loss: 0.000102 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000234 \tValidation Accuracy: 92.52%\n",
            "Epoch: 62 \tTraining Loss: 0.000102 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000233 \tValidation Accuracy: 92.52%\n",
            "Epoch: 63 \tTraining Loss: 0.000099 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000231 \tValidation Accuracy: 92.52%\n",
            "Epoch: 64 \tTraining Loss: 0.000099 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000229 \tValidation Accuracy: 92.52%\n",
            "Epoch: 65 \tTraining Loss: 0.000098 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000227 \tValidation Accuracy: 92.52%\n",
            "Epoch: 66 \tTraining Loss: 0.000098 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000226 \tValidation Accuracy: 92.52%\n",
            "Epoch: 67 \tTraining Loss: 0.000098 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000224 \tValidation Accuracy: 92.52%\n",
            "Epoch: 68 \tTraining Loss: 0.000096 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000222 \tValidation Accuracy: 92.52%\n",
            "Epoch: 69 \tTraining Loss: 0.000094 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000221 \tValidation Accuracy: 92.52%\n",
            "Epoch: 70 \tTraining Loss: 0.000093 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000219 \tValidation Accuracy: 92.52%\n",
            "Epoch: 71 \tTraining Loss: 0.000093 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000218 \tValidation Accuracy: 92.52%\n",
            "Epoch: 72 \tTraining Loss: 0.000094 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000216 \tValidation Accuracy: 92.52%\n",
            "Epoch: 73 \tTraining Loss: 0.000095 \tTraining Accuracy: 92.94% \tValidation Loss: 0.000214 \tValidation Accuracy: 92.52%\n",
            "Epoch: 74 \tTraining Loss: 0.000092 \tTraining Accuracy: 92.96% \tValidation Loss: 0.000213 \tValidation Accuracy: 92.52%\n",
            "Epoch: 75 \tTraining Loss: 0.000092 \tTraining Accuracy: 92.96% \tValidation Loss: 0.000211 \tValidation Accuracy: 92.52%\n",
            "Epoch: 76 \tTraining Loss: 0.000090 \tTraining Accuracy: 92.96% \tValidation Loss: 0.000210 \tValidation Accuracy: 92.52%\n",
            "Epoch: 77 \tTraining Loss: 0.000090 \tTraining Accuracy: 92.96% \tValidation Loss: 0.000208 \tValidation Accuracy: 92.66%\n",
            "Epoch: 78 \tTraining Loss: 0.000091 \tTraining Accuracy: 92.99% \tValidation Loss: 0.000207 \tValidation Accuracy: 92.66%\n",
            "Epoch: 79 \tTraining Loss: 0.000091 \tTraining Accuracy: 93.02% \tValidation Loss: 0.000205 \tValidation Accuracy: 92.66%\n",
            "Epoch: 80 \tTraining Loss: 0.000090 \tTraining Accuracy: 93.02% \tValidation Loss: 0.000203 \tValidation Accuracy: 92.66%\n",
            "Epoch: 81 \tTraining Loss: 0.000088 \tTraining Accuracy: 93.02% \tValidation Loss: 0.000202 \tValidation Accuracy: 92.66%\n",
            "Epoch: 82 \tTraining Loss: 0.000086 \tTraining Accuracy: 93.03% \tValidation Loss: 0.000201 \tValidation Accuracy: 92.66%\n",
            "Epoch: 83 \tTraining Loss: 0.000088 \tTraining Accuracy: 93.03% \tValidation Loss: 0.000199 \tValidation Accuracy: 92.66%\n",
            "Epoch: 84 \tTraining Loss: 0.000087 \tTraining Accuracy: 93.05% \tValidation Loss: 0.000198 \tValidation Accuracy: 92.66%\n",
            "Epoch: 85 \tTraining Loss: 0.000085 \tTraining Accuracy: 93.05% \tValidation Loss: 0.000196 \tValidation Accuracy: 92.66%\n",
            "Epoch: 86 \tTraining Loss: 0.000086 \tTraining Accuracy: 93.05% \tValidation Loss: 0.000195 \tValidation Accuracy: 92.79%\n",
            "Epoch: 87 \tTraining Loss: 0.000086 \tTraining Accuracy: 93.06% \tValidation Loss: 0.000193 \tValidation Accuracy: 92.92%\n",
            "Epoch: 88 \tTraining Loss: 0.000083 \tTraining Accuracy: 93.10% \tValidation Loss: 0.000192 \tValidation Accuracy: 92.92%\n",
            "Epoch: 89 \tTraining Loss: 0.000082 \tTraining Accuracy: 93.10% \tValidation Loss: 0.000191 \tValidation Accuracy: 92.92%\n",
            "Epoch: 90 \tTraining Loss: 0.000082 \tTraining Accuracy: 93.16% \tValidation Loss: 0.000189 \tValidation Accuracy: 92.92%\n",
            "Epoch: 91 \tTraining Loss: 0.000081 \tTraining Accuracy: 93.21% \tValidation Loss: 0.000188 \tValidation Accuracy: 92.92%\n",
            "Epoch: 92 \tTraining Loss: 0.000080 \tTraining Accuracy: 93.21% \tValidation Loss: 0.000187 \tValidation Accuracy: 92.92%\n",
            "Epoch: 93 \tTraining Loss: 0.000081 \tTraining Accuracy: 93.25% \tValidation Loss: 0.000185 \tValidation Accuracy: 92.92%\n",
            "Epoch: 94 \tTraining Loss: 0.000083 \tTraining Accuracy: 93.25% \tValidation Loss: 0.000184 \tValidation Accuracy: 92.92%\n",
            "Epoch: 95 \tTraining Loss: 0.000081 \tTraining Accuracy: 93.27% \tValidation Loss: 0.000183 \tValidation Accuracy: 92.92%\n",
            "Epoch: 96 \tTraining Loss: 0.000078 \tTraining Accuracy: 93.28% \tValidation Loss: 0.000181 \tValidation Accuracy: 92.92%\n",
            "Epoch: 97 \tTraining Loss: 0.000078 \tTraining Accuracy: 93.31% \tValidation Loss: 0.000180 \tValidation Accuracy: 93.06%\n",
            "Epoch: 98 \tTraining Loss: 0.000078 \tTraining Accuracy: 93.31% \tValidation Loss: 0.000179 \tValidation Accuracy: 93.19%\n",
            "Epoch: 99 \tTraining Loss: 0.000077 \tTraining Accuracy: 93.31% \tValidation Loss: 0.000178 \tValidation Accuracy: 93.32%\n",
            "Epoch: 100 \tTraining Loss: 0.000076 \tTraining Accuracy: 93.33% \tValidation Loss: 0.000176 \tValidation Accuracy: 93.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Aybqwzqa45Cx",
        "outputId": "c12cff17-9c33-4025-f218-b81515071520"
      },
      "source": [
        "plt.plot(valid_accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGnpAbVjzhQm"
      },
      "source": [
        "As the above plot suggests, our model converges to optimal parameters around the 40th epoch. The validation accuracy peaks around ~92.3%.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWuWW0tcvV7_"
      },
      "source": [
        "## 5. Evaluate the model\n",
        "Now that we trained our model, it's time to evaluate it using the test dataset, which we did not use when training the model. This gives us a sense of how well our model predicts unseen data, which is the case when we use it in the real world. We will use the `evaluate` method to test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkZOiI_p6MlR",
        "outputId": "5b16f61b-c7b8-4003-d793-ad7b58c33902"
      },
      "source": [
        "test_loss = 0.0\n",
        "test_counts = 0\n",
        "\n",
        "# Setting model to evaluation mode, no parameters will change\n",
        "model.eval()\n",
        "\n",
        "for test_features, test_labels in test_dataloader:\n",
        "    # Calculate Output\n",
        "    output = model(test_features)\n",
        "\n",
        "    # Calculate Loss\n",
        "    loss = criterion(output, test_labels)\n",
        "\n",
        "    # Saving loss\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    # Get Predictions\n",
        "    test_preds = getPredictions(output)\n",
        "\n",
        "    # Saving number of right predictions for accuracy\n",
        "    test_counts += test_preds.eq(test_labels).sum().item()\n",
        "\n",
        "# Calculating test accuracy\n",
        "test_acc = test_counts/len(test_dataset)\n",
        "print('Test Loss: {:.6f} \\tTest Accuracy: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.120642 \tTest Accuracy: 94.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92XmHVgW0xLg"
      },
      "source": [
        "Wow! Our logistic regression model fit the Google Play Store data pretty well, correctly predicting whether an app was free or not around 93% to 94% of the time. However, the distribution of free apps to non-free apps in our datasets is is not balanced, this is called *class imbalance*. To give our results more context, we should check the *confusion matrix* to make sure the model wasn't just predicting every app as \"free\" since there are a lot more those than there are \"paid\" apps.\n",
        "\n",
        "A confusion matrix indicates the number of correct predictions and incorrect predictions for each class. It is particularly useful whenever the data has an imbalanced representation of the classes. The diagonals of a confusion matrix indicate the correct predictions for each class, while the cross-diagonal indicates misclassified predictions. Below is an example of a binary classification confusion matrix.\n",
        "\n",
        "<figure>\n",
        "  <img src='https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png' width='35%'>\n",
        "  <figcaption>A basic confusion matrix</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hPEGd12NbY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "89586a95-b05e-44bb-9811-84a25e243317"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "test_predictions = getPredictions(model(test_features)).numpy()\n",
        "\n",
        "# Converting labels and predictions to numpy arrays\n",
        "test_predictions = getPredictions(model(test_features)).numpy()\n",
        "test_labels = test_labels.numpy()\n",
        "\n",
        "# measure the accuracy\n",
        "model_acc = metrics.accuracy_score(test_labels, test_predictions)\n",
        "print(f'logistic regression model accuracy: {round(model_acc*100, 2)}%')\n",
        "\n",
        "# plot confusion matrix\n",
        "labels = ['Free', 'Paid']\n",
        "cm = metrics.confusion_matrix(test_labels, test_predictions)\n",
        "print('confusion matrix:\\n', cm) \n",
        "\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.xticks([0, 1], [0, 1])\n",
        "plt.yticks([0, 1], [0,1])\n",
        "plt.title('Confusion matrix ')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression model accuracy: 94.18%\n",
            "confusion matrix:\n",
            " [[1758    0]\n",
            " [ 109    6]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujEVg8_C4Y6J"
      },
      "source": [
        "From the confusion matrix, we can deduce that the model isn't all that great. In fact, it resorted to predicting every app as free. There are a variety of ways to improve upon this issue, but we won't be covering them in this lesson. Nonetheless, it's important to be aware of misleading model results.\n",
        "\n",
        "Let's take a look at a more comprehensive set of evaluation metrics: accuracy, precision, and recall. Precision indicates the model's ability to return only relevant instances. While recall indicates the model's ability to identify all relevant instances; and depending on our data we may want a higher precision score or vice versa. If your curious, here is an in-depth discussion about these metrics: [Beyond Accuracy: Precision and Recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6JPh9RVB_oX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b822d3a8-1f82-4c2a-beb6-5b884a446ffa"
      },
      "source": [
        "print(\"Accuracy: {}%\".format(round(model_acc*100, 2)))\n",
        "print(\"Precision:\", metrics.precision_score(test_labels, test_predictions, zero_division=True))\n",
        "print(\"Recall:\" ,metrics.recall_score(test_labels, test_predictions, zero_division=True))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 94.18%\n",
            "Precision: 1.0\n",
            "Recall: 0.05217391304347826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMvSCZRn6ATD"
      },
      "source": [
        "What's the take away from all this...\n",
        "\n",
        "**Always, always contextualize the model's results.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDoNhPh367sZ"
      },
      "source": [
        "# Summary\n",
        "\n",
        "- We use *one-hot encoding* to represent categorical data.\n",
        "- Logistic regression is popular and foundational algorithm for classification in machine learning and deep learning (neural networks). \n",
        "- The *sigmoid* logit function maps the input features to a probability distribution.\n",
        "- Linear and logistic regression are very similar, they differ in two ways. First, the labels are continous numerical values in linear regression, while they are discrete numerical values (0 and 1) each representing a particular category. Second, logistic regression uses the sigmoid function to transform the input features into a probability space and the model learns the optimal parameters to maximize the probability of confidently predicting the correct class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mITAGLVCRsa"
      },
      "source": [
        ""
      ],
      "execution_count": 191,
      "outputs": []
    }
  ]
}