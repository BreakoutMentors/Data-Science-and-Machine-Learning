{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_nk8MGdUFbu"
      },
      "source": [
        "Adapt from: [here](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb#scrollTo=oKOjFuwK9HI0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6ajYKVDkxB",
        "outputId": "c1c298e1-c116-430e-b6fd-8493453c42fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (3.25.2)\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Collecting gymnasium[Box2D]\n",
            "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[Box2D]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[Box2D]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[Box2D]) (4.7.1)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[Box2D])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[Box2D])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[Box2D]) (2.5.0)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[Box2D]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373075 sha256=987e1c555b43e3a123edc8148a17c520fdc5febfc3b170d8a734ea9cc17c8eb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: farama-notifications, box2d-py, gymnasium\n",
            "Successfully installed box2d-py-2.3.5 farama-notifications-0.0.4 gymnasium-0.29.0\n",
            "Collecting rl_zoo3\n",
            "  Downloading rl_zoo3-2.0.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sb3-contrib>=2.0.0 (from rl_zoo3)\n",
            "  Downloading sb3_contrib-2.0.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym==0.26.2 (from rl_zoo3)\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-sb3>=2.2.5 (from rl_zoo3)\n",
            "  Downloading huggingface_sb3-2.2.5-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rl_zoo3) (4.65.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from rl_zoo3) (13.5.2)\n",
            "Collecting optuna (from rl_zoo3)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from rl_zoo3) (6.0.1)\n",
            "Collecting pytablewriter~=0.64 (from rl_zoo3)\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3) (0.0.8)\n",
            "Collecting huggingface-hub~=0.8 (from huggingface-sb3>=2.2.5->rl_zoo3)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface-sb3>=2.2.5->rl_zoo3) (1.1.2)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter~=0.64->rl_zoo3) (67.7.2)\n",
            "Collecting DataProperty<2,>=0.55.0 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Collecting tabledata<2,>=1.3.0 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading tabledata-1.3.1-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading tcolorpy-0.1.3-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.2.0 (from pytablewriter~=0.64->rl_zoo3)\n",
            "  Downloading typepy-1.3.1-py3-none-any.whl (31 kB)\n",
            "Collecting stable-baselines3>=2.0.0 (from sb3-contrib>=2.0.0->rl_zoo3)\n",
            "  Downloading stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna->rl_zoo3)\n",
            "  Downloading alembic-1.11.2-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna->rl_zoo3)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna->rl_zoo3)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->rl_zoo3) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->rl_zoo3) (2.0.19)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3) (2.14.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->rl_zoo3)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->rl_zoo3) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (2.31.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=0.64->rl_zoo3) (4.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->rl_zoo3) (2.0.2)\n",
            "Collecting gymnasium==0.28.1 (from stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3)\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (2.0.1+cu118)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (3.7.1)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (0.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->rl_zoo3) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.5->rl_zoo3) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3>=2.0.0->sb3-contrib>=2.0.0->rl_zoo3) (1.3.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827622 sha256=3b15b890e6da0d73387f5fa80831c50a98fc8ceffa9bb38738be84aa40510a76\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "Successfully built gym\n",
            "Installing collected packages: tcolorpy, pathvalidate, mbstrdecoder, Mako, jax-jumpy, gym, colorlog, cmaes, typepy, huggingface-hub, gymnasium, alembic, optuna, huggingface-sb3, DataProperty, tabledata, pytablewriter, stable-baselines3, sb3-contrib, rl_zoo3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.29.0\n",
            "    Uninstalling gymnasium-0.29.0:\n",
            "      Successfully uninstalled gymnasium-0.29.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 Mako-1.2.4 alembic-1.11.2 cmaes-0.10.0 colorlog-6.7.0 gym-0.26.2 gymnasium-0.28.1 huggingface-hub-0.16.4 huggingface-sb3-2.2.5 jax-jumpy-1.0.0 mbstrdecoder-1.1.3 optuna-3.3.0 pathvalidate-2.5.2 pytablewriter-0.64.2 rl_zoo3-2.0.0 sb3-contrib-2.0.0 stable-baselines3-2.0.0 tabledata-1.3.1 tcolorpy-0.1.3 typepy-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cmake swig\n",
        "!pip install gymnasium[Box2D]==0.28.1\n",
        "!pip install rl_zoo3==2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3m0Gxt9ckOM"
      },
      "source": [
        "So we have previously studied how value and policy-based method works and also the pros and cons of the 2 type of methods. In policy gradient (ex: Reinforce algorithm), you probably see that your training loss is not so stable (fluctuate a lot). Hence, here is when **A2C** play its role !!!\n",
        "\n",
        "\n",
        "**A2C** is an abbreviation for Advantage Actor-Critic. It is an RL algorithm that combined both policy and value-based methods!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caVxDjJfiMtG"
      },
      "source": [
        "How does A2C works in general?\n",
        "\n",
        "When we are training the agent, we are changing the parameters on 2 things:\n",
        "  - An *Actor*: performs action(s) (Policy-Based)\n",
        "  - A *Critic*: evaluate the quality of the action(s) performs by the *Actor* (Valued-Based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTSpM0fjlXX"
      },
      "source": [
        "### Step 1\n",
        "\n",
        "![Huggingface RL](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/step1.jpg)\n",
        "\n",
        "- The current state $S_t$ from the *Environment* being feed to the *Actor*, and *Actor* performs the action $A_t$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRqaAy7Pj_Xd"
      },
      "source": [
        "### Step 2\n",
        "\n",
        "![Huggingface RL](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/step2.jpg)\n",
        "\n",
        "- The state $S_t$ and the action $A_t$ are then pass into the *Crtic* to compute the Q-value at that state (do you still remember Q-value?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q_515AHkJNd"
      },
      "source": [
        "### Step 3\n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/step3.jpg)\n",
        "\n",
        "- After *Action* $A_t$, the $S_{t+1}$ and $R_{t+1}$ (reward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUfcvOKakNSG"
      },
      "source": [
        "### Step 4\n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/step4.jpg)\n",
        "\n",
        "- The *Critic* is having a say on how much to change the policy parameters (by the action value estimate $\\hat{q}_w(s,a)$ )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbfJTFkkW_9"
      },
      "source": [
        "### Step 5\n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/step5.jpg)\n",
        "\n",
        "- Here is how the *Critic* will update its parameters (**don't worry** if this look too complicated!!!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lLui0W2ItWZ"
      },
      "source": [
        "We will use A2C to train a [Lunar Lander](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)!!! Though we can use the [A2C](https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html) algorithm inside of stablebaseline3 to train as usual, there is a more convenient way: using the [rl-baseline3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework for Stablebaseline3 agents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0YmQIy8JySq"
      },
      "source": [
        "![Lunar Lander](https://gymnasium.farama.org/_images/lunar_lander.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rqv3RgHrnbu"
      },
      "source": [
        "The following code will train the agent to play **LunarLander-v2** using 100 timesteps (and using the pre-defined hyperparameters), feel free to train it more if you want!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsG4L4qmToxc",
        "outputId": "7b7eaf60-fbec-4f73-bf3f-5469f8c5a0ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-09 20:13:05.165159: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-09 20:13:06.030313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== LunarLander-v2 ==========\n",
            "Seed: 3689662668\n",
            "Loading hyperparameters from: /usr/local/lib/python3.10/dist-packages/rl_zoo3/hyperparams/a2c.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 1e-05),\n",
            "             ('gamma', 0.995),\n",
            "             ('learning_rate', 'lin_0.00083'),\n",
            "             ('n_envs', 8),\n",
            "             ('n_steps', 5),\n",
            "             ('n_timesteps', 200000.0),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 8 environments\n",
            "Overwriting n_timesteps with n=100\n",
            "Creating test environment\n",
            "Using cuda device\n",
            "Log path: logs/a2c/LunarLander-v2_1\n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120/100 \u001b[0m [ \u001b[33m0:00:03\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m950 it/s\u001b[0m ]\n",
            "\u001b[?25hSaving to logs/a2c/LunarLander-v2_1\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env LunarLander-v2 --n-timesteps 100 --progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kn4p7VmwSHw"
      },
      "source": [
        "Next, we will record and play a video of running **100** steps of our trained agents!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdB0PU1GTzy8"
      },
      "outputs": [],
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFUiIY0RT0Z2",
        "outputId": "91dfb87f-6147-45d0-da4b-c541dd8ebebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-09 20:13:37.497168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-09 20:13:38.757104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/a2c/LunarLander-v2_1/LunarLander-v2.zip\n",
            "Loading logs/a2c/LunarLander-v2_1/LunarLander-v2.zip\n",
            "Saving video to /content/logs/videos/final-model-a2c-LunarLander-v2-step-0-to-step-200.mp4\n",
            "Moviepy - Building video /content/logs/videos/final-model-a2c-LunarLander-v2-step-0-to-step-200.mp4.\n",
            "Moviepy - Writing video /content/logs/videos/final-model-a2c-LunarLander-v2-step-0-to-step-200.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/logs/videos/final-model-a2c-LunarLander-v2-step-0-to-step-200.mp4\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.record_video --algo a2c --env LunarLander-v2  -f logs/ --exp-id 0  -n 200 -o logs/videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oit5llYTT9T9"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "vzk3VlngT_ps",
        "outputId": "bd550892-c322-4001-ebf4-bb34dd3dad7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video alt=\"logs/videos/final-model-a2c-LunarLander-v2-step-0-to-step-200.mp4\" autoplay\n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAdHptZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSByMjk5MSAxNzcxYjU1IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAGwWWIhAAv//72rvzLK3R+lS4dWXuzUfLoSXL9iDB9lNeCiACYAWPGnfHQcKWB0+JNq2H89w8Cah6P4WuDv2dKX66egM2h1Rp9vqZ2hQ4eztHDSFY8RuBgPlAu6WNcXNDJCCEOkKADkBJw59gIkp2l7PuUG/ppa4osXr+mxK/+Kz1gS6aQaeo6O1owc5/No+3hVBdpr/CWta1pZnykEmfZqsBcTuAYZnmWE1n/XYMG4rUp2Ud2HJZHd1R12YfLTGvJzn12ocp6Heu6bS3OAD+Z8kMixsQ1uslsamzvq6mX4/OLjgZHkoAAAAMAAGOD2ELYlCN4Aq4vw7fHR0fr7BKchngXHKKlmmLhnvvdWtEy6NC9h81QOtsWi0A0kgja1JsSi1mlBTRU63AACJgjJJkDyQggiokgxBNCDkjIkWA3wAAqyCy/lkaod7cgjPGDhS73GOMcdZoluy/xfJO2QkRsATOeCUoqmEP55jHACnkhHVj53vLjINhqflgR+GYRLPSBs7Tkx9CiolHOKtjGrOrCX2tPXIOygMwD6V6Z30mz+JdYII+bQgUic9pvmpFJ/Z/vRBmVdlF3Mjhdz7UCk+EKAr1pnv7eXHW82RsBKPDqzSeMPhSXAFqy6aLgnL2i42Kie4Vs6RkflItFJHycS2obON0EMiU2/l19mmQ1Gtr4RqXntWPg6ZRR/rx2Z2hAEVS2fyJwvSmzUVUDRr1RFHfNKrGJc/4YsOJ2GA6l703P/WH+cQ5166rF6SI6S/1JCZTu2q8M9Oix9JjEkVff8+pku53soJ9gKmhYTSESo3o4cWsz+YyJ5Ve9M1imAAsJsVAoRzlY/OsMGvvmT1X0gnCPSZ6YFSTLtmQb8BR+vcpaRhMG75IBGlabNlnO8v2M+zZQl0LJt6D31Qp5ZjVrEN02EmcS2vpHJlHmuSUyBhjXRO+CJ8W5m8DJwKEl4PwlzyT1xdt65jVcwiw8IUHmDkW/HMuED31l6B9kisE8pdwEudZuwnwEfOVWuJ4BS8kkuwAc5RGO7yrf2WaSsodE63nd+YtofKf/B8djZkCITqDo7mvxXQauZcpBrysR6CPOOlu/PBKglOlnmE+6GHyEn1dBhliN+vRKkjAghBZ8Sjs6q99Lgh1GqRUjxy+cYo2z/9EFNE8UknZr9y7oFfxFCUrNZLgSr6siu6+MKgkm4MNhe4RcxUIOgt/dn+L8bae5VpYtkleGzGqqnDdQT6zeQwp2YtPUoh2n9J7KLCrTtq7VaRFe/7jUlNkoO4tzhg5ZT5HAxW2DtrFKWDcK4WH3nK/CSnzPeABKnEReDBAEFHbr+6AIqRZcBwBGGYJZGM/mkj/BN/Tg2qY33wVHZDHGEudLJXBsPlHuanS9zv1WmeeI7BSs4M+wMT8c4Va+YvYvwV8MbqNzMmSRySwwGZUrh7JZmRYh1DAgrmpx9Zo/Y5SymhiI6wfQ0tZymJRypx2GJGJGHN0eT2tptigw7V0dkkvLnicgFBzlys7CgLeCs3PpcECxA2QVowAFS3r7NFUNW2UwErTGXnqNcHs/h83oroq0WHAznusIXuXHbntkWsgJB+J5fSjwVdBJqrFDuoNA709BgWh+Oj03QKykAylaCeEC5jkj2i7q/R9SPXuqpv1nPIBpVoYIrrdTnG9jl6dLBx+oaOzRw9xVsn4MQWOzJVMOJlEP128wCdL6vFckD7kdCbAWk4XnOQ1VPsb04kgCNHV6jKLY2BBMh2+Rwi6uAhvuShaDm7oGLcUlRVWiRrF/jb5wpDx15HIqz0VCv+6gmDJRjdzpiWTluctKizEigrth7rgVq+LWgmTgpv6IH1UuINC3Vw9TvmylgkcAdcbWgfCJJfx3pfoe6WmrHykqOCAn2Z4A5wWM/34u2TW5pbAt/rLsai339rAwC4gBnMczfTA0MbXLWwKKdyziUXrVJvGgmAQ26N7XXRtAhnX9GsrrPNvSHrXwYCX4krCX9x5IgyRDWPefaADG0xIPO0UimDL5NdLkt4PuuK7ge4EoEzIDN5nSePhxR12/QnhSnsb6UgUAXJVDqETzz/jT4DuV0k8djNpa8F6IAtZHGDXw3vQdGELhohcChX3hZywYi+oBew8FmotC5PStoaJdZc7BqToA2yKhEZKBzOaiY5/XGkxbNKFsu659g1qXSo1Duho1w4R4rEkh/2/JtWkNdfRCSPOeQMzc/1hmglkTJBbS/9rKGQw5ssAK02TI8U7g7OWNqZw5zCEBTmxlQyz8YAGL312ehupTG82UtHz5F3jZgQ358pjQCzrxcDNBNoN0gAAmgAlQB5UAAAGWQZoibEL//ozTM3+fj60cLbfuN/rNSOAD3SqtfR2XBauxbIikY0yuDtW/k9ilufgEAWuoYENbgybT6BB/s3UYH31tgCaRiUe89cVmTghxXbCgzDa0+STJ7+aIttXvMvkkrexN4r1ZTW5u0oSO8rw6ir7+hGszJrsa0XyV8aK+yk3nAAAM0MP4U0wuNDAjTtg88PGlYiCuc5hF4TWKa5QHOblbL+sWbpagrv9X98lnmQBoHuZfIkke921TNaKHXq2EsuTZCMB0fBqHdcx0JNXOOim8uVywzEYJzXJEGdhw5XDSIj1MKwUxMQlzalk89BRcrfcOOnQeh50xp2guuCHtgdLuF6kg/kQPgE+psCX1vyAfaBFa9cZxcMuCS//rTc+yLyirfg9+Bix9tN6smlfhOAEP/Qb+K53mYGu87NpL5BF1ldx+KIiBVYRR0YS/YZxdcxUuie9DS4fJY1/TbpwVi1V5f7hKl6zoe5lYt8q5/xpqlBZGkiWf3fIVcvpA+kmx0wMM/j1gYBjy55jQ6RKzao93ZVAh8wAAAFIBnkF5H/8VFXw5/3B+NQSAD5hsasR9P6D32zGH7akaVtsxOOXf9oab0i0W+kAD8Kg+AyqQvioPHDSbpZGzglxcGKW04/qc2QseJM9tmR2pRD5hAAABAEGaRTwhkymEL//+jMQoflpU8Bg0k5gAnHSX9DtvSexYO3YWwv54CjNbuXW4tQPz/wRxteu69CIB/d2Vx6wzqsKSmi12Ou+bEe+/93FXh6G2EillFBjNW1y6BBvUUvKCV9gonU6wVW7ij2/BaWP09nAzIAAAB+PHkoMfu2AK2WIp2mRp6tafHHzwZrmJ3Xi5n84je57OTkx9GmSnmJnCTtEezFV33bVNE/cLRPVpTfk/XIABCMQDsmw03tOV3hkr3jXNK9laURCI2zKFFAiOWoi9EcXsfDNJGSQR7/QvB4GWBMkovoFaAHmv7T+orvfYw5JyTNTyMjvmwHZ4DhHQj4AAAABnQZ5jalPCPw2xgmk8oUAI7/k+bm2sTCYy+ygJWbjKsMAEsfpqfWKbQc6KZUR+xTfPCELrAA6HYgO35b7BgC0o/ETkB8Ws46Iscd3D6Nj/UnWjNJ5oi6bfbQRG5j+/dWjebSDOQDAtoQAAAGkBnoRqR/8SyErq5QNwAcAeztbZUi5e2+VCwZJ3tor/l58bgv50Z8+1wdNydndrBYGz4egbNurIRQm5YAfG2SiQuf4ogI+YByxS07DEOfa6+FkL+eFmlcSopTHlxF/8DMnfi5gzJRrFj4EAAAD5QZqJSahBaJlMCF///ozGum4WFUbaEIrAAdO2BtdiOKMbV+8zmuFtZdCReN+pMFLvnvbGrXZS2Boj4x623eDMwWBWLdN96Z/vdOXzNKeBryfDyw72vREWc1NnUx3IbjGEE1x4f5ADtnAf6St531oNLliRMwk8w1Q3id3aBiU8DbuT8KypC8jnm4ESEs6K09xHpBjn/6B+zaonlf7guKGeBr1wjvqO/gB1lGgqlzXqFa4JQPui2DBdYQMSzxulM7XVEe49B/RjRBt5/ne0MwS9BJ1HZqFpZr49aUAXk04h+YQAHMYsw9fY9SwY3EREW0NmoPyX0dRfhH+BAAAAlkGep0URLCP/DfDCkekgEufCHABNW9qrAKH3Ilr9YWaZd/r3daet47Z9tixZIoCAyx+cKFnupzp7kRuQynPkFyvYVgn+dBpWLpzZ5d6UGiWlZstev/KtSlXEqu3z0iaRB7tLHcUUUVL1aPnLovrhumfidwBGelyRlqVHzxOHKweFf1/FUFwOTuexSfE+AsKyQ03kfOAakQAAAHUBnsZ0R/8TBCf8AuhlxCAATUehHpavibGXwfdUa+NKX4ouVtDQIy3LbwYXknaZVbI/I249GE5o5sotmNFj35q68Pt9qu10WmXVe+oV//Fch6mgB6JFvlExu7kABkufGeTkhC4xWiRRgB3vm8QpjkMtX6hcDugAAABxAZ7Iakf/EJ3nywjLL3SKrRxiyNrJBo+KABXJ3YO39B1asGr3BkOUP6mzUomXB2l35VEJyuGUUMUBHH4crmIvkENUiJOIY6LK7sGYSmN8mWukaywADoa+Df/tRlUqcHm1faIvSOMvDbWih7fbLBVCubMAAADLQZrLSahBbJlMFEwv//6Mv2Cf1nz4hvEFT0UApbzBGvuBLqo+s9aAQDUIodzrtzIhXIYZIGTxdPO0CaKZSN46cahqWgK+eHuCfHAVdALG9uyL33+eav7LgPN2L76/O4vyck9cZah3G0OMI8YbMdQYCN3rOX8UwIUOn6rTIYjrU/X60nF0Q0wPwukX2F7c2UzX6zTOh70jqviaaT140Atl/IBhCtAryWzLaNO/GcOQ21ZkZCNdjgAJ3rNoIA3eO+u3a+vceej/obmiJuEAAACZAZ7qakf/EUVByJmVp5qd2qCcvwQBDkViYBwBCA6pYmfvome+SFTfwt6wipiHhtOBlJzsELKK7diqeJXhbEdPXDusqkfc4UnZgOfeqHyjz3p3TVS64DDt6Yf8CHratkgfOHs+bTropQDuQTNtkpohHlYx7cRm9iZy6GtV/ffC8AYMGNCSqLfaVmC6Fe+Rm9iO73W1v1rNMBHwAAAAxEGa7knhClJlMCF//oywCEabz3Mcc5GSRnBOmhxEQHAAE6lHrA0VLuNUeflQizB2qihM7BS++hEHnawAZJKPRJvJbwkB9iUrpfCk0giPjs73j4bE5EQ2SKlrNQ6DIQ9hgghq+XowFAULJGS9BUvUVIx7fwyFE+wTIq5XKde5p+0dAEfUiI1Q5tptUe8Bx/9fAx6UrcOcAIapKlfgeRHl+rgkCPPdzIgtWvJ1xxF7vnFhEimYer7tKI1mKSXbb9sSfutSFTAAAACQQZ8MRTRMI/8H9Rvs07fHf2cBH79RnQCEAEsa6qofVtvFZ54TDVDZNjovCPWsWlwtSPj2egN44+cJCSJWh34VSAK6YZEPFg6IOuHSnaClQMzHNY+MUbQhlrJw51fx5gc/aoBcBLRml+II4mezh9fv5mvjO89WtgR+fETaIcH0L0Nk3Vg3J0lZ+qS7Coy3WPVlAAAAbQGfLWpH/w2qb4u9Gu2VLI34aSVQAfiRd3CVR2mR+WDsgdokYF9MHzSjdwoeuKWzo5qT8Ck+K52hgWfhoFakzo4Xwk+5y+MvZR116cDBbfxAgE5RF/ai/uYPcpsyRProcG0YeKdn3qppvuO/MCEAAADdQZsxSahBaJlMCGf//p4QB8bTld3E0fcm1ABwbmGGxVZBUGshVJIlOdHtoNka/IEiJZr6RFgOZfdI8JIdZcIwos3uwfjEvdYrm6QH6Wk3VQYJmxLqnb9A+lnpO+mwP4758HRpS7yWgpeVu+XYDJcUUNd9TrewPIoOh7yCaKhUrZl/AAg8donRCm7JHJCr3eRa4Yl0G93TlKHAMaUvGaqydeE8o2G8aOa8iNT+eQyf0IVKbtkNDdN5H6LJeRiB7GAni8sUEV42L3PE8xlB/JeBkxNebaAlUyFCk8Dg2UkAAAB/QZ9PRREsI/8IVgN3MwomtrNJ8giF8+30DlLRp0HkuPKzk5ba6Sa/MFEeAEqpw4tMBXEGpqAtZ/x1LBLHz58pUxStgpFAs9R7H9spMGAignAn3++k9OFNKBkADWRkvJ+j/49ivTpUdOjKDsgniIGOxKDP+H/hYWpJaJSoddv9mAAAAJ4Bn3BqR/8L8KXex5SAFTjF2u8ch3L4b1qlEtI/Jhl+uaLBuRU2/9HU2wen30L9jPaSA2fc3A8+Aq92UKSCRCRyOd9uTD/HPZt2Fg6QqZw6qKYS8Nt8Jt9gCqyV8X28LWLVj2aRjVl3G6bRxO0/pMwN7k16+xfxFjRBBiF2+aR0sxT513QCpdFlj1LWGgby0hitKJ021K4D/Uyu93ipIAAAARJBm3VJqEFsmUwIX//+jLAG47mhar/xlQNYZRjgFBi9ikv8fH1K6NDm/sViOis2UBIvcBIGMgZD6gbtfvRhGJtDkKwTwdgD0jfZ71e+d8yGKgJ3l7k8LZeSiZplhteY9nBIKVXz34+LdBOrKLnHeSJ6OfDDHVksmCDlmubWwpZNZOisOZ3vdw4ouy6C/YQmCvpRXn+ziuMlT8PWzAEQZQOMmExUSMV18O0LznH6p5j+EAgsFQYtV8eZsBfVNuhBlZ2A9/Oa09Qjte7Yo6eayOUTe+EnMA3uwnWZWDuQyNT7ZlFB8ikM/WdQ8/9BEkaT4G9iMji2km6RlE/d3QuftKWr7rAWOzMaAEM5dHUD8narg/zBAAAAyUGfk0UVLCP/CFYDcRd+HOnZ5T8IlJ+4t1wex9K41VBrQtDBj72NSIAON1F6gv3AOvHMmpQEJS8qqbWBsbc+8+lLBrR8EkulMLIiB+UNhsZeeeWkQlJN5FhXnxa/qA1jvWlLSAF/7pYDzidXfsbRgmBYX4HWVr0icxoyHbor4b72mFQXCQ97/izVihEy7Ry9F7vuNazLHWXu2UhdibQgkwZ4KoA/LCQT5UziBBXKT0Ohh2DGJtek/JHbGNMx8cpSIsYZeNgGumJetgAAAHwBn7J0R/8L3qbF0CZC1QdT4ACuN+O+J5gojg5JqWUds1AQyM7Vkg7ok3bwLhZRuzbN7uLALT7Edkk1XXnRpjnTUyxtQNu41KlBAVNLg7ARLlUF3fv9+pjIlysIoIcMU2xYaiVoGuoQLXee3yYqJiCe13EjatT+hZKaGllAAAAAmQGftGpH/wvwpXz94h6LMM0QPEXsr9hqFjfqnh0GDg4w0LL/YYAJ1ltCzQrviKlnpbu+pdPf/UNWb4t68cY9ehviGJsfOb3pNu51lRElMwIeqjRU5uc9hiXUd6QnzvlANigowz4RAf1tib1vbLJfYjIkB8h1I6z1UccA445YCIGY2h2t4Qo33LKBz/goAUGRqswMRGwv+m5LuQAAAOlBm7lJqEFsmUwIX//+jLAChcy5eG6kqcYUSIEc2fGJVoYAF0Hzf27i/8H0uJJcygkWJHgasPG40bBORXIkSVATq38SjMh8zi2TfIU/OhVreC9Pm8VFuzi2Ccg+pkBkcFOnkE/xF2CyzvAL70prC/1W4gsPz9JPBNqzXv/p17TEqG4+/ik4cg65h6IBDpej8ZPV/DhjQlVCwpz1uspJG+lmo4dPAS2NtK6lvZxQxmatS8HidU9NC1J1CT3wqGoY3smvKifefc272lxrZ+FdCuo4Pj8ykfO0NSrNPDozbbgBwFRElrGKJGsSFgAAAJpBn9dFFSwj/whWA2IytKY6UoqeNNqI/6+slufpYk4ej6kGkALRWAwpV3YmPfIr5F7yaf0eibh128o4bd8Va7rQl1i63mqGiBVJawmfslKr8kVJh4vfAw0Z3/2PrT4f/QO8/fUkzmf05JF4Pp9tm4rZ/7wXMZ7q+1N9n0tL5l7whd5QcFKQxnpx/MYUxympXLOIsv3ZxAGFlQypAAAAhAGf9nRH/wvepje5Yj9iKymd8ASU+sNNwOELMA/y27/hv0QPBMVDkMTJmg2eTyANiJ9cUDN1Lz0PuW911nEKZCIQAIM0uhP0TsogyYoROgmFRPxAeQ+/EGuHd/M7sdVuriQqw8fRpoB0Wpg8M1uX4pYhSsVoTFfAAcMx2Y76zy0kghdiwQAAAJIBn/hqR/8L8KVfk9N/q3/ehEIOmhgZ/Oc+MZFwriaT+nO2gBNXQqreO1TOsGClcu3wa0N1OsvXNHf6KTWEy6Gua4ddD6McNr/1Ht/xuvNiY/bOc+JDO5zvp54/UgUB0nelp5e21M1IuwM6wsT5LRyT4dUWdj2AbEIoVj8vkJV+m+Uw9LH6zR88IWMgYX4P7OZWwAAAAOdBm/xJqEFsmUwIX//+jLAA7/CWffcNCrMYAceu+O5oLGPwYpHQHsOQ4rnj2H6vn1jhsIAkA7/Z0yrCOJDBz53w4PgHJwr/joaczKUQxy9o09UmreJyZT9ExYVuFXTBgudnMFwXt2usZ/KyFEhBkisercjr3pFHVtwAYVfKwjC43dsUfHANzQ+z83QKJIfxbeW+dv2+bD7oWIzWO5ylGevtPFZKP3tRN7ay8JQo9ngARBX/USD1YYIsB2iKwSU9k2wN+5S4zucIBIzwfI1vv8P41TVdaKtkqX14rexx9vRtyTkxdOoKopMAAAB1QZ4aRRUsI/8IVgNcc4lCvK7t0eccrL/WOlQycSqJtPT7kZOgRKLgBCm9qrAKJCQZ/6dJBrXoBPqu5gey7tPApsK7xquSKaUTE1Htu6d91m7bQc7iMefxTEm6X5CydXq+vmXKj5jFXyaYMmkZdLNkTU3byTegAAAAcQGeO2pH/wvwpV8SbqWZbpGLc24b0D3GEvOWqbZ1/qphpCqj+UYpp4cn5lX/YB1xmABtM/70BrlQ29GGRv9iUdzeUV7C0SR2cwVEO/fLG2WjVPhEmDK2SAF9vs5NCfZ7T07njgqKxI2a2wW+uTdnOClTAAAA6kGaP0moQWyZTAhn//6eEADo8J0eiZ4s/iQ07lydCSxAAC1q29eeBHz8BZmdSpxXNobOdcr0eMb+yMjqSBBbk9meVlkAVOuIhSvbFeYymcb+0PzU/58aM+cb/taXMwWzBECWusq2TOlBEPjvWRatdaObN9UX1H+EW7IJwG/7R2V/I2vR7WBAZKMgOPd6u/FKYTqwmG0qvurx7r0s1h1tm5O6VhB8WayBqot5+T+oZabqjqtQGmkM6A3szPBCIwBIgo+1Auw98YCOsk3WodYvBD2SqJzmUntEXwRgjOoTTIToTGaN8bmE1f7/MQAAAIdBnl1FFSwj/whWA1xW2sQDRvxsU2aVH/unDCc2wGPLpNAmhwISvaJb3f6MZ4MtWmKhnEKhiXnMy3A4TndV/5+8ALqKrqdyiwfnXB9h5F0Dss6IIh9ninWba1Bu5Ya35dsY3RJ0RCx20psvKYw0da6Kclqa8UTTkaOLsyT+yTu6GR0zUxIjuBAAAAB8AZ5+akf/C/ClXx7gcGRGaqCLglndXWjoXazDa80VAEWrJolj/gUAAEpVVSLBcx8UMeIjCZ+nMLTLi+IU3HipTc4wa1o6uE3FC4FikRPbSXtQITSIKM21FpHzLqItgUC2njPYPUUo4qs4cn3IQbl3BIp9b36IHZMYx1vzAgAAAQxBmmNJqEFsmUwIX//+jLAAW/mXIxJX961LKh3QtgBEJeTNJrLHvtMx2ABF+2mLXD+BRpRTHwXyBNY6rOe1gmiUDL3+3kVEA2IaN9DldW/f3HDlnZ9HK7NC3PsXxIC3zxVl+Zx9MS3s2R7pJAMltxDOJk8QtDvyDvfY7cAKEdNDwxoVtEmjzvp21YWmtIpgIkrQEWG/mdvzHHadc9i40YkBnvxbnSl57uyn6o5jfGEUA3ZQAae7hu4miRotDZSCR0CzNcMAdhuOXoTS8MkpV3m68RXdGait6rxyi68+KanDIoJBTGDPbSPDjmMPtInH8N/4pZ1q5dGtiBmMHLg2OfNiUsJ0f2gJB+SjJA/zAAAAjUGegUUVLCP/CFYDXHXUmtvI8np05orXGIWvik0JWkj8B/3IrJYKlQLCyAG4Oqu8BePLqp2dvuyx0Pftdcu86MSSYzgBdTNsCQxrho/sxSVtfAiSJMLQ5U7d5WxjIxdwbxThWAAo1/RfsjoXT5sT/BsYGtEwF2pv3Mj2soK0eIea5/1oOpgIwR3gzIGQ8AAAAHABnqB0R/8L3qX+KFJMMQ89p1ksZCJxho+SeoPPFdS1E3i6orzLXqqHlSsbVb8RmBVwAbSKeG+fZLEhj766oX3bAKr9OWBKcV//bBfqYEbagwlFF0silZ6YQnpbv9vxSF75INZRFlpuprcPpDP1Yq2BAAAAbgGeompH/wvwpV8fAdBC3NNIGsxUpa04+l1jwu6stojn+/1ID+KBdOF4Nw1JxGeUwABtKQeXx8E/8tY0wGobf0ey7BkdVs13TrD03ZoEKvGamPKBLsFq0L7P0Fxh9I1BWzAvV87/kD22VM1JjWJgAAABGkGapkmoQWyZTAhn//6eEABYZ4yRcSH5xbgs7J+AGbFsoUSGzjyCwhkXnIfcqt4SEYF5fdM1O36n1F3I5VO/2Bf4EbvqjF8x5HSMmNSD/xblJyVm9Y7pKZDskYT/HdHR/ly6mjjaLQZwbv2uQ70MRUO4yW8xKQT8P9Ezx6FnT/td+j3Ux+brASo/+RHh3EO7gCviqKYi6/jnr/b8Ci0SbCT9+u5LtdLAmoxfhtbDtkb+JjUSZWAmC6Yt2fVVc/JY7Mk5V6HdqVKZqn7QuOr47yi4oFFyAKnf6sSQ7IPa98i78V/i8dOyDycZQz4N1bR/57HzgFRqTiBwIlh9AVTmd11rTLcm72NnDz7rHthiAYUVY7NGAAREsbBdwQAAAHpBnsRFFSwj/whWA1x11OPrBOSvUWpnfPHlJteh9c8Q1QcarMKvOBR4gDYigw0TcybLQQarsBIyavtfE9eABxZEU5pL5F9Zhqp8z+bFg1iywI4d2oPlMGky2K4zjZWwuyK4A3HU7tlmO0Jb0WLDC6iW7jk29tdQ3RCxHwAAAIEBnuVqR/8L8KVfHwkaIAACw7ywYFnEW3XMgH1FDeHhVfV+wkAEY8gJZFV5Nd3KwOzvSk1qKshw/fDJ5y7cFZmBMnZ0TZTWn4rTLxyw5V8m0OgDz2qpVQPqdk1iV0CZnbeWZbKTfuNKGbiKWx/fc78TbKkmDmSJEOZdbAAKSKWaF3EAAAEuQZrqSahBbJlMCGf//p4QAFj+L+D8hII0z9tjYArTUP6iC7vhoWfI0qMop8CalVsBbqhw5LgudbA0j7v0/3eB5RUtIRPeyrORzH7NUuckQBCEltzsfQW1jDvWY3xDp6ajEgjNrSF0y7NUGLwxAriBEnclIIgxYMAqYyCLn9bbvbILUvxx3Rda0iIKWc+DJIPA2ZJ235TDiHI2codiJ+ZflT8Ho9fMp+bigyTKxNhU8UBr/vdGXMDDau/K3YNaa7fgLwM94og1XCOogRsYy0JfkJn2e4cFt8ZBBm80jk33NDvIDjEHjqg2vtPHrzjbi3xbet84uSx/LeRFNgYX/o6ZNr9z0pST3rgJ71a0ZzhSymAQcBHFA3iYt+eNn4FQVE48VNYOZeMfuMNMXkL1YXcAAAB7QZ8IRRUsI/8IVgNcddTjaDqwsYKbp4ec5tGZ8ch6G9nkHZeUTc/JxOp50SGO10MtzvmywGL41NA1sOk5awUaqoWiOQqNsH/WpBX4O/5EJ5h9h7G+hsCiSLWEdDhvHAlAe84u1qIvmDlCyXlSAE3WCjdKCm13Mn79bhOAAAAAhgGfJ3RH/wvepf4oYp7NHtxfQRvB5E9Ht5j5wwJupXZocmcb8861pydAhws/5ZgAXBZTnmhceyjucW4GNFQJ5xMvjQ/zUdPh21wSgXO1qECBGto7ze9gwP+IGGnhCZqojrqSrV+1t1UcsnfV0GuurATYQcCeUACb0bHr39M5qhhlHza80nMCAAAAnQGfKWpH/wvwpV8fCQi99S/MCWb5a/94KgWcGCJRlucEQwg3j0QgBO3aKmQvEX2isPlPYkakHzstdtCYNjXeHDrP3+9q+qZWAAlgYqjc9MRrdpwK6GOYqEtHxshivgdHCWV1TDnP+QY4NML6W3dp0mzsfBJZL9QMxK+ep1n6RWNSMUAgYsKL4GnqzxMJ4nSO0PDD1JbIG+SLkQtD2XkAAAEqQZsuSahBbJlMCGf//p4QACHcefA0EQKj14LQZwPtXb1jITwl4VmNBa8Yw0QxoQsriveskt0btHWYM6vOncrvUEv/mS0AktkbHGGg7ZsDi5Ear0O1Ck9FnU4yWrjcCiXi378st002or8567kmIQ+yH7BS7ZzlAcXnoZCUCCprlMZXg9o9qdPbFWEoYUhN3WRpJuTZ0KsONQTsGWBWXOgejrD6FXVwOvUeTPr/MB0veQS/CVJOD7usLYx9NZmtaRBLM40SKEZwstI7pefbVotXD+rO83pzJyeN890ina987553jW8W6lCjZhO3q+/wFi4USYmPiyfz2BhOFyoZ6TTpjOyjK5v6f+lnwMR00ddt0daMb7roXPb4PwGhU4qGMK47VI8mAxQAMOCJCwAAAI9Bn0xFFSwj/whWA1x11MKApcz5Re6Gph3S6vearTSX648im3maBZ1n7sXovTFQof5dkfDW83rkVMnzPhdRhy+W2oAoU0f+j1jDZE6/zna79srtDcHeowRoEfmDSbrKc4rcoJ0QRLt2V7YGRFLlorLyhHOY9y5kIEts2KkzKyCAB796AE3BPAb9fITPvbBWwAAAAIMBn2t0R/8L3qX+KFpkbFVArMK/4b3LijmIr049TCcWHKFXhksiAFXHfcUIByLuGl09W5Q22GsMuD/igkpL/6yq3fOuA3q/Nl83b9XVvYWL4p1T/sbCeRshC1vp/GTJ9XFqy2tJ75yEfO4li8XYdPFKTnbRGI0JUNkCRi2wPpN89X/HdQAAAIMBn21qR/8L8KVfHwWSDqkXxhWG81/jXsUDwC3qTj3wAC4rElx7VxYdJ0oP3sELQykDlPbl4JMWPBBxfEVinjHOE8PCykkqSMZK1SAJJFs9uHtC3gsPhOG64lsKhS3OHPpXFF/5EyJoV3w8lSHnMyHmPBlDEVpmGFEtnKxIH9q58hPZAwAAAQpBm3JJqEFsmUwIZ//+nhAAId03nMMjkVv9OLcqy88hhkHMAUwJY5BBWEo5GasPpV5m8Oq4lhpQDkevnmakAw8e+YeN5+4XT/OEHpUn+M6hXJB6oG6auQrVFqJlKrz9yy2hNG22EWqLHIE2Qx6ftW2KZkfUcK/4YYqHYgnyVAaolOy2pS/tQqKRFZxQXnYQB4LLiKb7EYIi0odZbmOgIUKnVzPfJ+AyDxIIPHzomAJZn7NNhj8/3CFdZU9J1WiRzthrw7TzL9/6ndJr/VTazVLBXZNZCF88ZeMaiIGXVFJwAfoBmBdhTPF/JMKIOB8PtNBb+sVrg9ANs28dCOKoNWM7FJ+LtC1PiNTBdwAAAJtBn5BFFSwj/whWA1x11MKP/L3sN5dG5tQvOYA0AAlEqhG/dJK9A5caGMWAv9NiEbG9Mxg2PPSFdEnYVjuo6YEn6EBEELXYVKY+1lnLpDFxuNkNmnc8W3zQ8I05GzB65QgCYEz4+cMSBcHmV7n/6RmMV62yQKjIW7S8YmGwk9yRo6m9XURjDI+BX2QgXmXVjf+NmRgY8+QwpIC48AAAAJMBn690R/8L3qX+KGJ2HLBDU0SQSam5XOheNHtHy9ZCG4v1aw0jCvYYALn/6C7SOjfuIMVVyi5zAPx8XG/S+Ok5AoWgwx3JnpEyTydLNKQj0G1Q8H9YsdMJw3QY37fDF8ZsH5/ApYSDWeQxBiFWJGCF5h9U/tz6eVNehbYcWaO3nvhukvG08kOE9SYwz3sPTq37LAgAAACIAZ+xakf/C/ClXx8FkHK0YO4xPEXP2FhIbWbUIAP504pVv8NDhvNXyUnMwyhuatIyWfElFvwTCeADsxnenwNq9g8xyklq/djUvChLrXKDrTTfCJK66yccor65Rf3ES+/z6iD33Ung7M++gH6DH7BuxWwPTXW5OK4geDqMKxWccg4VBMjVsZMUEQAAASNBm7ZJqEFsmUwIZ//+nhAAIaiKAzhNuex8OU3oIQn5lYo/h5xcF2cwUomK45h7UYjocEMsqtMb6RXSh8cKIWMWW1W/zO3PUTaARGMN2LQToIVidp5+WxlDzENrnc4X7lWdGnBhIpOsKDMYrssUHNlcWUOjrW0TA20G4k8amPogA9D7pkZWnNOaoxtlRisQqs+QlKRMAf432Gnly1XqxjdT04MIXP3IyLjjCenlF/VfHJRLYOprOXRed7Snoo+GnseIeGbMqI4QmCxkFCxAKJ95jIWhgFg/Uip09M9hMMAI4tc65ad6InrEBPLWdSfb3Z2AGozEq1PuC2u3kciz+n0tVDSJ/FzrZ0EvDdA1eGvS1lnkwArVvBWubov0ylVCqmlEhYAAAACuQZ/URRUsI/8IVgNcddTjaDtE9363tsgrV/KK25yeZ5fOjYG7K20aAE3YGd4raHn5G7PzCGu6Vf5U82r0O6o+hSFPMKjla3qrr/E9IF6wiaZ+gmeIqloAeoC9YcANPTdiyDKLibZsg9CRZqiSvJCFtZFQ9ymoIrt4mBRckrx8p+Xbub8l3sEhzzP5V81DtghgueIiwVvupBWSMKB8ISNy9EBarVCkpHI31Ytasd6SAAAAjwGf83RH/wvepf4oYrs/KgIm5AZE0wL11hwV3uAbnI07AAqA6HqePWHtV11n7UgfxWzzz1SmehUplkoB/GM1+mXKBTba8wZjSbxrIEBTdKVtVZSUmy9WWBktZJUr3UZlVb+bvotuB78Jv4vgOpjRI3NgQlLEq8MRAiL0FaDFiR93wVDTMJV4R5CdnNxuIu6BAAAAYAGf9WpH/wvwpV8fCRq55NZxztA8rNNkE47l8AOae/gAW1cSUKtlqQ9OuMfeThTp/04xxiUNKcfYiNTugcpZKVF3t1jqZAaiHPUsx8MgsoNZL9bUm0bXpgVHHjzzvMJPmAAAAPtBm/pJqEFsmUwIZ//+nhAAIbRY7buxri3v/qAG+I8xQyp9n45I/x7nZJ1ensu4FTclPRxEyXD8Q78yqCuZvqxLtdhusmTFcBhwi0/aQYF1sEl7O9NseieEOaB7Zft+D0xjlhsznXF6Pbo8OGXwiViDSkAORCaJOZr4orTkS3TIz/NNZXsXcQovAxYARG68xGsAb6cID8Ds8bPuQkPhZI9jS8zSjEbMCmPSJOelvBpBcGvZIBB3iQFHwx7hnZwKL67VVRAFW40kbXGEYzh9aYq38YcClEaU/LXhujwtjSgGICvYn8CmP4bFUe/24RO6cSA/SwNC1m18azUQ/wAAAIVBnhhFFSwj/whWA1x11OQUrBAq/4fn0V/qA0whiSUAxBfASbyoPSOIAE2GxKk6r22miaIsZaGeuhS3DRcVRI5HjD/n7HhGTBXpno3PFjXanh+aLfw+EUOlUFgRHIr8MAT+tOx4W7oxcnqhv2MGhhDU9YPGtSsI6zqhBA9ye/JXdUYXRiu5AAAAgwGeN3RH/wvepf4oYrtUCVfLsBKXy0F2zU4lvDFm5UjPsk50IPcdMFnCQIAXD16D9pdsI+n7saXRD1cAiTnRAXGoCheZ6SUp6IDQHNa4bYrezxUsqmi8Hndv6hqzpG9XS8kokRPJv0ercDds5Wxua2hcbilvnAfBOXM5HdtP5Jxf05UkAAAAlQGeOWpH/wvwpV8fCRq54899FGA5n+jBQlgLQtaNAAfiKdMBrxKcTExTH2gjtgjiols9hgziSaa/4aHs5N2f4wOS97Ew9yfXEAB0d0KyAL7spRZEd3OVhoY9orxUIMkzu78HUUntE2Nm2ED93pWIdWu2xGgynaYSUgWUtDk4vBoJpZk+Pqp51Rj4oCLN3OO79dDENiJXAAAA40GaPkmoQWyZTAhf//6MsABZPs2LixKqG6AP0DcYANuF4PlEUmcMyqUzvii3AP4/FB59yLTEHKmM1lMXxO/if+Hs3kVW6PAFRh/BpIhHlAApnNJkVVE+BfPJ0Ta9qbH6qjp/3LwRzI3WbjRwn73Qpdhj8WDYxBEppp3zGuFmv/D4i+javjSU0+LdJvwOgeLZB9wgE+Dcp5qireHSeUEUcoDafRc1r/9yl6iamNWflSTsy8FElj0eWsHOmIAkFT/ZQ8ipv/WPQ6lr7JOEOk5+qmapDSY1uZ33Cg7cvJT1DkPgABgwAAAApEGeXEUVLCP/CFYDXHXU4/KyxgnJixr2eqmIKHN6N6QUQY0PUNhRUANRfx+LqWvSbzteMlf8/kXwjDUE3oMTgHRdcSOZbd9vsYiUcTrJT6rmaMNTNgu3n36WgXD9DjPgr+NPeDA7zTmXK4vtA7ZUJ0y/B79b6U+ORnXXieEuXjgLq/zsucPiG+FVNOHFQg8FmQ2oeiqcEy6PzmSV4kZcnoY1E8XdAAAAcAGee3RH/wvepf4oUqsqKJxbKKxvfrkbIQZP8rlFBAk4VXV+mRs53Q4AHEfGPvJwgtVgxstlnbb57BCd5dmEom53tFSI68f/EATJRMjPaEcmq7qf9dS0mkZi1SD4lH4pJiiEoEQP3qvfcE0ufW9axVMAAABzAZ59akf/C/ClXx8Cy4mdVrMBAt7KmeAoeYrmN334BFHcdBKYIazlJVWWH8kbgOzW6AzI9nyD3EwmAAJYzhoQ4YQJy3DyKE1D2XROOvk91vnUPjK+Z6idjF6OsHUjBSvhHt/ez3rPgAy3mzK9r3LEfPcqYAAAAQVBmmJJqEFsmUwIX//+jLAAIwDdbMiwAs/xWVKhNpwnBCuqsEecNiGWUu74P1sEKP8Zc14wV1CU5oplFG+BBR6BfDQURMZ0c618muwlfDaqCO1ZDGa6CnlKz3me2Lpv+XtqzxQ0ds1YYy2pwnB1y37mWZYGbpVTY3c3f0hVok7qN929rmwOi+ZSde3upJOJB/+axCGYTITBIxbKGovSj1s6K2slz6V92Gcj8x2/h3hAl77dF6dcZMA8BYxi/V0w8ADjy50FYc5XdZT0Q31zaZRH09ngBDWLqp4qpoOGOLpeuC6BoWtnKaY79omESMVE3XMDQ9tZ12A7c3qZ8NyUYil+u65D03AAAAC2QZ6ARRUsI/8IVgNcddTDub06yYf5UpavbRLKzrIIOgMw+8/ymrbTFBoT5bvvXHIo5vXxQ2CIcWOwBYQp31fgpwONoACVSEyCliM89IoNGYz4po3LVRlFXnV502Qwck7TBGBMOefVRNAOe81yScyw5U8rwx2QI8x+JIjujQK46Ye1Wjll9LocHK93lyIPJzyZPLIdD+gyF0i6BNxfJDCNcO7MtERXhUiWPZGSL9XM0cvTNlxrsoEAAACTAZ6/dEf/C96l/ihaiwuwJk2TZdgALdJWzq2zHnnxruijX3n1XFElUTEkWiQJ+WNe0ps+tKwbLNAxiOn4+1NUSdHxcgrxDMk0r7PASiRLeFrxEeGg173nvqLSI4V3UfZY3rbWIl/v9WQT1DccvKUr0DJVxFP56yQNG7/TFkT8g6Ivf/lUJEevgB5PFbrFewb2cwpuAAAAjQGeoWpH/wvwpV8fCPPuz6145QS1YsEQABZ08WALWg3Ezq5lSq3j9LuITLdeH55ZwuUb1aw/rd2Hxkn8sxvtvZT4Mo5t5JaZTWdMOk4tmC/6jBIgD1sfbYXyJNjRq6/F5iKqJLr3xR+5JaB9tiigjUiP4YdUbklDouBpQ6Fq2FEZtj4GLKFPM+eVpQeVNwAAARdBmqVJqEFsmUwIX//+jLAAJCFyMbPjuwAXSnUy0WHsfqNskKVkZA/cBzB19wakmD9+4YmAx7JY0s1akEiibSJB50tVYtJJDRAgzCBwGi9z2ArGx6DjEM9DJ7hBQON0XPzMSXj+4y+aou3CSOZr4aK3Ew2uedS1JrCRCLLcgEVG878kd3D1K5mkzW7ntMQO5BNjY5YBeluAylX3T856S77jnf4TN8Y+qcS2X9rIVOGAO4TL9wr3TlX3Jjg93xffegn7pe8f9sV+h4aQLgnPzcCP0lE7ZFelYk1V/0Y2f20zqz9YdLuQwlyTgwHJxAVoZr0VWw/ENUxTVETUsmrT3419dpi3IGsVA+BtmaYY+MLCbiVb/tUsYeAAAACaQZ7DRRUsI/8IVgNcddTDwCNwWHxALc74zfZ8rCfW4bcxZv9y4mqz43pQ6sGPFTzaxN2xeJg8+gTKChsZg8XdWvbrCxiOA587GUEW5ab6UhJLhHNZvQ2m7UI4BK/Fdydk1O/LZMm02JPnIG5r6QOAz3yN4d/pMU9SjY6VZ1u3ilL7yTALj7kgySTJh1I+UYacthwYmJWWXZAyoQAAAHABnuRqR/8L8KVfHwWxcXLJxU5bcLCyZJ2j286XI6r1eSNxhoyqF3eoADYfviK/dhsUJ7eNq6XtnJ53pJlCwywBpotL+TALBpgt5L/cCq6fLAeNPtAclaDLirJht+HizAR6wB1vN6LKd/lY2pTiL2TtAAAA/EGa6EmoQWyZTAhf//6MsAAlKxKVhKMAA2o27W4kBs/stEOB0jV4+ddJPV5K3LHU2j2I192H4zW2Dut/scEeUUmetrQg3jElXk+lFkAh4NZROdyHPQK/Ue8qa4zAL+Hpn9nC1HqxQgUpZOFZBsmnkg8Qk9cnKt9CfbumnmBKXemMbA3vuVKUeqzdu5DpY1DjoVguN5DtHxC9KVFyAUI3nQdgXffB9hNYgu9yk9kQMKQTEctFUFIH5l6QchxtJ5Yt1C/gKRMGeK65e5AhggUad8wp8GKylmA5tz+u+wpbHxfS24V1vSONaMPHwQEdGgWqr7L0D30WL8JfnGkfMQAAAG9BnwZFFSwj/whWA1x11MRJx1Dl65hViwb4uSNcobMRCUFd5siOM3eeH00SdR7kNPj3oAC07kfevATjTkU5VVcaQ9Q6JahcAppyXyTjl8xMcNKljpsgyFOMm1zLfJhl8LWwWNFvZK8d5g0vxL+fAysAAAB6AZ8nakf/C/ClXx8FvsFIVbrSdAkgmVgALd9mmMwl57TEhWT4M/ECnMomTfZLNNR8C4cegvn9MCMuXc6unHSsJ5VRKAMP9g11qJGJSMeImJEOYD1D9Ra0m2XLjFLilAY7QDBuDUbuaoy9ZjhCUEAQanfAX1j8xSBIS0gAAAEFQZsrSahBbJlMCF///oywACYA0iVzoEAC0LwTTIK2B7SYAySyIjChIgA+Ny3JGqlP3c8rTVd7izZw/R/Hci/aFGq6/DejwJy/DxYbJgaK0dSfxwyXlPMOGxqGL99U6sNLcQ6uRPbBzV3g3/dpH0i2zp3PJseGEU6JPqtMD5MgIzHbdLuYJR0R6R+ZWeAuzegiDYFgbRiFz01bcR0B/Zlupqq6+w3ydjixo3tFZ0urJCW6dgwgwRPL+4cGAeozuBIuyutXX3t8ltm8uqRnObBeJf8KpPigQm3BlaBu7YTCM4j7bjQRYQXbhCyClhdfQXotue+SwXWK4wIhIzxhu/CRBSA9hAVMAAAAb0GfSUUVLCP/CFYDXHXUnGaZoWneizFVCc0GDi/kAKyQStekksnFuNwzoww8pF6LVoY0sm8M3mLifwwWJEzP2zWPUEQ9tgoReYMUxQHdbE1wjBSou6jihfPzVS6Rtc4WFwKaf5u8GSDf3u/3nmhEHQAAAIgBn2pqR/8L8KVfHwXQHQhHTQQ7FAAD1v1lJ8Z9rA5LO0Y/7xiBNBZvPHi4ebRMSkftLONeczEJvrWx7knHg8jf76MAgVAOjZErXQ1cyeN2vHrmn6byRMaWSvxWjmji2blojugOS8zjTvbZmT3sG9y6IpFvgThQPc+v/CTIAP4EV6w/vmEtc53QAAAA90GbbUmoQWyZTBRML//+jLAAJfn+jjxnGAggAAC48ywykMNtxjuRralJlsXOYKeI3ioBcPNRv4wrxEO89UeTUTwrLmUUhMbSwouR3EOkfDRkELSWBvVKvb18wSxSkUpLP+OgYCMHYgFuTX719OVkW5fulrC5fSMXLCwWf+H39hfT1HbDfjjG85F6c5YeFdPcg//t2nxqzoFN/J5FgbGlx+J7TBuHV9y1BuTrQIxe2ApRralcuwU/J2rX5fmDnNgvLv+FUnxQFa+IN4Vv3ew546G9s/se8Wba8TDsGASwXMqaIXhz280K0iNwREucU8p+jc4xKPC3GdsAAACQAZ+Makf/C/hhf5I1YUGkU8aymmUvzM8wEimIsZWGtwBTI+51acRzkcr4t0blFhXI3GlG9wgADjdl1umgSS7SR2Ot2xyhqEk+pjMUHBelqb4o0jtZXYnd7utVMUP9bS10n0+LAWBg2gbKf4gcJK4+uFaVYESZZHY9ZQUXUwhLRZ3fJi4TpxufNdypCX7nHoNnAAAA40Gbj0nhClJlMFLC//6MsAAnANjjizABcjp4FmRO90/5jjvkg+CbmTVSaEKCDDuD5P6QmQN9Lx9HutUaMpiSquObi+nkjexfUtP3wlmeNnua9OgZFo2RxSvaLkOz8A/nWUGKRooQ9k/v/nnOFq7IBcGlstfXeslHfz00fVJH67l9wl6DPrvK3LXfXRvkziGc/IMDnotwn0TxM9DqamhnxP0NS8ItaYHf92N1sWhQaFWFldQexfkTpKV94Ru0VYwX4hYEv+F7eLmRDTz/N3CBr36Kqtj3wtIcQ4c5r6cTl9RQAA6pAAAAdgGfrmpH/wAyXkPqDAZ3uKhNbQdXQKKfOwmmFgGWw1TvOj1eWP+jyACu7JhgA36rr6MZMssf3tpC4haab5O3czJIJUfqZkIfcp0kORzd/1EsRbwvzQbZzvF5DuYGlXqFdCuaswtCVe6Q4LRnpRkcDEqoss+A9IEAAAC1QZuySeEOiZTAhX/+OEAAmske26+VJSAAFuZIuL/azU/cTNx6xBbwzV+MEY6S2SPnaujHXViKMilUkGsX4D97IzKvyh+s1iN0pRh14a2+QAKSqwhT2fA2ThQu2tGq0ote8o254Qs0bNH05stDDRqeGg79Zg3xKA3QE321I9PWhXnNuPhJnzWH7bF/sd4B3TkTb9t+ik4z58bWU7V0FnU546NugX1t9fjcSmFA4djjnON9B+BxwAAAAIZBn9BFFTwj/wAfECOMwBo5s8S0b9zoS1J637gNNYIUsfS9pi8bb/FYynLxYArfUmqUGz9z0nmcYoTqbSoYWOzCTJTQj/Nzx0dgv9SZZkFGiX+xHc7IGwfq4wYLYaw78wrJ2wvYgfYA6Entey4HAR7TNkdlsCTe8Yr4SDwiEDurKTZyZPrKBgAAAHIBn/FqR/8AM594BX+cJiYODQ3gcERQggAJqJbvBYGpVAXdFxfI4dcWOKGgpM0413f2emBuDFgkh2b+Z3O0lCY0X1FqS8rOEO1IqhPVV0SmmwA84QuFXNNowEAGPF6Q9TefigmLuBs8le/ycA+1JfJK+YEAAADYQZv0SahBaJlMFPCv/jhAAJ6jG8VkfTiE59K6efgAP6nAWp85+dNkN1d92ANFpCLiGm6EfdDPy23cuGrXXemUmpB82LiiWgTIcDbHJHQvBc4cgiNS6o5EMhHWSEDuK+pr4VNvdEMiw9vuk1eU+pfyxprpl7+okxM/lCRnCnoa56I0JhxZpPD3SSTD0sBMa74bKURRpWjjUNrGldmPLGoLamfXwL52a6O36HcQ773JhxjzUTzr2QeG3GFhlHHHgWLQA7KtHpr38ISN0bRKI4T/4QVyIVOTaWKCAAAAhQGeE2pH/wA03jBWAPe+AnBoWilg8Ex8iBC932SIlgq1IfCIGRxpsL2CmbD/UAAK5ZRoasQL9IxDUzjweTSS+vI3k0bLJcx8GgylLdbYPPJUCvs3OzY9AfpV+su9gcflpWFVHNh5x05TgoLXevCaag+cAG0AQnSqOWloG9w0/4tiVlKkApoAAAC+QZoVSeEKUmUwIX/+jLAAaD1vAesiUkvvCUMVUS6AEf8kWtpSDIB4byIxi5CpW63DZv1MGzL2M+AT6paVBkIBoUM2h5zYFNVZPpecTgoZZ+WsUr75RI1JqEIQWSKnVAktngrkGViYTwEYHzkVBSZhAc2wZyQHYGUvsJtZNoDMNIWH75NXdBYWpYJLhVWgEyW1H+Lvz6iDn3TMhWLK7pjvGOdj4QvrGPwUxO+I+s6TcszXkOwE+kDEqY3ES9gIOQAAAQBBmjdJ4Q6JlMFNEwv//oywACunVLKb+IAEmPRY+6TpQIhLPuvG2PskMJptRlR1p7ftDR8vPakpAcmG+Qvn07Wbq7ELmAyVsZL5aTNt7PUwWMf4JEK82fp+TIMBZSUn4ON/Jl8gTlzSgUNxECE9dzm88IxwOsClYviiBttfqRlx4GZv4envfKDq6EWCj0BXMkoeWaZ+qjSRV/P4z+DowLyB+7Tp3P/FO054euj0f7fV4LeAE1gB+UgyCd8nagtEJp4zvkL6r4b//v01Z6eSFERcHhC4AUDwEzcFPI8FAO9TItvci4YskUZkwSpN8VgJZO3DTLy6AgQIIMIyhnv5DD5gAAAAZAGeVmpH/wAWLKgqBQ7bn7HwTYWcbkFaVqyrdmaIBScx+cq1tqczdGyM4AipOv/KgAQn1YmCx+78xsxWQoahxNM9Yw4h/LmKgjfWxF/sU1GDy36jeq1Sy4/Iy354OX7wJ6igA/0AAACgQZpZSeEPJlMFPCv//jhAAKgomgclVmju/v++Pp/hgACwpz2LfebxWqIunTkxKnDUhTvlFEAAe0UQD85ph5C9/XLdKcs1CVJXNahlKy2K4dRgPUW7/5PIfCuK4Nu4OnCkkJyPqMTXwXJNrRSfu9NWkAaxSjzlwu1BOnYxnMrPCllHvdqAOWoJixpBFfyqRhA1eXt7DO2HXrw42lryySBpIQAAAIEBnnhqR/8AOK/fwKn8NdpHiY9wpU4Gkv8zbiou0k5hgAuovKmQvEUG84Cn3MomDsHtMu95Q/lBnno9PWUINVJDK6UCKaaHUFynCe54jCSARBYAjyCUBCrlkUmqvgRSqBCZpvySAI1dQU6MorcVAFvz8hky/sRuIzwuAYGlt7BgRMAAAAC4QZp7SeEPJlMFPCv//jhAALDHTv9ucAIPygwPnBVv+SHW+4Oj8u/U75qRS9X5uIt3XvQCKGtLwX/T0FnX+lO3BvnKd7EyE1oCNaEvnIO4yBpSAOyYC5/FcnViJuQMimmhgfpJMFLzXpF/4h80V+W3jmfjyR7lOJI9r7V8gdYoaoMWOPnwWaQGElAieOSWpk2I0D9QVQ1aV6XDd8GPVonCu1O1DUAhHCyACFQN44jDrvV5oJ+Rb+BJwQAAAJEBnppqR/8AOhAC6/JezDMlpdcAExYBza3WMZ/sz7PNwsfgwb4T2kZc46Pgdv8+1otUgArftlk9uwPZ71HcmdhakxESECMx2Qjzeueu4c2T6ZE2e51mSbwaO5r/It0Q35bhsJBcKsHnj4rB5phjtAMG4NRu5qlG3I91RijfOANIw45S85C2SQt/ydq0QY8E4MCAAAAA9kGanUnhDyZTBTwr//44QAC1R1IHmhGaeEAVnQucGDWZ4moC4d/g0lWUlDOr8Okb65tmKE8nP3KuthI3Fs3/ZYxAhZDPvIJUgrw+SGrOI9dhOd5oXgwXY4aWmhFORoMsb9CKbG9y7ESR+SLwhNriBXWvu500Qtf6vKjcwNjO2T7iKeBB2UgjQOCWIOThk8OmUOh8UTsNoW37bohKX3FuFBPi+BXSPH8ZyqGkQ3T1/rFRT6T4SGeOiku0a0/vk+IAZmiIUFMzg7wIxvEk18D1/6UsrJzAvc58TQ8AwILBr2tX7/HrfUQosoUXfKIgTPbVnfneAcPtgQAAAIcBnrxqR/8AO2/fwKq6JtFESW/CWK4/dS87IeMjiAUSC1SVKaS52Iz1G43Tb1TADjCEOBq2dQfDwcK0iMXXKZrJ/KAm7vfG841L1ZdUomiSwpyngxGutbUeRNcT2PsCMogJOVrMwWGErP+SXYX0pjycnNOqTlAES+YR92ECfAJFVKMjfiwQDPkAAAD5QZq/SeEPJlMFPCv//jhAALVHVhO4UwAsBkxbN9IPlFEcd5DURkrmrjVAis1tf5F9Tpu7an82PP0R9drtmixBpZjpyq2j26dfxnjFwsd8yaJXLLk+ijkIEUL3Av1A2A+PpJYqijiMC1/DQF/Vx2UOjpbWgC99iy8GgyIptfdM3jD1WGiY6r8rN5zUMNMI88p2KoPd0w3lvHe+O/sc+zkcEBSpqryfSWIFtkohQm2rMEWdhwa6xibKqi9HJs282pbGwEAGYEz3YD+HCQhsNvGfnTv2/ZWIUO1xLnXMkJNvORSqylSardGDsORPlc8fjLQm80wtIE2V6QqYAAAAfgGe3mpH/wA7fe+9832+FqmidyOWdU7tt2O38rClwc55KgAQSTeKgYNoHBnaKK20phX6Yqqp035w1zeNpCSmWYG8WlN1RehwNQPIlye7wY32355JICwJHn9b9GANTjHAdPCSy8K8TaOZVHbNqeivjeR/pf6FF5m4TyUEfzDivgAAAJpBmsBJ4Q8mUwIV//44QAC1qHOXqcl+GAFTEJ7Y2y/5p/2GEf+wtDyzEyvnjtPY5sAY0n+MyRRo0Vwe/aY2+5NyT6K2i+k6WWgf+PcDz6aL6lYI6MLbYlrXEzKRTPVLaTe8htbKB4bZ1ckqQ+17GbN8TaZ4AXaGXPa1gFyomVqOn35RAHpQhxSjP/+CwOg8YScTLDrCHNhM55+xAAAAvEGa4knhDyZTBRE8K//+OEAAuiitD9vOax/UABZ3cMmC+ownU5+76Ib2wbnUfpVZvzD61BrukFXkEu1GOnKqq8USCywz8KxhPzKVHlrqRDrYQFuF4GNXjj2eCCFabpzlO10yb+tmVDZfZ7rKrPIjmEFNK2AQ9GQcqtY+Pmn1hC+01SUQU2u27Zf2XdS9hmC0+opkKe80GkDGPRNzCfiXfhh42ST+KZ/qXRJfzY2o2GrRoO6lM2V+a0ozqSs2AAAAgAGfAWpH/wA8ucCzUSx/biBV0jvxLvtTj/iSKbnjsPiwKbbHwBVp7+dgW07uV+gf/WqyhIsfFadw9T5hmiY6Xyq3qJPNDHgccvPpW0lBvZR3gnleRS3bJHPzVHnN2Hv278L6Xsu7dPInsGT1XV9yYyPKhY57EERKZIoAA3Qr0C4hAAAApUGbBEnhDyZTBTwn//3xAAHZuSNa3gnlgIANijLGkev8jR3is0h7m6pa2XV2hiSHCjfhCGT4EVhD/jGEiHxLr5uul5Dco88q8lViyUCWzujchBtBXMwfGF0x+sBSG2QJehCtZ3W3+hlYoFGOoQoMjvdZM4a299uCRU4Vpy9VFFtdVlPIVgYJzGK9yONfDbsMhtW2wrrZEOvHpNYgH9rRd2a7cbJOrAAAAG8BnyNqR/8AGckorm4iMQAt1F/6VyU6v3R8zKn9kBGgPeOwIDGkBxu3Ie5+syqgtpwDRydgcN2xQKF30/dJuP9fDjYqSujMPpjDil7CYS9Hqhrl5QxmLfH227PdFXbf5mrCQ3u9g8eESZgZBv5+AakAAADJQZsmSeEPJlMFPCP//eEAAw4r53xr6ANvbCjGxs/Bt/iSBHs9sr7p7fyF1r2hSqEos6hcM5IFVTxK3H7SWU0L0739jktCai0DMg9bByquUbDPaUaUEWVFLKfgSK9BQ4+Oxhwd1C2f8sc74TWcObNZFy+qq4rIR1SpQ74OwwB7c+lewRrUvhaBkiUEaYlFJ6OWrwAyDxWarDIhqd6W09rxmWaGiJRN+W4ZeG77Sy/NhJIOnztHMZnKZhoHUCwCSJRJLJnxwVrGShBfAAAAbAGfRWpH/wAaaSitGhqgnsUO56ncu6A9poJf/hr3pMCJQTKtbUJ5n/CQPAAODP86N+hgDpy5oTpHYNXjRMF809sXzCdaBQ6r13Dv93M0g6xOvjtwEZoHaWTY/b9n+SBEwGYAxm6ar2FV1LAScQAAAKdBm0hJ4Q8mUwU8f/yEAAw4DkpTNEApGcYRUau/K1vM8lLPmGfPMGa5cuDkH9G+D0besaQbhwETUssofYs01OGgtn/v19hvLoI7w/NsaqpVf3b0weEkH25UiUOYq9tIo3k5VrFCv2KzzZdONvRKmYv+46GteCeaBypH7xcDnMfghyIcyloxsGBo84CQlhhvyp3pbjKg9b5B2JGUu9LxtSgk3QC8RgB6QQAAAIQBn2dqR/8AGwkQKzHTOdAFmvev28QyWrHzV8peHCTbhXY6xAj7LtyCgAna3N+mnWcCSAEogaj6z19t1Z1KZx3tFLgRi3IOPUw3r7lxqoGDaBsp/iBwkrcz2A4ch9KpwmsxtrJNoeYg3vbdNZ9wMBmgIwmldpp0LW73LNY0OFUAMRagA9IAAACsQZtqSeEPJlMFPH/8hAAMTv+KgU5n4WbE8YAj3d5VFrHjN1X+53ZFnNbZYORcrm9kurNss5BI7rB3hRPyNhEVnhsk+sBUWHtB7RNo+4qgf5rUuJSC5FB/qwOjOEqHR5qA8Ax2MUWWnAbJ5IZjfChltnvEw1zDSpnbRV8GlDWXk92DBTxXjchOUiWrLkwb9F5jZRoPC3DQULemIAKodqE9K71niHrckDvNcOuWXgAAAI4Bn4lqR/8AG6khS6ryDv38YcrzD0M7FdACa9igoIQNGBU0zhybH+f8G0YTJbVSqLLLc6UaegS21rivuYBW5QuCiZMPcfExud53YKYw/LkbIR+s76G6yVUzCaGr/s1AyntObZ7BaXIaGmBgpBVUbFwNkdGniLTRjFfBZVExYzPmPIbGmHTgHiOWNfjWigg5AAAENUGbjknhDyZTAhn//p4trp2hKXDgAfvlqy3RmoX3PAFUCleCvBbo4gjwrC1xaZfvSCLlye4KsP0JQUnYiVXrvusC+oYJ3bR4sF9ibgGxcxxUTH/uY0Tds5EThjrPPQOjgRphYZjc6Ec3Vb+67TsjvUSdZWxYj0WDbfW0qlYDZtLndswNJYxOoXda0hUf/igQNqUutZw6cw2eb+UgIbqbiOk7e6YBRwTpjo0HwhmD1h6g/nVlMur9e/LIquKWXVjkzA8hHKkRCfNZh/EoFT7jISFUzfItfx89QRsTVweHr0TDfzh2YULgzG7BkvIng9AYY32R4Wos6w6Lpti1qyv35xGQ+r7sxQjPyhfAPZ5LYkfhq4FNO/ZAEI99GBDQWCaYTaVt2w16Nwb9FCqCNv1ymfaEZRA2TwkTZu1HAUyeFfs+9SmfGzD60Ve7DMVxyQ1CIwKeipP/M1/s92gACyIhmCTyX0jX3GzmtCDCG6dTuzs1dEtFe4/v1gcbx0FeYOdhuccVnHePWE1kg6i4/61Ikx37m/Mx86V1j2NHIYrt5iztXrFkSWYCPH2wq1e8VyhrLuGuwBTzPtpqaonJiMp4DS8Nzm5zvg6bOfual0YI+h9d8yzKyHbZKDNnSLQ/j+1QziSYr0+uUkRoE6Mjlp3tAlwThBTGNmNLjGuBg30DSXeLeUdxd/WVwq/FySjBqYTzotKfGXLOQELkGv1D6t/WcroGQDgIvWmQW61nKQoICznnJsszrJuNbvFoDMriRODWZd3BmxjuEJE87+YJ86BLW5yvqPLfak94hlq/2xVy47lr3hWiY9MYdT7sfHAKsHqivXyuQM+bq498m9ZjR10bnunxPry3wp9T/L2debUOyl0wRYG7UKJnm0XnYBKc3lucWhaRA4Rdcd4zdMNcR57HyPBvSMzbPJjmsQ6PHrwnlaVOjSRpAbSPBQBbiHQ/A2xC3L63PqwPTKiQBd9Gtpzgs2BwGUrmbaJf4AtJjQuM8UjH6udCnsrWRm7dFqgMqKXliooBQ34vZmeHnV38/zzzcIvypoJs4EpOGOZb8R+89jWD1/+gfI8/hAYqmLfFvgdW46hF5ycp9dEIK6cu3v5ooDk/LWjkwzpg0pzxiqKs0zeXEvFGlatQxjbeiM/mSII/gn92qRpcbzH2QVohoUl2EkRv66/33CKheZWtCqONeIQ754DrVm97HCT0+o7b9zocVDqP8D13zGw8IExKgWtSj8gMl6rWJx/O5a9ukoeVJShHUY7JV6pXgyHKg4NDxNpORRV233E88kquSRRTN2G07cQidGD3mVnDdVtrIRH6QP2mAa+xcxfrCryTsNPq+U3mG+12rRPbdnaTu91xCUzI1FnesyGG0QtKqV6PFLZNYcNHEMGaKOHywnVJ40njJrI0iVjTE5MJdx9JiTGjyvIdhqDmbm3uUwAAAM5Bn6xFETwj/w95KJIk8WIFGA+gkNxB8AFzgvAQ5HaYTtg4Pb1JhFu0CAh29HeHBTQ7x0RYQe1+eN8ConFmqzYQIDXO2NjAzY33SDXhd3U1WOu4YocH1DwCo7nERDduDjcIaE3DZI2m7x+6SsaoSHKBAvVJFsnHzK2Ny5e1lWarVNHZKr1JiVP3IejfnM4qlG7Svb287IFFmN0v2ajuC4AUgIlk0+UTOn6pKU2Sn496Z6w7JINCtNSEDOOkmj95AjtDWnSygCWqckZVZXrFfAAAAHsBn8t0R/8AG5wr3MmFA6QoAfGHhfLS1mOFcYF10m1WF7tGgNhe0ZcPRxaZQQaL39xar0gKjMaGarLMWKNK6+XolpLaCbs29JPCKk2M5fWtDU1CpGrjEIdMJdYpS84RdU2NFCIvJUz/OrN86pWML1hj7De0NX3LJz4QUkEAAABfAZ/Nakf/FL+FrLj/DQPkrl56D6FkSkNSVeABaeSC1O12AAZ8EzS/aV+/2T45vklAUiO8FAB1s7934nuQu5hR/rYYFYiluz5QqeqjL47LuAKx9jStvq9qbB3SmBxGDQ0AAACIQZvSSahBaJlMCGf//p4qjjEtr+KFDCIACyYZQFKQtbaCutBLB9Vod2PWtxSGcNl45biTA9UTHTPJsbwa2Tp0YzLv45/YHYxd7HBu2zp3TD5eGd5YxZKZmIJodEyG067Z7glKO2zUra10NbROs97OVBrirJjDlFI6T68w6tC24lG4+1zc2MBbQQAAAF5Bn/BFESwj/w8813dlGjF5MpbqABdAGw2Q8wHg7yFVSaHiUmeSc9M3TX1iF4SrGih6B4gbakNb9we9eHy+m3gDeLpZHvPyHdwqgU+bP6adjedGuBwemXmtFaSAhCLaAAAAPwGeD3RH/xUXMlCqGSpgakhbB3d3v8aeoQDZJTLtMKs3LRyjnTxAoQVMAAPVDDMB/gldLCf5D5g2Er4FSBp3QAAAADcBnhFqR/8U/VNHobiCpyT9FJfV7KMEZTgM21sqCivdlUD5rce8N+A2jfZCI6GseckD7jo7AI+BAAAAVEGaFkmoQWyZTAhn//6eIXNuB1L2Ms+vJHpwAtcbVmRUfvPqcNYjk76AFBU7rmEyhW7dc3XasVfal5nuhqJR+bU25p4xuEdh061Rj8w0UdZwf3DHdAAAAENBnjRFFSwj/w3OWVt6ApPB8s0WKcABWbq8+AHRuA7f43Sn+hiEj2h/ZoAoBmQGZo0r/TLzPGg8idfHPg7BBhMGSEz4AAAALgGeU3RH/xLLXnSjYwD5Ccs97IRsYKPkr1HQyC4ta8vbiQiiiYCBN3mv3ahRBeUAAAApAZ5Vakf/EwOx0Mr97ih+JbZnNpaMk0/lbzgB7k6QWUJ1F6/UP8C+AVUAAAA3QZpaSahBbJlMCGf//p4h9B8LUP/brR1wdBgU5EouwLqR/kQ1Cze62lGrhUKyi0Lnhj3KS8ADFwAAACpBnnhFFSwj/w3j1TsnH+z706US7i8/fuIA3A/85X4dKgoxoMU82XHSCRkAAAAgAZ6XdEf/Evq2kS3wxdyyU1ttIDsY5nmYia4+Mqz8C8gAAAAcAZ6Zakf/EwOKVl2afndyXCRD+BfdFpugxv4dMQAAAFNBmp5JqEFsmUwIZ//+niKvlSK6AoFGgAUfWzDgpaOvyWAVT0V3vp72AAADAAZ2Fv/4XtalU8ZOp4uKMJl4HWyMxkmSiVyXru46YeH+WpRYctAPSAAAACtBnrxFFSwj/w3j1EB0e26IzvtC6Jz7ocGt5ZHBUBaADviQMPouAJDtwhExAAAAJQGe23RH/xMoo4xpADPP6RoN5cG4SISm6k/1+gHCSPYGIN/Fw1MAAAAmAZ7dakf/EzS5+ytsS0POLXTejTMGm/LTQEcEz8YFSAX4H1gAaMAAAACaQZrCSahBbJlMCGf//p4htodLe7MVtgaIng0AJPJPa0FHA7xonEiOTnAStKLrb33aWEpxbBAseEbIoI8sS2tJ5nQTyMwAAAMAC7uf+K0gK21yyIRGcaYush8PvPjt22pVnqjoSeSQW5bITn6Oye5wJYZti1AAFUfbUJ9Y26/8fnydrOyr76bKstsxhsleyf/NNzx3HVMoOpAP8AAAAHlBnuBFFSwj/w3j1EA23FQJwYGgALi57UzPeXoXIziqubx97HSqBunnFW1I0dSgxPhFbV3bqI0qjlxeLMSe4jraRCm6bq54VZwPZd8gbvCsryyFZSaM4g4QKlVzurfkeBBNDy1lKiAGzjcb7x16UQ/dQCAT1pzU2wYtAAAAPgGfH3RH/xL6yLM+wOvheiQAGw/fEV+7DYoT28bV0vbOTzvVgocxlflR+Ypt/JZM+VX5YACvdrQP1yNdZASsAAAAWwGfAWpH/xMDqo+VFM6dA8dABuZgQaL1u6af2Qw4PzMWEWy5C9J4V4+VtMydFVNnO4O9x0PTlwJUsfosn9HQ93/oUCpxqJP4VPyV+gu0vbAwm7QB7QdiV9dqAUkAAACUQZsGSahBbJlMCGf//p4cXpyBq8AC1fwEjUGBF5epphe4qdUbHRdkx7baH8OYvcw/B5b8HFNE7agA1D/qvauTjNXYrAfn9nlHknFxJq3sKI79chbAN84LKPIAAAdp2DTq4pIQRj+r/9dSyd92tSwY5YKyp7KhBlwbnbW2BcufwThohYYkHVeMwuVtQ1Tv/uo7s4AYsAAAAGtBnyRFFSwj/wx+Kng6O9AABTp7kKsvZKGuak5JQQofXZI0Nuujt0jB1jX2zQqrJMsWJIZn9g1n+qF6eqOBbZx6LfIsT3s7G/d5rrh3eBjU8pOZYyvLPHfraCInc0ZC4Sf9ZseM5Z+hBRAVMQAAAE4Bn0N0R/8SSxLgtfap0kwybx/+PvtQA0uA+aHvb1EZO7myVJxn3UORoYryc4dgZovth5tu5Zure3qySovC80nm80gUNGAwq5xarVHAj4EAAABUAZ9Fakf/EksS4LZUGBZpbA5nuAAi/P20/Kg5bpKjBIhRO3xpisnK+a3wMNj0qphEbpWy5xcPQRZt0wBAKg120dVozWrLnxVvCGko9ErbhzC64OqBAAAAbkGbSkmoQWyZTAhn//6eHOJhs4/cDgBLZdg4eT9L2Gk7PFyBrK9J37lY/Ib8Gy/R9MMgqqkMAAADACIvf8Wzys+CS7Is4h2Xki177tqmYpEYEvMn+aMbns38dy3qXh7QcAS1UT7VaxE6hzU1iAaFAAAAXUGfaEUVLCP/C9EflZjGzw1aAFsIytBp/1/JsO5Hx3BCoinNJhjfs+b5r54zDXg+t62Fn4HSOFar87m/TBSX4bCOPzX6kIxOYSMMphtsGGfDcgD2INtvrTI8engxYAAAAF8Bn4d0R/8TGgF9+2iXQAAWyjuvoxkwSx8nrPmKqaosIXGe9Ma4ZxSHfsvOzcOwKD6IRYQmhTaPJpcSMUwIZ6M3t7LYzRc9SLN2/MGVzUciOztSZxAX67IRc/oicPkIGAAAAE0Bn4lqR/8TE5nfTKS5I4ABxlEUc+S7Gwy2feweQsLkynyP2+ZmOTvcPOvl6l7M+2lKKbORYrDGhhvMFPKIHbDTtYDbh8bSUoCBEcJFwQAAAHZBm45JqEFsmUwIZ//+nhzybJQRAAfBfNMMZxqMKE9RWDJE8QycG4xXBF5UYF2zUX4crTAyhqy4AAADAJ+ieuTfM5WjcouCZsRB/ieIP4zR1j1C5dqtAGVwE55vVPffdrUqwIqXYIErGzMH80vAp053Ep7BQBFwAAAAUkGfrEUVLCP/C9jiY454OiyD/c8+/LF1zOEjvlAAcGvf/KMWohjcUcolxAr7OcHVL94CVHA0pUJhp0XN84M3SWUE5MAKPha+KP9zeXkMgsPwUz4AAAA9AZ/LdEf/EaPyHvOGADaW9B+0s5SCfuxoo/SP0Xvp1EnTPiRDHpqk36gjZK2CWaUun7UO9pIxaZKFOKrhxwAAAFEBn81qR/8RFgng+Gq6AALP+9BCLs0pdUpFTDCzUyhQtsJRiZYcbJf6hu5YETPYWaSFa7xHaHJHrglAudrUIlifcJerVEEsCtVVJ4qW8PU4yPkAAABPQZvSSahBbJlMCGf//p4cXqsgEmKAAuAdIQpy5favdLf0vsvgL9qOSh7KLPQeJAe1kP3x7m9GtAXyCZw6f7SqPl65bRTQ2BBQQAAbitya2wAAAGFBn/BFFSwj/wye0HZ+QA3Ap+VUgN/i1RhXbpnvolHFWvYsEmt412ADMBWuyXavnqsJN6OH4+ogd1GrQOgi5Sv4ZtPXgZz0ij3tTsPjlY8zcsf3ABakBeIh7KuW3WnRVBQQAAAAPQGeD3RH/xMy/NpahgNfTACKff9sWJBAmDhpWTT1Q2dW+ZN71fUk/UKUiXmddvRsWt84AU6dQzJ5iFQ2MWAAAABdAZ4Rakf/EWpFJr59WgAHBUF4OdmY1kMffXhbBkqTEOm1gK+PGgterBo+eGShQKdfRaUKA5C1nonVnWe5qZKlVX+wwU9RoCmeRzdcYDGv+JGq73AgBkExiBa0fUKnAAAAWUGaFkmoQWyZTAhn//6eIXHPV0AGuz8jg40FnGJZeaEu0J35E/sbQbXWNvWmQthgsU1BtPJeWUaido8mhP8QgPT1wkUzAlq7FbyfQDVtQ5boEVwOLhlAg7sYAAAASUGeNEUVLCP/DeWnb9rma/R7cAG2kinNJTG/Z83zYKusw14NuplH1yO2iBZmEzQqE0DuccyotPjfI4vFxsAGSGKY++tUJbSMFDAAAABIAZ5TdEf/EksS4Uyyknnrrr/48AEYCKeG+fZLEhj766oX3bAfTmiKmtJSmnc6NdJuNF0ZG7+g4LzyPfWXgC0ho/7HrctVKFbBAAAAMAGeVWpH/xMoQNEFEXukbaqUARPIR64JQLna1CE1xQvB10A3FASPVU2Irn+ymt/FtAAAADBBmlpJqEFsmUwIZ//+niIGym7zKOdegA+B0Kww1QweMjKrAPRfMCuU959MoqAABjUAAAAzQZ54RRUsI/8N8Qf5TVFhcSoArQGPUERBLAWNsFCL2S6SeQKCBJXmAjrZOvH1xUbOmgspAAAANwGel3RH/xNX+ACx2kyFrcNBnjCBQoGIAhTT5WUQvrevO52/6TY9L96R8W9FEwBLDXjyta9NC2gAAAAcAZ6Zakf/EBty0fD9cYht3pvLniKrbNDvkBqCvwAAACNBmp5JqEFsmUwIZ//+nhhrjhMW9AB7VzxHZZ/0QkJAAAAEnAAAAB9BnrxFFSwj/wt3Llefq+5n4yuqgJb1aPznSII5uAqZAAAAIwGe23RH/w/9ag/oAARhoxllMsfP9EIGvWkNRr/00UXW7hKxAAAAFwGe3WpH/w23SgwFcwKY5B3qKAcTTtf4AAAAGUGawkmoQWyZTAhn//6eFFvG0CYgAAADAbMAAAAdQZ7gRRUsI/8JrHKCBXRO9jkcqeime2c6kCn4SsEAAAAXAZ8fdEf/DaEybAZucgGRadPfvtG+sqAAAAAWAZ8Bakf/AAAdt/4puoWvToaBjeK0gQAAABdBmwZJqEFsmUwIZ//+nhAAAAMAAAMDPgAAABpBnyRFFSwj/wAAEuKfkG66o3OZ3GOTY/DdBQAAABUBn0N0R/8AAB2oo9oihV5apMnB76UAAAAWAZ9Fakf/AAAdt/4puoWvToaBjeK0gQAAABdBm0pJqEFsmUwIZ//+nhAAAAMAAAMDPwAAABpBn2hFFSwj/wAAEuKfkG66o3OZ3GOTY/DdBAAAABUBn4d0R/8AAB2oo9oihV5apMnB76QAAAAWAZ+Jakf/AAAdt/4puoWvToaBjeK0gQAAABdBm45JqEFsmUwIX//+jLAAAAMAAAMDQgAAABpBn6xFFSwj/wAAEuKfkG66o3OZ3GOTY/DdBAAAABUBn8t0R/8AAB2oo9oihV5apMnB76UAAAAWAZ/Nakf/AAAdt/4puoWvToaBjeK0gQAAABdBm9JJqEFsmUwIX//+jLAAAAMAAAMDQwAAABpBn/BFFSwj/wAAEuKfkG66o3OZ3GOTY/DdBAAAABUBng90R/8AAB2oo9oihV5apMnB76QAAAAWAZ4Rakf/AAAdt/4puoWvToaBjeK0gQAAABdBmhZJqEFsmUwIX//+jLAAAAMAAAMDQgAAABpBnjRFFSwj/wAAEuKfkG66o3OZ3GOTY/DdBAAAABUBnlN0R/8AAB2oo9oihV5apMnB76UAAAAWAZ5Vakf/AAAdt/4puoWvToaBjeK0gAAAAFNBmlpJqEFsmUwIV//7xlSIHJxb4ALv34xlkK8OAvLrS8wIkl6g+kzKYLA0Lw/4iFVncN69Qs0+gRDTNPELegWAIW2AfKlwKf07lQEnKgAAAwAScQAAABxBnnhFFSwj/5lEluAHT6laRY6qB7Qk0KCx0DuhAAAAFQGel3RH/wAAHaij2iKFXlqkycHvpAAAAD4BnplqR/+i+QbQAEZU8/sVyicz7tQSDlRrF3AVJRUDhpHy3zPG5thROmg2IMgJpXNsBPahzeSELCEGPbB9wQAAALRBmp5JqEFsmUwIa//+yLt5Am9vGGc/UVEm2t4yKb7TFydDGhLhCh3E3l98t24j0CgsHrOjQWM+dM0iehmaxRd7dnPPD57YoGhi2lu6Coi1x3IowLB0ro4Mb0NzeDCIDB3hiMT1539MwIrOyZd9qhhIjqXPeNzpqiAkcxHYK/N8imEgHa258dfkjpjIyJWfbX5qHu7Uao+Vv1QzlsbBZmjk5AVsw2N99+spwANxrGdDQAAAIuAAAABGQZ68RRUsJ//19oLj4vb/gAGqn9FnmYtZphLw0xizQCB9bWvhRxmBtYhIUGAVLiC3Kgid5eVVwP5kII02pwH2J4CV7owFTQAAADMBntt0R//KXLpOAeIJN65AOETAgBYE8JMkDnlBEgS86wEW3n4yxAHvYfGJzB9LdZnGDgkAAAApAZ7dakKf+WzRGc5Xlfu8vdO5Ba13DNNjleMbHvYMfWApx3uXENtsVsAAAAB6QZrfSahBbJlMCf9gnDNhRUDdmuc932wix1oYArmhSmpKxqIAAAMAAAMAAAMAAt9uqnmCvMw33bVMsJtxdFAM0Vx6L7NBD/4Zd9FgzOroZNYonWxiI3hXTapOTS2c3zhNlVRrLXVZ3HBQYrvW9PC+iDaIrOBwJSyPnDQAAAWfZYiCAA3//vbw/gU2VgRQlxHN6J0zH78VuLo0N73i2cGM+6XG+uhZ2kvm9MR7Ph3M1otuxppTvC9AXfpq5LKUr9TQs9bRjZ+F5g62znUCQj5i/tZRAW31Q5yeiAkZ+JNgKsgHzeMr8r0DcTL6r1T4iTURXRobcLR1qRLrE82RqQTPOwQHeLiIHAjebhaDwTfoJ3rbD9r7awe4ZEiQEiMMYKWeMkqpLX3BPFYRQKVqWTRmU/B9LkbTHSbMy/Q7I58FDu68Iw0ATgtnxq4jgmsNYSdfb/Bu0ZLoezrClWi4T0RkcsEfNGNCtnrP9WETcDGCkGvgwAAAAwAACvFKf81isoGpq02kNgxwAA2ockrOBGQ6Q6hCBYiED2IcQkrBbJQbHl+utZlTc1PPjFFi6KuEFj9XCI+8J0ICV+0vIaPtj6S9KPHqgMKoH3P4maIQck5hlVZzJ0kw8QzrjIveh0g9QzteHabTaczWsI8NTBf4Yj3uqSq8OF/1wUeDTMHHl93SonauqPgC1WbEhHGJI+eGtecE8Kl8i+evGz2FRv43rbBJ8mH2VOqbeIdueF8BT7BSQ7VIDSZkpy+nczDRdab1Q+eHPioCHo67rpX4nhEPZRgC732rl5cNIYYjcCQqDG30MSeVIu+sdur5s+UWa4ZTYwylNPh7tVJGkR7Rs0g0nkNMHyTY+vS+LGDrbmsZug5oNKjnD/B3HRl45iLI6NnFYAN3CwZLCiu6h/kt/ajbBJRpWO0E/loclbh+fM/FO0XNxS1PYwGYrVEZvQnJd05VfGrz/iB3gwFZxzBWRiGQKNi9WVPwnunEa0JnZAP4UqBBCKPz9WPmjwthIJkV23EAiPGpcEOTy4X40g+hRa5CnNq0yusoYTxteyypR6v4n5vrcrRE89OqvuGOzoOxy7eytPwjaM3euebYu9+vQThL5/E9fO0FL7HIbzFtWYZ0JSgcpLpuLpAGrEYqOGjRWdvqz2ry3ztIwaGf09x/68JYLsiyB0q7PyurpXunKqVTp/g79a9wT072KSpWU467vrF3g2cIK6+4c/tF0jpk8VSGyflSoQWM05p/JLfu+kCmVsEJ+LO1yS9qC8SebaEk329PryVlN6JhmE0lmjI0H57LbWyPEt8GdRdvAJChSTU/SS0rorf4mZUiXizaEpRNQkPTU3g0D7iVQ9YN/0f/gsIPD0LsJ4C7+H+UJbQHi/SAj2tbFQmhjZaYmUstJ3nqWTpy3ZJMgHXZorspfkqovdctKVHTZwt0XJw1T4HFmh8GO/e1plEIyZ8NGVB7xsPLgTUk9FR736GJUasNe8fCZ/CgJ236Lc9fvQu7A5tNmAmOl6mykCHJctfLMrDEoDHAqXBlH98KZlHN/NeI6KLuTcRc+5ygHp47851L8MOd9fcC8bEMdr0BWiD11ofs9KokJxr0thM2Kb028jr8qdDinozhdrSVF1UhnXmQOciIM3zQeq5guAo8ZnnOSlHgrzN4q4Wp/2Dav3uBIrPb608AuyRrH7XEvK5mXhm9qc7GvjsBId/LTJ09MUSjmdrfw7srbMd9uzBPNs0cZz1xdYvrnP/yKBEz/U2RJxeWTukzsOUxa3NLLGExTniRQj2FtHQU0zVavhK1V7ooLcOHc4IbebRP/nr7gH+zCxth8ejaQUiTwA1s/OY3JY/71y9BpBhD873TSFXtrc8SYSOFMCfLz3clWaub6bnzdtdfPmkrVPNZRyVwnH/WVVHEv/rBnWwCvyN2kZKR27rrOrMNns9tA9b4K6tRX2ODiRbEpSM9ZLnBvumwA2IM5uVasJ2z/+nOKGlBrX7i/Xb1XNXdZRUhAYpTJK6qUZEQJzeCgLuw5l1l+vpTB7tZwidCbbMSmbNW/+R5DWEosW5HFOKogCINekW4u3le5wnUAATTAU+A9MDpAZUAAACKQZohbEL//ozSJfCUAdACaXbQiQJH6BYQT3qWW5+HnbwariLpdVcw56N3bgS5t1YLqX0oCPSqgAAFwP2IhF0V75x53Ii5HLcRrAhIiZwSxQUb7talVXLgWCWuIR3SEu3+hNESWoVDZlFl5kVx3kCNJLZBUcAOlOhkRkivmK/ajHTgwfvAqFffZPFiAAAA4UGaRTwhkymEK//+OIh+LwV4e2wATqhZx1K4oqRHoVhFqe+hAtEJCOB4NoJWdq57K5dK71g1tAZmGbr+NRcqWYB1djWYcAAAAwGGQTcofvtqgGNUqPFz1QHTLF/BNOzWoIbvu2qZedNabi33DCFMdjsjBCsrkEN0FRy2b+McE/xYCx3skC0+1EmSgMoeYDByMLuQYGHJOUDTsk20m2NdgJvdaXqSIqvrp/53zh6jkFmAQpTj8L70JggOSdgmyBuMdL9ehpmpcOJ+rUZwxjkMurlnP4eJCBgVOPBDHSa7KMAGFQAAAIJBnmNqU8I/EUQbloMHOfDiHJj2hC1ER6LpcchpxAN7sABANgUGt32MwnpiCWCQL8IzRln+EXtA/kPwylNnLok1R0+rf2i9dEvUPkihLjv3B3rRL3ulw9lXQ8sQEZCC82xgJneyg5JvcoMYTpn4VJeh12AnhDbQ2EPpadVNoHNEQMWAAAAAQQGegnRH/xOsZbtJSm1kwZaLjwlntoAPvmJgvr6hYy7SL19n67YP9zwvxQoDiKek+uneezwjM9/Z5h/nJiQ2JAFDAAAAbAGehGpH/xcnePuk1LSd9rV7e5YK4AH7LlGhqzfLIJRPnjtg0hAy3Tc/p+5vycB/tiJbIHwEU95zyR67bPPP9CX+IDyJf5OHVNzTyGKSQKOfKbKDUb0jmakH1gy19hbmG9/2aBxACJ8jH5AWUQAAAJ9BmolJqEFomUwI//yG8c+ttMABbFKLcGe0jjTtMNxqKZXvxp8DR8vQuJeYAAADAAAa3c87/5bd5pC+921TL8idPCq1GWD/AKD7aMl+ZPQj0vl0nLM7J7VtQbvBV2b0WE0cCrfc5T/S1Sg1IJIA4STNNdwJ4OMxnLXwn2/IkVtpDokNTZkghJEtpB2DumXenjkoMo/cqKXNXHqgL+WwGpEAAAB2QZ6nRREsI/8RPNhv6AwaCTYN3KM8biYnJ5rgBMoanmAPwoNNQFEXs7JYGlevQJLLQ0+ZfkkrQTAFyyNl+4FQsKsguDbdmiao1zNeKyz+kJcJSl8CTRFg+inslHIGCRvoBLo5AAAvo4oO4VzDb5ayC/3IhiDZgQAAAHIBnsZ0R/8WA8Nvp7OjBnTMU7xZzztWbYqCoKAKAIgVCWwkykC+z2mBz04L3pBBgiOM97rLL87qprOUG1hlxHdEBYFUVvNeHLEKspngoF0DFKtEboPCUQvb8IW1SUrwA/Vs+UQ7E0tfVkyECdFYIEAAakAAAAAmAZ7Iakf/FtDbXu2hK3fGF5mUhAEuKllF85ixls4IdCbN4RAmHHAAAAwvbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAD8gAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC1l0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAD8gAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAGQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAA/IAAACAAABAAAAAArRbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAAAygBVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKfG1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACjxzdGJsAAAAmHN0c2QAAAAAAAAAAQAAAIhhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgBkABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMmF2Y0MBZAAf/+EAGWdkAB+s2UCYM+XhAAADAAEAAAMAZA8YMZYBAAZo6+PLIsAAAAAYc3R0cwAAAAAAAAABAAAAygAAAQAAAAAYc3RzcwAAAAAAAAACAAAAAQAAAMEAAAYAY3R0cwAAAAAAAAC+AAAAAQAAAgAAAAABAAADAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAgAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAADAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAl3AAABmgAAAFYAAAEEAAAAawAAAG0AAAD9AAAAmgAAAHkAAAB1AAAAzwAAAJ0AAADIAAAAlAAAAHEAAADhAAAAgwAAAKIAAAEWAAAAzQAAAIAAAACdAAAA7QAAAJ4AAACIAAAAlgAAAOsAAAB5AAAAdQAAAO4AAACLAAAAgAAAARAAAACRAAAAdAAAAHIAAAEeAAAAfgAAAIUAAAEyAAAAfwAAAIoAAAChAAABLgAAAJMAAACHAAAAhwAAAQ4AAACfAAAAlwAAAIwAAAEnAAAAsgAAAJMAAABkAAAA/wAAAIkAAACHAAAAmQAAAOcAAACoAAAAdAAAAHcAAAEJAAAAugAAAJcAAACRAAABGwAAAJ4AAAB0AAABAAAAAHMAAAB+AAABCQAAAHMAAACMAAAA+wAAAJQAAADnAAAAegAAALkAAACKAAAAdgAAANwAAACJAAAAwgAAAQQAAABoAAAApAAAAIUAAAC8AAAAlQAAAPoAAACLAAAA/QAAAIIAAACeAAAAwAAAAIQAAACpAAAAcwAAAM0AAABwAAAAqwAAAIgAAACwAAAAkgAABDkAAADSAAAAfwAAAGMAAACMAAAAYgAAAEMAAAA7AAAAWAAAAEcAAAAyAAAALQAAADsAAAAuAAAAJAAAACAAAABXAAAALwAAACkAAAAqAAAAngAAAH0AAABCAAAAXwAAAJgAAABvAAAAUgAAAFgAAAByAAAAYQAAAGMAAABRAAAAegAAAFYAAABBAAAAVQAAAFMAAABlAAAAQQAAAGEAAABdAAAATQAAAEwAAAA0AAAANAAAADcAAAA7AAAAIAAAACcAAAAjAAAAJwAAABsAAAAdAAAAIQAAABsAAAAaAAAAGwAAAB4AAAAZAAAAGgAAABsAAAAeAAAAGQAAABoAAAAbAAAAHgAAABkAAAAaAAAAGwAAAB4AAAAZAAAAGgAAABsAAAAeAAAAGQAAABoAAABXAAAAIAAAABkAAABCAAAAuAAAAEoAAAA3AAAALQAAAH4AAAWjAAAAjgAAAOUAAACGAAAARQAAAHAAAACjAAAAegAAAHYAAAAqAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\" type=\"video/mp4\" />\n",
              "                </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_videos(video_path='logs/videos', prefix='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcMgtUceyu8Z"
      },
      "source": [
        "By using [Optuna](https://optuna.org/). We can also tune the **hyperparameters** of our model to improve training result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBp9aSyfy8zo",
        "outputId": "f6d5cf32-cf25-4f44-b0dd-39667f9b92b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-04 21:44:22.529563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-04 21:44:23.434326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== LunarLander-v2 ==========\n",
            "Seed: 598707094\n",
            "Loading hyperparameters from: /usr/local/lib/python3.10/dist-packages/rl_zoo3/hyperparams/a2c.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 1e-05),\n",
            "             ('gamma', 0.995),\n",
            "             ('learning_rate', 'lin_0.00083'),\n",
            "             ('n_envs', 8),\n",
            "             ('n_steps', 5),\n",
            "             ('n_timesteps', 200000.0),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 8 environments\n",
            "Overwriting n_timesteps with n=100\n",
            "Doing 1 intermediate evaluations for pruning based on the number of timesteps. (1 evaluation every 100k timesteps)\n",
            "Optimizing hyperparameters\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/samplers/_tpe/sampler.py:278: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "Sampler: tpe - Pruner: median\n",
            "\u001b[32m[I 2023-08-04 21:44:26,178]\u001b[0m A new study created in memory with name: no-name-164bd05f-a7a4-4323-b1d8-fe35ae46d6f9\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/rl_zoo3/hyperparams_opt.py:164: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  vf_coef = trial.suggest_uniform(\"vf_coef\", 0, 1)\n",
            "\u001b[32m[I 2023-08-04 21:44:32,511]\u001b[0m Trial 1 finished with value: -119.387482 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 2, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 4.267916436926637e-05, 'ent_coef': 6.616597344402895e-06, 'vf_coef': 0.1996417488745189, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:44:36,516]\u001b[0m Trial 0 finished with value: -483.73490839999994 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 0.6, 'use_rms_prop': True, 'gae_lambda': 0.95, 'n_steps': 64, 'lr_schedule': 'constant', 'learning_rate': 1.6580070220394617e-05, 'ent_coef': 2.2560483652873018e-08, 'vf_coef': 0.31308465068664637, 'ortho_init': True, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:44:42,046]\u001b[0m Trial 4 finished with value: -138.3428134 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 64, 'lr_schedule': 'linear', 'learning_rate': 1.6220282046714455e-05, 'ent_coef': 0.00041466834046455513, 'vf_coef': 0.39829149510112394, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:46:20,999]\u001b[0m Trial 2 finished with value: -276.5960692 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 1, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 512, 'lr_schedule': 'constant', 'learning_rate': 0.00011617164749538172, 'ent_coef': 0.07613096017052384, 'vf_coef': 0.33455207503403483, 'ortho_init': True, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:46:41,845]\u001b[0m Trial 5 finished with value: -733.0206716 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.92, 'n_steps': 512, 'lr_schedule': 'constant', 'learning_rate': 0.059127857022322906, 'ent_coef': 4.696997037383984e-07, 'vf_coef': 0.5644275715765086, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:48:00,564]\u001b[0m Trial 7 finished with value: -610.3381084 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.6, 'use_rms_prop': False, 'gae_lambda': 0.99, 'n_steps': 512, 'lr_schedule': 'constant', 'learning_rate': 0.053161164324119686, 'ent_coef': 3.2549549004646895e-05, 'vf_coef': 0.21707491643693666, 'ortho_init': True, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:48:52,273]\u001b[0m Trial 8 finished with value: -477.925259 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 2, 'use_rms_prop': True, 'gae_lambda': 0.95, 'n_steps': 512, 'lr_schedule': 'constant', 'learning_rate': 0.46275464194361726, 'ent_coef': 0.0001702329658777573, 'vf_coef': 0.5060686321536848, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:49:14,336]\u001b[0m Trial 9 finished with value: -635.4144662000001 and parameters: {'gamma': 0.9999, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 128, 'lr_schedule': 'constant', 'learning_rate': 0.5721690878766238, 'ent_coef': 1.8748480811017361e-06, 'vf_coef': 0.4109961281213852, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:50:35,521]\u001b[0m Trial 3 finished with value: -1299.9941144 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 0.7, 'use_rms_prop': False, 'gae_lambda': 0.9, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 0.004434862305451838, 'ent_coef': 0.08940591105455929, 'vf_coef': 0.6504078129043955, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:01,357]\u001b[0m Trial 6 finished with value: -1176.7232238 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.7, 'use_rms_prop': True, 'gae_lambda': 0.99, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 0.024116626374884115, 'ent_coef': 0.07557454239012051, 'vf_coef': 0.22972535389297122, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:02,507]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:03,211]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:03,819]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:05,210]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:06,130]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:08,551]\u001b[0m Trial 11 finished with value: -600.4150066 and parameters: {'gamma': 0.99, 'normalize_advantage': False, 'max_grad_norm': 5, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 512, 'lr_schedule': 'constant', 'learning_rate': 0.0008141794417167555, 'ent_coef': 0.0022045881466668284, 'vf_coef': 0.15657174221858716, 'ortho_init': True, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:11,546]\u001b[0m Trial 16 finished with value: -234.50397979999997 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 64, 'lr_schedule': 'linear', 'learning_rate': 3.682212187991739e-05, 'ent_coef': 0.000194826644440967, 'vf_coef': 0.6908912394884558, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:14,823]\u001b[0m Trial 18 finished with value: -172.20598979999997 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 64, 'lr_schedule': 'constant', 'learning_rate': 0.0005513594894168917, 'ent_coef': 0.0006642668341331448, 'vf_coef': 0.6900006390962108, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:24,101]\u001b[0m Trial 19 finished with value: -411.15275060000005 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 128, 'lr_schedule': 'linear', 'learning_rate': 8.646320204922197e-05, 'ent_coef': 0.022045534688084942, 'vf_coef': 0.42972119778054685, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:26,649]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:27,926]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:29,263]\u001b[0m Trial 23 finished with value: -138.4149962 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 4.9540630719916626e-05, 'ent_coef': 0.005026523408827297, 'vf_coef': 0.7372855253227767, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:30,913]\u001b[0m Trial 24 finished with value: -302.360569 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.7, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 1.8791032767442853e-05, 'ent_coef': 0.0019171697845820547, 'vf_coef': 0.8912888531119278, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:33,276]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:34,624]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:35,936]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:37,444]\u001b[0m Trial 28 finished with value: -243.8747068 and parameters: {'gamma': 0.9999, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 0.0004457814583563191, 'ent_coef': 0.001714777960025279, 'vf_coef': 0.6332715988851282, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:40,839]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:42,098]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:44,478]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:46,055]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:47,302]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:48,603]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:50,222]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:56,471]\u001b[0m Trial 36 finished with value: -159.5725064 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 64, 'lr_schedule': 'constant', 'learning_rate': 0.00047879277528823733, 'ent_coef': 0.0002146993919525054, 'vf_coef': 0.6890164594090276, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:58,546]\u001b[0m Trial 17 finished with value: -200.38660039999996 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 512, 'lr_schedule': 'linear', 'learning_rate': 8.215094673670103e-05, 'ent_coef': 0.005794744473355114, 'vf_coef': 0.11290745417330583, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:52:59,437]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:05,606]\u001b[0m Trial 39 finished with value: -152.9703178 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 64, 'lr_schedule': 'constant', 'learning_rate': 0.0016633045236681564, 'ent_coef': 1.4369386955376976e-05, 'vf_coef': 0.674077371189913, 'ortho_init': True, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:06,981]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:09,291]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:11,008]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:13,107]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:19,589]\u001b[0m Trial 44 finished with value: -158.3093782 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 64, 'lr_schedule': 'constant', 'learning_rate': 0.0003327791114474765, 'ent_coef': 0.0014008918191976802, 'vf_coef': 0.7543171504186418, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 1 with value: -119.387482.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:53:23,020]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:54:55,193]\u001b[0m Trial 38 finished with value: -65.7153034 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 0.0003186289531256399, 'ent_coef': 1.798360605113218e-06, 'vf_coef': 0.8307463640795073, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:54:56,515]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:54:58,337]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:12,673]\u001b[0m Trial 46 finished with value: -221.70760220000003 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.92, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 6.069737810906424e-05, 'ent_coef': 0.00010631288952370465, 'vf_coef': 0.7641185254175453, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:14,383]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:16,612]\u001b[0m Trial 51 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:19,120]\u001b[0m Trial 52 finished with value: -149.64684019999999 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 0.7, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 3.0549552734667046e-05, 'ent_coef': 3.2220555909743193e-07, 'vf_coef': 0.22015834826960598, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:21,687]\u001b[0m Trial 53 finished with value: -212.18613599999998 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 0.7, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 5.161538133489252e-05, 'ent_coef': 1.1745479153559317e-08, 'vf_coef': 0.22060710053701002, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:22,928]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:24,197]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:26,674]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:29,972]\u001b[0m Trial 57 finished with value: -111.8609352 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 0.7, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 1.2877935710907424e-05, 'ent_coef': 3.6808017313312726e-07, 'vf_coef': 0.41694845402386826, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:31,331]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:33,456]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:36,745]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:39,602]\u001b[0m Trial 61 finished with value: -121.45625480000001 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 1, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 2.0129506815935133e-05, 'ent_coef': 1.683122372463337e-07, 'vf_coef': 0.3444423964554658, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:46,584]\u001b[0m Trial 62 finished with value: -161.0675574 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 1, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 64, 'lr_schedule': 'linear', 'learning_rate': 0.0004685960733749913, 'ent_coef': 3.399275247656039e-07, 'vf_coef': 0.2093233236963179, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:47,853]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:49,448]\u001b[0m Trial 20 finished with value: -135.1422666 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 0.001033023201603018, 'ent_coef': 0.002349643631887365, 'vf_coef': 0.5500666401589219, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:49,692]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:51,209]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:51,479]\u001b[0m Trial 65 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:53,218]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:54,036]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:57,898]\u001b[0m Trial 70 finished with value: -88.3400726 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0001435423607222271, 'ent_coef': 4.587945597324247e-06, 'vf_coef': 0.18303294973069792, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:55:59,236]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:12,535]\u001b[0m Trial 72 finished with value: -181.1480674 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 128, 'lr_schedule': 'linear', 'learning_rate': 4.712388740692724e-05, 'ent_coef': 2.577261889537543e-07, 'vf_coef': 0.28981733025931783, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:15,218]\u001b[0m Trial 73 finished with value: -135.9980762 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 1.6130364691283387e-05, 'ent_coef': 6.85231885407697e-07, 'vf_coef': 0.3207846723311227, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:17,674]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:19,972]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:23,222]\u001b[0m Trial 76 finished with value: -124.7045932 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 4.300038665374626e-05, 'ent_coef': 1.9268907089409442e-06, 'vf_coef': 0.44162480178981744, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:24,758]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:28,255]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:29,586]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:33,090]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:34,492]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:36,643]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:39,169]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:40,842]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:42,189]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:43,574]\u001b[0m Trial 86 finished with value: -215.5353788 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 2, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 16, 'lr_schedule': 'linear', 'learning_rate': 2.76309487092777e-05, 'ent_coef': 3.655972673293182e-05, 'vf_coef': 0.2357354562977197, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:45,833]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:47,242]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:47,537]\u001b[0m Trial 49 finished with value: -111.1408156 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.5, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 0.00017859488886453706, 'ent_coef': 2.9770908557141515e-07, 'vf_coef': 0.9959426091361576, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:49,578]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:51,198]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:52,937]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:54,759]\u001b[0m Trial 93 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:57,010]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:58,447]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:56:59,925]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:01,456]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:03,190]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:05,461]\u001b[0m Trial 99 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:06,874]\u001b[0m Trial 100 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:08,269]\u001b[0m Trial 101 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:09,639]\u001b[0m Trial 102 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:44,540]\u001b[0m Trial 69 finished with value: -195.3712352 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 1024, 'lr_schedule': 'linear', 'learning_rate': 0.0004840987515523503, 'ent_coef': 3.103900474649554e-05, 'vf_coef': 0.8132221267386257, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:46,769]\u001b[0m Trial 104 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:49,543]\u001b[0m Trial 105 finished with value: -136.2202432 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.7, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'constant', 'learning_rate': 7.424052993545533e-05, 'ent_coef': 1.2968580111919618e-07, 'vf_coef': 0.4058620085259332, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:53,079]\u001b[0m Trial 106 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:54,410]\u001b[0m Trial 107 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:57:56,065]\u001b[0m Trial 108 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:00,871]\u001b[0m Trial 103 finished with value: -148.41604940000002 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.5, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 0.0002681136649213413, 'ent_coef': 4.3459235067948224e-07, 'vf_coef': 0.6515713830052898, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:02,359]\u001b[0m Trial 110 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:06,198]\u001b[0m Trial 111 finished with value: -267.68303640000005 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 1.9869433600556622e-05, 'ent_coef': 4.82533558532263e-07, 'vf_coef': 0.03625987823316415, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:07,661]\u001b[0m Trial 112 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:09,960]\u001b[0m Trial 113 finished with value: -140.04903299999998 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 2.114744137941296e-05, 'ent_coef': 0.0686913385361048, 'vf_coef': 0.8364674203201092, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:11,349]\u001b[0m Trial 114 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:12,747]\u001b[0m Trial 115 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:14,012]\u001b[0m Trial 116 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:15,884]\u001b[0m Trial 117 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:17,918]\u001b[0m Trial 118 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:19,517]\u001b[0m Trial 119 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:21,291]\u001b[0m Trial 120 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:22,660]\u001b[0m Trial 121 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:23,807]\u001b[0m Trial 122 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:28,522]\u001b[0m Trial 89 finished with value: -240.53931859999997 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.9, 'n_steps': 1024, 'lr_schedule': 'linear', 'learning_rate': 0.0001742053465146324, 'ent_coef': 0.0011984255461431358, 'vf_coef': 0.4133563729140207, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:30,141]\u001b[0m Trial 124 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:31,979]\u001b[0m Trial 125 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:33,526]\u001b[0m Trial 126 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:34,937]\u001b[0m Trial 127 finished with value: -121.36787220000001 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 1.219891552728171e-05, 'ent_coef': 0.003752962878579067, 'vf_coef': 0.736379268165587, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:37,285]\u001b[0m Trial 128 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:38,638]\u001b[0m Trial 129 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:41,606]\u001b[0m Trial 130 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:43,136]\u001b[0m Trial 131 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:44,940]\u001b[0m Trial 132 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:46,632]\u001b[0m Trial 133 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:49,248]\u001b[0m Trial 134 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:50,608]\u001b[0m Trial 135 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:51,964]\u001b[0m Trial 136 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:53,296]\u001b[0m Trial 137 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:53,617]\u001b[0m Trial 109 finished with value: -185.0342732 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.5, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 0.00015354144227187183, 'ent_coef': 1.0185683873915357e-07, 'vf_coef': 0.9819374333144825, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:54,872]\u001b[0m Trial 138 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:55,403]\u001b[0m Trial 139 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:56,933]\u001b[0m Trial 141 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:57,924]\u001b[0m Trial 140 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 21:59:59,085]\u001b[0m Trial 142 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:00,515]\u001b[0m Trial 143 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:01,850]\u001b[0m Trial 144 finished with value: -137.1659836 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0021394578198437766, 'ent_coef': 8.305981665785958e-06, 'vf_coef': 0.5517123014370787, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:02,825]\u001b[0m Trial 145 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:03,315]\u001b[0m Trial 146 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:04,060]\u001b[0m Trial 147 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:05,580]\u001b[0m Trial 149 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:06,196]\u001b[0m Trial 148 finished with value: -135.9980762 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0002956808478104801, 'ent_coef': 3.437789248610091e-06, 'vf_coef': 0.836175072292412, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:06,926]\u001b[0m Trial 150 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:07,626]\u001b[0m Trial 151 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:08,354]\u001b[0m Trial 152 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:11,133]\u001b[0m Trial 153 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:11,362]\u001b[0m Trial 154 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:14,300]\u001b[0m Trial 156 finished with value: -127.30734460000001 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.00684363346689241, 'ent_coef': 1.3804418775915397e-05, 'vf_coef': 0.6789645987876972, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:15,067]\u001b[0m Trial 155 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:15,751]\u001b[0m Trial 157 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:18,129]\u001b[0m Trial 159 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:19,776]\u001b[0m Trial 160 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:21,645]\u001b[0m Trial 161 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:23,541]\u001b[0m Trial 162 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:25,430]\u001b[0m Trial 163 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:29,111]\u001b[0m Trial 164 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:30,459]\u001b[0m Trial 165 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:33,882]\u001b[0m Trial 166 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:36,369]\u001b[0m Trial 167 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:39,521]\u001b[0m Trial 168 finished with value: -125.14533639999999 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 16, 'lr_schedule': 'linear', 'learning_rate': 0.00010420282116292236, 'ent_coef': 2.3490516403267357e-05, 'vf_coef': 0.07610077106227531, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:40,835]\u001b[0m Trial 169 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:42,888]\u001b[0m Trial 158 finished with value: -113.4811544 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 256, 'lr_schedule': 'linear', 'learning_rate': 0.04079407691161101, 'ent_coef': 0.0013042667655163444, 'vf_coef': 0.7743636077736259, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:44,408]\u001b[0m Trial 170 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:44,733]\u001b[0m Trial 171 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:46,084]\u001b[0m Trial 173 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:46,643]\u001b[0m Trial 172 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:47,897]\u001b[0m Trial 175 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:50,025]\u001b[0m Trial 174 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:50,450]\u001b[0m Trial 176 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:52,058]\u001b[0m Trial 177 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:52,352]\u001b[0m Trial 178 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:53,822]\u001b[0m Trial 180 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:55,519]\u001b[0m Trial 181 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:56,863]\u001b[0m Trial 182 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:00:59,150]\u001b[0m Trial 179 finished with value: -71.98856880000001 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 64, 'lr_schedule': 'linear', 'learning_rate': 0.001753405024068061, 'ent_coef': 7.497051217363321e-05, 'vf_coef': 0.08576686704649078, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:00,662]\u001b[0m Trial 184 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:00,732]\u001b[0m Trial 183 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:02,111]\u001b[0m Trial 185 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:03,720]\u001b[0m Trial 187 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:03,891]\u001b[0m Trial 186 finished with value: -149.26001639999998 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 3.653619260067666e-05, 'ent_coef': 5.035846387513106e-07, 'vf_coef': 0.6111273985107579, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:05,666]\u001b[0m Trial 188 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:05,910]\u001b[0m Trial 189 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:08,217]\u001b[0m Trial 190 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:08,749]\u001b[0m Trial 191 finished with value: -176.94262239999998 and parameters: {'gamma': 0.995, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.006473482225406962, 'ent_coef': 4.0135532210333237e-07, 'vf_coef': 0.501690167685711, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:09,827]\u001b[0m Trial 192 finished with value: -130.321026 and parameters: {'gamma': 0.999, 'normalize_advantage': True, 'max_grad_norm': 1, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 1.6427744649032063e-05, 'ent_coef': 0.008215866700226327, 'vf_coef': 0.7678609268640687, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:12,140]\u001b[0m Trial 194 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:12,456]\u001b[0m Trial 193 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:13,436]\u001b[0m Trial 195 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:14,016]\u001b[0m Trial 196 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:15,461]\u001b[0m Trial 198 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:17,038]\u001b[0m Trial 199 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:18,929]\u001b[0m Trial 200 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:20,604]\u001b[0m Trial 201 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:22,386]\u001b[0m Trial 202 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:24,088]\u001b[0m Trial 203 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:26,962]\u001b[0m Trial 204 finished with value: -120.8614998 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 2, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0002329273138745231, 'ent_coef': 3.1501779424149997e-06, 'vf_coef': 0.12225524470251974, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:28,407]\u001b[0m Trial 205 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:30,369]\u001b[0m Trial 206 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:33,963]\u001b[0m Trial 207 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:35,816]\u001b[0m Trial 208 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:37,197]\u001b[0m Trial 209 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:39,792]\u001b[0m Trial 210 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:42,160]\u001b[0m Trial 211 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:43,800]\u001b[0m Trial 212 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:47,822]\u001b[0m Trial 213 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:49,217]\u001b[0m Trial 214 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:52,777]\u001b[0m Trial 215 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:55,562]\u001b[0m Trial 216 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:01:58,321]\u001b[0m Trial 217 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:00,422]\u001b[0m Trial 218 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:01,802]\u001b[0m Trial 219 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:04,107]\u001b[0m Trial 220 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:07,532]\u001b[0m Trial 221 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:08,868]\u001b[0m Trial 222 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:11,937]\u001b[0m Trial 223 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:13,706]\u001b[0m Trial 224 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:16,923]\u001b[0m Trial 225 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:18,235]\u001b[0m Trial 226 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:21,530]\u001b[0m Trial 227 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:24,140]\u001b[0m Trial 228 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:26,108]\u001b[0m Trial 229 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:27,599]\u001b[0m Trial 230 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:28,940]\u001b[0m Trial 231 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:55,713]\u001b[0m Trial 232 finished with value: -138.086593 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 256, 'lr_schedule': 'linear', 'learning_rate': 0.026584854080596295, 'ent_coef': 0.00029284347043137695, 'vf_coef': 0.5831695921841137, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:57,132]\u001b[0m Trial 233 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:58,506]\u001b[0m Trial 234 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:02:59,728]\u001b[0m Trial 235 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:01,058]\u001b[0m Trial 236 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:02,522]\u001b[0m Trial 237 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:04,025]\u001b[0m Trial 238 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:06,152]\u001b[0m Trial 239 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:08,716]\u001b[0m Trial 240 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:10,090]\u001b[0m Trial 241 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:10,682]\u001b[0m Trial 123 finished with value: -135.1422666 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 5.480249349445427e-05, 'ent_coef': 1.7834617452805e-08, 'vf_coef': 0.6031310660813634, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:11,927]\u001b[0m Trial 243 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:12,799]\u001b[0m Trial 242 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:13,529]\u001b[0m Trial 244 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:14,386]\u001b[0m Trial 245 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:15,047]\u001b[0m Trial 246 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:16,342]\u001b[0m Trial 248 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:17,946]\u001b[0m Trial 249 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:20,942]\u001b[0m Trial 250 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:22,339]\u001b[0m Trial 251 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:23,773]\u001b[0m Trial 252 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:25,222]\u001b[0m Trial 253 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:28,736]\u001b[0m Trial 254 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:32,778]\u001b[0m Trial 255 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:34,442]\u001b[0m Trial 256 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:35,892]\u001b[0m Trial 257 finished with value: -134.27781499999998 and parameters: {'gamma': 0.98, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 2.4240492704272077e-05, 'ent_coef': 0.0011965020042249317, 'vf_coef': 0.9364510992516467, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:37,344]\u001b[0m Trial 258 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:40,868]\u001b[0m Trial 259 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:42,298]\u001b[0m Trial 260 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:45,601]\u001b[0m Trial 261 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:49,364]\u001b[0m Trial 262 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:50,745]\u001b[0m Trial 263 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:52,156]\u001b[0m Trial 264 finished with value: -124.30014080000001 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 7.116016967640992e-05, 'ent_coef': 0.0016516154459830126, 'vf_coef': 0.6963634733774546, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:53,586]\u001b[0m Trial 265 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:56,048]\u001b[0m Trial 266 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:03:57,544]\u001b[0m Trial 267 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:00,115]\u001b[0m Trial 268 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:01,677]\u001b[0m Trial 269 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:03,208]\u001b[0m Trial 270 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:06,588]\u001b[0m Trial 271 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:07,941]\u001b[0m Trial 272 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:09,543]\u001b[0m Trial 273 finished with value: -96.42289740000001 and parameters: {'gamma': 0.98, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 2.5438733721305263e-05, 'ent_coef': 1.5093352884834797e-05, 'vf_coef': 0.8014550112800741, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:10,997]\u001b[0m Trial 274 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:13,501]\u001b[0m Trial 275 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:14,906]\u001b[0m Trial 276 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:16,318]\u001b[0m Trial 277 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:17,739]\u001b[0m Trial 278 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:19,284]\u001b[0m Trial 279 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:21,828]\u001b[0m Trial 280 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:23,255]\u001b[0m Trial 281 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:24,937]\u001b[0m Trial 282 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:27,920]\u001b[0m Trial 283 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:29,253]\u001b[0m Trial 284 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:31,389]\u001b[0m Trial 285 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:33,283]\u001b[0m Trial 286 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:35,367]\u001b[0m Trial 287 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:04:36,748]\u001b[0m Trial 288 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:02,377]\u001b[0m Trial 197 finished with value: -127.3396694 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 0.0003433728017063992, 'ent_coef': 3.463344528496514e-06, 'vf_coef': 0.9464037018959098, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:03,912]\u001b[0m Trial 289 finished with value: -113.4811544 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 256, 'lr_schedule': 'linear', 'learning_rate': 0.06388774608256031, 'ent_coef': 0.00010635592665836387, 'vf_coef': 0.6296831702027303, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:04,200]\u001b[0m Trial 290 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:06,131]\u001b[0m Trial 292 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:08,125]\u001b[0m Trial 293 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:10,712]\u001b[0m Trial 294 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:11,938]\u001b[0m Trial 295 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:13,406]\u001b[0m Trial 296 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:14,874]\u001b[0m Trial 297 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:18,687]\u001b[0m Trial 298 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:20,695]\u001b[0m Trial 299 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:22,095]\u001b[0m Trial 300 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:25,007]\u001b[0m Trial 301 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:26,380]\u001b[0m Trial 302 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:27,686]\u001b[0m Trial 303 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:29,686]\u001b[0m Trial 304 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:32,969]\u001b[0m Trial 305 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:33,173]\u001b[0m Trial 247 finished with value: -124.4686956 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.5, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 4.0624224897414984e-05, 'ent_coef': 3.8722432984123943e-07, 'vf_coef': 0.42953927499657385, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:34,840]\u001b[0m Trial 306 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:35,786]\u001b[0m Trial 307 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:37,023]\u001b[0m Trial 309 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:39,748]\u001b[0m Trial 310 finished with value: -128.95396540000002 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.6, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.00011318726646964504, 'ent_coef': 2.141646209584004e-07, 'vf_coef': 0.5773199583130627, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:43,223]\u001b[0m Trial 311 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:44,625]\u001b[0m Trial 312 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:05:46,520]\u001b[0m Trial 313 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:06:54,186]\u001b[0m Trial 291 finished with value: -113.2600038 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 4.6620877497335005e-05, 'ent_coef': 1.9837790701702334e-07, 'vf_coef': 0.9335182528411383, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:06:55,814]\u001b[0m Trial 315 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:06:57,362]\u001b[0m Trial 316 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:06:58,800]\u001b[0m Trial 317 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:00,341]\u001b[0m Trial 318 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:02,187]\u001b[0m Trial 319 finished with value: -134.27781499999998 and parameters: {'gamma': 0.98, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 1.0332977384438457e-05, 'ent_coef': 0.0001229751366470798, 'vf_coef': 0.5297144380440544, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:03,926]\u001b[0m Trial 320 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:05,605]\u001b[0m Trial 321 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:07,312]\u001b[0m Trial 322 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:08,954]\u001b[0m Trial 323 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:25,717]\u001b[0m Trial 308 finished with value: -128.9627628 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 0.5, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 6.667401081833077e-05, 'ent_coef': 7.327427671856752e-06, 'vf_coef': 0.4442006965975001, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:27,157]\u001b[0m Trial 325 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:30,919]\u001b[0m Trial 326 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:32,533]\u001b[0m Trial 327 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:34,412]\u001b[0m Trial 328 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:38,127]\u001b[0m Trial 329 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:39,401]\u001b[0m Trial 330 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:42,060]\u001b[0m Trial 331 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:43,473]\u001b[0m Trial 332 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:44,969]\u001b[0m Trial 333 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:46,879]\u001b[0m Trial 334 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:48,855]\u001b[0m Trial 335 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:07:50,183]\u001b[0m Trial 336 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:17,279]\u001b[0m Trial 337 finished with value: -137.55960299999998 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': True, 'gae_lambda': 0.99, 'n_steps': 256, 'lr_schedule': 'linear', 'learning_rate': 0.031841751968538334, 'ent_coef': 0.00010815500610246293, 'vf_coef': 0.7028883699492607, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:20,125]\u001b[0m Trial 338 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:21,531]\u001b[0m Trial 339 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:23,938]\u001b[0m Trial 340 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:25,486]\u001b[0m Trial 341 finished with value: -134.27781499999998 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.95, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 1.8231001200422407e-05, 'ent_coef': 0.0021684911218135105, 'vf_coef': 0.9665607942551048, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:28,636]\u001b[0m Trial 342 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:30,031]\u001b[0m Trial 343 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:33,264]\u001b[0m Trial 344 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:35,046]\u001b[0m Trial 345 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:36,554]\u001b[0m Trial 346 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:37,909]\u001b[0m Trial 347 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:08:59,321]\u001b[0m Trial 324 finished with value: -132.5564654 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 1.0355640087174356e-05, 'ent_coef': 2.6567809927216526e-07, 'vf_coef': 0.9419664709011847, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:00,845]\u001b[0m Trial 349 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:02,656]\u001b[0m Trial 350 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:04,082]\u001b[0m Trial 351 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:05,456]\u001b[0m Trial 352 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:29,534]\u001b[0m Trial 314 finished with value: -133.2418404 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 1, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 2048, 'lr_schedule': 'linear', 'learning_rate': 1.6630580621648354e-05, 'ent_coef': 3.526944859682038e-07, 'vf_coef': 0.2551926083819419, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:33,190]\u001b[0m Trial 354 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:36,068]\u001b[0m Trial 355 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:37,523]\u001b[0m Trial 356 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:38,801]\u001b[0m Trial 357 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:42,155]\u001b[0m Trial 358 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:43,488]\u001b[0m Trial 359 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:45,129]\u001b[0m Trial 360 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:46,749]\u001b[0m Trial 361 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:50,687]\u001b[0m Trial 362 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:52,055]\u001b[0m Trial 363 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:53,437]\u001b[0m Trial 364 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:54,799]\u001b[0m Trial 365 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:56,161]\u001b[0m Trial 366 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:09:57,489]\u001b[0m Trial 367 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:01,413]\u001b[0m Trial 368 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:03,766]\u001b[0m Trial 369 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:32,731]\u001b[0m Trial 348 finished with value: -128.4325568 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 2, 'use_rms_prop': False, 'gae_lambda': 1.0, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 0.00039589802369198836, 'ent_coef': 4.3503969469655513e-08, 'vf_coef': 0.41192795155461553, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:34,235]\u001b[0m Trial 371 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:36,560]\u001b[0m Trial 372 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:40,437]\u001b[0m Trial 373 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:42,427]\u001b[0m Trial 374 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:45,385]\u001b[0m Trial 375 finished with value: -135.9980762 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 5, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0006993343638635492, 'ent_coef': 1.573898775646769e-08, 'vf_coef': 0.7511414751629595, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:46,853]\u001b[0m Trial 376 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:48,376]\u001b[0m Trial 377 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:49,869]\u001b[0m Trial 378 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:51,432]\u001b[0m Trial 379 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:53,075]\u001b[0m Trial 380 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:55,968]\u001b[0m Trial 381 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:57,505]\u001b[0m Trial 382 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:58,782]\u001b[0m Trial 383 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:10:59,860]\u001b[0m Trial 353 finished with value: -134.71557860000001 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 1.171172115134318e-05, 'ent_coef': 1.4726782253313335e-07, 'vf_coef': 0.7375998926808327, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:00,363]\u001b[0m Trial 384 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:01,347]\u001b[0m Trial 385 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:01,909]\u001b[0m Trial 386 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:02,771]\u001b[0m Trial 387 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:03,455]\u001b[0m Trial 388 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:04,156]\u001b[0m Trial 389 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:06,523]\u001b[0m Trial 391 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:08,009]\u001b[0m Trial 390 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:08,503]\u001b[0m Trial 392 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:10,035]\u001b[0m Trial 393 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:10,357]\u001b[0m Trial 394 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:11,514]\u001b[0m Trial 395 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:13,193]\u001b[0m Trial 396 finished with value: -147.8239826 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 0.6, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0008813757485267063, 'ent_coef': 5.987730916549549e-06, 'vf_coef': 0.7186988874569289, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:13,872]\u001b[0m Trial 397 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:14,587]\u001b[0m Trial 398 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:15,390]\u001b[0m Trial 399 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:16,868]\u001b[0m Trial 400 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:18,303]\u001b[0m Trial 402 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:19,044]\u001b[0m Trial 401 finished with value: -211.4740086 and parameters: {'gamma': 0.9, 'normalize_advantage': False, 'max_grad_norm': 2, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 6.180039198205772e-05, 'ent_coef': 8.428500449734088e-08, 'vf_coef': 0.19541578706665752, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:19,906]\u001b[0m Trial 403 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:20,691]\u001b[0m Trial 404 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:21,904]\u001b[0m Trial 405 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:24,461]\u001b[0m Trial 406 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:25,219]\u001b[0m Trial 407 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:27,360]\u001b[0m Trial 408 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:28,743]\u001b[0m Trial 410 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:30,069]\u001b[0m Trial 411 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:31,912]\u001b[0m Trial 412 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:33,485]\u001b[0m Trial 413 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:11:35,309]\u001b[0m Trial 414 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:01,953]\u001b[0m Trial 415 finished with value: -113.4811544 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.3, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 256, 'lr_schedule': 'linear', 'learning_rate': 0.11349795435459757, 'ent_coef': 3.5428632492927917e-06, 'vf_coef': 0.6802762947368971, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:06,047]\u001b[0m Trial 416 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:09,581]\u001b[0m Trial 417 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:10,977]\u001b[0m Trial 418 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:12,477]\u001b[0m Trial 419 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:14,016]\u001b[0m Trial 420 finished with value: -133.18941260000003 and parameters: {'gamma': 0.98, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 3.679827106300484e-05, 'ent_coef': 3.367512771290028e-06, 'vf_coef': 0.44167331063399357, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:16,153]\u001b[0m Trial 421 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:12:20,168]\u001b[0m Trial 422 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:14,428]\u001b[0m Trial 409 finished with value: -121.4018822 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': False, 'gae_lambda': 0.9, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 1.9305133159086045e-05, 'ent_coef': 5.093326507681397e-07, 'vf_coef': 0.9529365434217794, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:15,850]\u001b[0m Trial 424 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:18,125]\u001b[0m Trial 425 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:19,474]\u001b[0m Trial 426 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:22,483]\u001b[0m Trial 427 finished with value: -135.9980762 and parameters: {'gamma': 0.95, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.9, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.006875177268161239, 'ent_coef': 2.3967952445611972e-05, 'vf_coef': 0.719334477152495, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:24,302]\u001b[0m Trial 428 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:26,182]\u001b[0m Trial 429 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:28,792]\u001b[0m Trial 430 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:30,394]\u001b[0m Trial 431 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:31,781]\u001b[0m Trial 432 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:33,323]\u001b[0m Trial 433 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:34,986]\u001b[0m Trial 434 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:38,646]\u001b[0m Trial 435 finished with value: -135.9980762 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.6, 'use_rms_prop': True, 'gae_lambda': 0.99, 'n_steps': 32, 'lr_schedule': 'linear', 'learning_rate': 0.0003546406409798696, 'ent_coef': 1.510632354482171e-07, 'vf_coef': 0.519600976219788, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:40,795]\u001b[0m Trial 436 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:42,313]\u001b[0m Trial 437 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:43,783]\u001b[0m Trial 438 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:45,808]\u001b[0m Trial 439 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:47,040]\u001b[0m Trial 370 finished with value: -133.8692218 and parameters: {'gamma': 0.995, 'normalize_advantage': False, 'max_grad_norm': 0.3, 'use_rms_prop': False, 'gae_lambda': 0.8, 'n_steps': 2048, 'lr_schedule': 'constant', 'learning_rate': 2.408318198512348e-05, 'ent_coef': 4.182924707392695e-05, 'vf_coef': 0.6999485796253616, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:48,288]\u001b[0m Trial 440 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:49,680]\u001b[0m Trial 442 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:53,201]\u001b[0m Trial 443 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:54,988]\u001b[0m Trial 444 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:56,234]\u001b[0m Trial 445 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:13:59,054]\u001b[0m Trial 446 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:01,407]\u001b[0m Trial 447 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:02,917]\u001b[0m Trial 448 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:04,497]\u001b[0m Trial 449 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:07,023]\u001b[0m Trial 450 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:08,624]\u001b[0m Trial 451 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:10,031]\u001b[0m Trial 452 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:11,518]\u001b[0m Trial 453 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:12,768]\u001b[0m Trial 454 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:15,180]\u001b[0m Trial 455 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:16,593]\u001b[0m Trial 456 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:18,120]\u001b[0m Trial 457 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:22,385]\u001b[0m Trial 458 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:24,977]\u001b[0m Trial 459 finished with value: -135.9980762 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.8, 'use_rms_prop': False, 'gae_lambda': 0.98, 'n_steps': 32, 'lr_schedule': 'constant', 'learning_rate': 1.7869864532227496e-05, 'ent_coef': 2.3272077013290256e-05, 'vf_coef': 0.9161572010625639, 'ortho_init': False, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:26,406]\u001b[0m Trial 460 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:28,423]\u001b[0m Trial 461 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:32,273]\u001b[0m Trial 462 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:34,243]\u001b[0m Trial 463 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:35,765]\u001b[0m Trial 464 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:37,303]\u001b[0m Trial 465 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:38,828]\u001b[0m Trial 466 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:42,455]\u001b[0m Trial 467 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:43,807]\u001b[0m Trial 468 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:45,411]\u001b[0m Trial 469 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:47,409]\u001b[0m Trial 470 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:48,959]\u001b[0m Trial 471 finished with value: -134.27781499999998 and parameters: {'gamma': 0.95, 'normalize_advantage': False, 'max_grad_norm': 0.9, 'use_rms_prop': True, 'gae_lambda': 0.98, 'n_steps': 16, 'lr_schedule': 'constant', 'learning_rate': 9.239443891992464e-05, 'ent_coef': 0.00016436244174377953, 'vf_coef': 0.08472834097933753, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:50,444]\u001b[0m Trial 472 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:51,781]\u001b[0m Trial 473 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:54,198]\u001b[0m Trial 474 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:57,042]\u001b[0m Trial 475 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:14:58,672]\u001b[0m Trial 476 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-08-04 22:15:37,844]\u001b[0m Trial 441 finished with value: -133.9207936 and parameters: {'gamma': 0.98, 'normalize_advantage': True, 'max_grad_norm': 0.9, 'use_rms_prop': False, 'gae_lambda': 0.9, 'n_steps': 1024, 'lr_schedule': 'constant', 'learning_rate': 1.056150866752446e-05, 'ent_coef': 2.0509129661623149e-07, 'vf_coef': 0.9225245560505027, 'ortho_init': False, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 38 with value: -65.7153034.\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env LunarLander-v2 --n-timesteps 1 --progress -optimize --n-jobs 3 --verbose 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
