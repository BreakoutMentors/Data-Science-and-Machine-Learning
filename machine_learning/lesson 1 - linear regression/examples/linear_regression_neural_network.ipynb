{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "linear_regression_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-migration-to-pytorch/machine_learning/lesson%201%20-%20linear%20regression/examples/linear_regression_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgtcQi5cPcFU"
      },
      "source": [
        "# Regression\n",
        "<figure>\n",
        "<img src='https://media.makeameme.org/created/brace-yourself-regression-599599.jpg' width='50%' height='50%'></img>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Perhaps the most natural machine learning task to wrap our heads around is *regression*--a set of methods for modeling the relationship between one or more independent variables (i.e., $x$) and a dependent variable (i.e., $y$). Regression problems pop up whenever we want to output a *numeric* value. \n",
        "\n",
        "Most applications of regression fall into one of the following two broad categories:\n",
        "- *inference* - to explain the relationship between the inputs and outputs (most common).\n",
        "- *prediction* - to predict numeric outputs given inputs (most common in machine learning). \n",
        "\n",
        "A few everyday examples of regression include predicting prices (of homes, stocks, etc.), predicting length of stay (for patients in the hospital), and demand forecasting (for retail sales). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoeVWX-5j7Gt"
      },
      "source": [
        "## Linear Regression\n",
        "<figure>\n",
        "<img src='https://learningstatisticswithr.com/book/lsr_files/figure-html/regression1a-1.png' width='60%'></img>\n",
        "</figure>\n",
        "\n",
        "\n",
        "*Linear regression* is probably the simplest and most popular regression method. It is called \"linear\" regression because we **assume** that the relationship between the independent variables $x$ and the dependent variable  $y$ is linear--that is, $y$ can be expressed as a *weighted sum* of the elements in $x$, plus some *noise* in the data. In mathematical terms this can be expressed as: $$y = wx + b$$\n",
        "where $w$ represents the learnable *weights* and $b$ the *bias* (i.e., you may recognize it as the *intercept*). The weights determine the influence of each feature on the prediction and the bias tells us what the predicted value would be if all the features $x$ values were 0. Given features of a training dataset  $X$  and corresponding (known) labels  $y$ , the goal of linear regression is to find the weight vector $w$  and the bias term  $b$  that given features of a new data sample from the dataset  $X$, the sample's label will (in expectation) be predicted with the lowest *error*.\n",
        "\n",
        "To motivate the linear regression approach, suppose that we wish to estimate the prices of houses (in dollars) based on their area (in square feet). To actually fit a model for *predicting* house prices, we need to get our hands on a dataset consisting of sales for which we know the sale price and area for each home. In machine learning terminology, the dataset is called a *training dataset* or *training set*, and each row (the data corresponding to one sale) is called a *sample*. The thing we are trying to predict (price) is called a *label* (or *target*). The independent variables (only one in this case--area), upon which the predictions are based, are called *features*. \n",
        "\n",
        "Generally, we will use  $n$  to denote the total number of samples in our dataset. We index a sample by $i$, denoting each sample as  $x^{(i)}=[x^{(i)}_{1}]^{⊤}$  ($x^{(i)}_{1}$ represents the area) and the corresponding label as $y^{(i)}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lV-loKm6kLV"
      },
      "source": [
        "## Linear Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM4R7LoM6kJo"
      },
      "source": [
        "To make the above linear regression formula more concrete, let's translate it to our house prices example: \n",
        "$$\\text{price} = w_{\\text{area}}\\cdot{area} + b $$\n",
        "where $w_{\\text{area}}$ is the learnable *weight* and $b$ is the *bias* (or *intercept*).\n",
        "\n",
        "The goal is to choose the weight  $w$  and the bias  $b$  such that on average, the predictions made according to our model *best fit* the true prices observed in the data. \n",
        "\n",
        "Before we can go about searching for the best *parameters*  $w$  and  $b$, we will need two more things: (i) a way to measure the quality of the model; and (ii) a procedure for updating the model parameters to improve its accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTuHWKk3loN6"
      },
      "source": [
        "# Loss Function\n",
        "<figure>\n",
        "<img src='https://d2l.ai/_images/fit_linreg.svg\n",
        "' width='60%'></img><figcaption>Calculating loss: measuring the distance between the predicion and real value</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Before we build our model, we need to determine a measure of fitness. The *loss function* quantifies the distance between the *true* and *predicted* value of the *target*. The loss will usually be a non-negative number where smaller values are better and perfect predictions incur a loss of  0 . The most popular loss function in regression problems is the *sum of squared errors* (SSE). When our prediction for an example  $i$  is  $\\hat{y}^{(i)}$  and the corresponding true label is  $y^{(i)}$ , the squared error is given by:\n",
        "$$\n",
        "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.\n",
        "$$\n",
        "\n",
        "The constant  1/2  makes no real difference but makes some future math more convenient, cancelling out when we take the *derivative* of the loss (don't worry if you don't know about derivatives yet). To make things more concrete, consider the example above where we plot a regression problem, the blue line corresponds to the prediction vs true value. \n",
        "\n",
        "To measure the quality of a model on the entire dataset, we simply *average* (or equivalently, sum) the losses on the training set.\n",
        "\n",
        "$$\n",
        "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
        "$$\n",
        "\n",
        "When training the model, we want to find parameters ( $w^{∗}$,$b^{∗}$ ) that minimize the total loss across all training examples:\n",
        "\n",
        "$$\n",
        "\\mathbf{w}^*, b^* = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  L(\\mathbf{w}, b).\n",
        "$$\n",
        "\n",
        "But how do actualy find the best parameters to minimize the total loss? We'll use *gradient descent*--a fundemental concept in modern machine learning, particularly *deep learning*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHW5a943sDqk"
      },
      "source": [
        "# Gradient Descent\n",
        "\n",
        "<figure>\n",
        "<img src='https://media0.giphy.com/media/O9rcZVmRcEGqI/source.gif' width='100%'></img><figcaption>Gradient descent: finding the best model parameters</figcaption>\n",
        "</figure>\n",
        "\n",
        "The key technique for optimizing nearly any deep learning model, and we can use for linear models too, consists of *iteratively* reducing the error by updating the parameters in the *direction* that incrementally *lowers* the loss function. This algorithm is called *gradient descent*. In general, we can find acceptable parameter values after many interations of reducing the loss.\n",
        "\n",
        "The most naive application of gradient descent consists of taking the derivative of the true loss, which is an average of the losses computed on every single example in the dataset. In practice, this can be extremely slow. We must pass over the entire dataset before making a single update. Thus, we will often settle for sampling a random *batch* of samples every time we need to compute the update, this method is called *stochastic gradient descent*.\n",
        "\n",
        "\n",
        "At a high level, the *stochastic gradient descent* method consists of feeding a random batch of samples to the model, computing the derivative (gradient) of the average loss with respect to the batch samples and the model's current parameter values. Finally, we update the model parameters by multiplying the gradient by a predetermined value called the *learning rate* $ > 0$ and substract the resulting output from the current parameter values.  \n",
        "\n",
        "Let's summarize the steps of *stochastic gradient descent*: \n",
        "1. We initialize the values of the model parameters, typically with random values.\n",
        "2. We iteratively sample random batches from the data (many times), updating the parameters in the direction of the negative gradient.\n",
        "3. After many iterations, we hope that the estimated model parameters ($\\hat{w}, \\hat{b}$, the \"hat\" symbol denotes estimates) can produce acceptable predictions (close enough to the true values).\n",
        "\n",
        "Linear regression can actually be solved using a simpler method than stochastic gradient descent, but the stochastic gradient descent algorithm is so fundemental to deep learning that we will use it for linear regression too. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFv_ek5F8b1D"
      },
      "source": [
        "# Linear Regression: What makes us happy?\n",
        "Now let's apply the linear regression method to a real-world problem--predicting happiness given features corresponding to a country's population. To fit a model, the process involves several steps: \n",
        "\n",
        "1. Find a dataset related to our question. \n",
        "2. Explore the dataset - clean the data and visualize it (if possible).\n",
        "3. Prepare data for a *model*.\n",
        "4. Build a model. \n",
        "5. Train the model using an algorithm such as stochastic gradient descent.\n",
        "6. Evaluate the quality of our model.\n",
        "7. Draw conclusions. \n",
        "\n",
        "For step 1, we found the World Happiness (https://www.kaggle.com/unsdsn/world-happiness) dataset. The dataset contains information about the state of global happiness with happiness scores and rankings for nearly every country on earth. Pretty cool right! Next, we explore the dataset and define our $x$ and $y$ variables. Then, we build a linear regression model. Following, we train the model using stochastic gradient descent. Finally we evaluate the model and draw conclusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QeOZ9rN8b1E"
      },
      "source": [
        "# import the libraries we be need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA78zSFaOlje"
      },
      "source": [
        "## 1. Explore + Visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmr-AHsN8b1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a69c2574-b7e9-439f-e475-e631e33e7fb5"
      },
      "source": [
        "# load the dataset into a dataframe\n",
        "data_url = 'https://raw.githubusercontent.com/krmiddlebrook/intro_to_deep_learning/master/datasets/world-happiness/2019.csv'\n",
        "happy2019 = pd.read_csv(data_url)\n",
        "happy2019.head() # view the first 5 rows of the data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall rank</th>\n",
              "      <th>Country or region</th>\n",
              "      <th>Score</th>\n",
              "      <th>GDP per capita</th>\n",
              "      <th>Social support</th>\n",
              "      <th>Healthy life expectancy</th>\n",
              "      <th>Freedom to make life choices</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Perceptions of corruption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Finland</td>\n",
              "      <td>7.769</td>\n",
              "      <td>1.340</td>\n",
              "      <td>1.587</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>7.600</td>\n",
              "      <td>1.383</td>\n",
              "      <td>1.573</td>\n",
              "      <td>0.996</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.252</td>\n",
              "      <td>0.410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Norway</td>\n",
              "      <td>7.554</td>\n",
              "      <td>1.488</td>\n",
              "      <td>1.582</td>\n",
              "      <td>1.028</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.271</td>\n",
              "      <td>0.341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Iceland</td>\n",
              "      <td>7.494</td>\n",
              "      <td>1.380</td>\n",
              "      <td>1.624</td>\n",
              "      <td>1.026</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>7.488</td>\n",
              "      <td>1.396</td>\n",
              "      <td>1.522</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.557</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Overall rank Country or region  ...  Generosity  Perceptions of corruption\n",
              "0             1           Finland  ...       0.153                      0.393\n",
              "1             2           Denmark  ...       0.252                      0.410\n",
              "2             3            Norway  ...       0.271                      0.341\n",
              "3             4           Iceland  ...       0.354                      0.118\n",
              "4             5       Netherlands  ...       0.322                      0.298\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2arfDeOvX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69f0139-f919-4b5e-c35e-aeaefadfb82e"
      },
      "source": [
        "# how many rows and columns are in the dataset\n",
        "happy2019.shape # looks like 156 rows and 9 columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQXvyqba3kwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "eaf505e3-ac4e-462c-e4bb-52697e64b19b"
      },
      "source": [
        "# visualize a scatter plot of GDP per capita and happiness score \n",
        "happy2019.plot.scatter(x='GDP per capita',\n",
        "                      y='Score');"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7QcVZ0v8O+v+zwSkpjEJKIkHCET0JswJMhRlEBuSNRBiDAOKA7iY0aN44C4dIaHl4ui3LkjoteZMXE0i+UsvQqCYRAEdeCSZGJ4RAImIYk8jhESgmPIkQAnQp+c7t/9o6pP6nSqu6uqa1ftqvp+1srinO7qrt1Fn/3b+7cfJaoKIiIqnlLaBSAionQwABARFRQDABFRQTEAEBEVFAMAEVFBMQAQERWU0QAgIp8Rke0isk1EbhKRcSbPR0REwRkLACIyE8ClAPpV9QQAZQDvN3U+IiIKx3QKqAvAeBHpAnAEgGcNn4+IiALqMvXGqrpHRL4KYBeAlwHcrap3t3rN9OnT9ZhjjjFVJCKi3Hn44Yf3qeqMKK81FgBEZCqAcwEcC2A/gB+JyEWq+v2G45YDWA4AfX192LRpk6kiERHljog8HfW1JlNAbwfwW1V9TlUPAvh3AKc2HqSqq1S1X1X7Z8yIFMSIiCgCkwFgF4C3isgRIiIAlgL4tcHzERFRCMYCgKpuBLAawCMAHnXPtcrU+YiIKBxjYwAAoKpfAPAFk+cgIqJouBKYiKigGACIyAqDQxVs2b0fg0OVtItSGEZTQEREQdy+eQ+uuHUrukslHKzV8JXzTsQ5C2amXazcYw+AiFI1OFTBFbduxSsHa3ipMoJXDtZw+a1b2RNIAAMAEaXqmedfRndpbFXUXSrhmedfTqlExcEAQESpmjV1PA7WamMeO1irYdbU8SmVqDgYAIgoVdMm9uIr552Icd0lTOrtwrjuEr5y3omYNrE37aLlHgeBiSh15yyYiYVzpuOZ51/GrKnjWfknhAGAiKwwbWJvy4p/cKjCABEzBgAish6niZrBMQAispqJaaJcdOZgD4CIrFafJvoKDs0Uqk8TjZIKYm/iEPYAiMhqs6aOx3C1OuaxqNNEuehsLAYAIrLahoF9qOmh38sCXLx4TtvX+aV5uOhsLKaAiMha9Rb7weqhCFBV4Nvrf4OV6waapm+apXm46Gws9gCIyFp+LXYAGKpUm6ZvWqV5uOhsLPYAiMhafi12L7/B4HaDxlx0dgh7AERkLW+LfUJP+bDn/dI3QdI80yb2Yv7RUwpd+QPsARCR5eot9u3PvogHdu7Ddzb8Fj3l8mhuv7ESrweNyxvGAIpe2fthACAi620Y2Dc6qAsIli+ajQtP6WtaqTPNEwxTQESUmCgrcBsHdSsjNaxcN9D2dUzztMceABElIsoK3MGhCtY+thdlkTGPd7ISmA5hACAi47yt+PrsnMtv3YqFc6Y3rcTrAaMswIFhzt03gSkgIjIu7Apcb8DwVv49ZSn83P04sQdARMaFXYH7zPMvH5b2AYCRmuLuS0/HnCMnGSln0bAHQJQhWd3GOOwK3FlTx2N4pHrY4zUFnn3hFdPFLQz2AIgyIuvbGIeZmjltYi8+dvps/Ot/7vR5Vn0eoyjYAyDKgCxuY+zXWwkzNfNjp89Gd7lh9k9ZMO+oybGXtagYAIgyIGvbGN++eQ8WXrcGF92wEQuvW4M7Nu8J/R7TJvbia++dj96uEo7oKaO3q4SvvXc+B39jxBQQUQZkaRvjKFM+m8nait6s3bieAYAoA7K0v02UWzi2qjinTey18nM2yuIYjbEAICJvAHCz56HZAD6vqv9k6pxEeZaV1nDY3kqaFWdcLfY4ez1JMhYAVPVxAAsAQETKAPYAuM3U+YiKIAut4TC9lTQrzjgDT9w3rk9KUimgpQB+o6pPJ3Q+IkpR0N5KkIrTRF497sCTpTEar6QCwPsB3JTQuYjIAkF6K+0qTlPpobhb7Fkao/EyHgBEpAfAOQA+1+T55QCWA0BfX5/p4hCRRZpVnACw/om9uHz1FlRGNPb0kIkWe1bGaLyS6AG8C8Ajqvp7vydVdRWAVQDQ39/PJX5EBdNYcW4Y2IeF161BSQSVkbFVQlx5dVMt9iyM0XglEQD+Ekz/EFEL9YrTm5v3066VHma8IIst9rgZDQAiMgHAOwB8wuR5iMguUQdu/XLzAHBEdxk1aMtWepTxgqy12ONmNACo6gEA00yeg4js0snArV9uvrerhG998GTMO+pVLReSRZnVk7WVu3HjXkBEFJtON63z2zb6+vNPxKLjZ7SsoKPslRTHfkVZx60giCg2cUyvjJKbDzurJ6srd+PGHgARxSau6ZVhto2uHx/mhjNZ213VFPYAiCg27aZXmsy5h+k5ZHXlbtwYAIgoVs0q4iQ2fQs6qyerK3fjxgBARLFrrIhtzLlzHQADABElwNbdMou+DoCDwERkHHPudmIAIMoBvxuw2yTsLB1KBlNARBmXlVsR+uXci74SN20MAEQZZuPgaivenHtWAleeMQVElGFZXdDU6ZYRFA8GAKIMy+rgalYDV94wABBlWFYHV7MauPKGYwBEGZfFBU1BV+JykNgsBgAqvDxUMp0uaErjGrQLXBwkNo8BgAqNlUy616BZ4Mra7Kas4hgAFRZnoth7DdoNEtu+8C2MND8LewBUWLbuT5OkJK5BlPRSq0HiPPXa0v4s7AFQYXEmCjChp4zKSHXMY3Feg6i3XWw2uwmAlT2WKGzofbEHQIVl857wSQzK1lufpZIAVUVvWSAlie0adJrH9xsk3rJ7f256bTb0QBkAqNBsnEJpMi1QDywTesqjlXOdiuCuS07DnCMnxXKuOCq4xkHiPPXabPgsTAFRodk2BdRkWsCbjjnrGxugNR3zfG+5hAPD1SavDs9EBWfDwre4Bm1t+CzsAVBhpT0A58dUWsAvHdMo7tZnY4ptuFrFxYvndPy+afba4v7OpN0DZQ+ACsmGATg/ptICftMqx3WX0FOWWFqfzVrF5yyYifuuWIKPL5oNQLBq/c7Ag8GtWtrTJvZi/tFTEm/5m/jOpPFZ6tgDoNxqld6xYQDOj6mBab/AAgA/vfR0HBiuBmp9Nl7P+u/b9ryAa+/a0bJV/M11A6iM1FAZCTYYXKTeWZoYACiX2lUgNgzANWMiLdAssAQd8G28nu/rn4VbNj2DrpJgqOKMGzSb6RO24rR1FbDN35moGAAod4JUIDZOAW1sYcddlqiBxe96fu+BXU2Pb6zcw1actra0bfzOdIoBgDIpjvROHC3tuGYRJZXyiBJY/K5nK6+MjGBCT3nMOcNUnDa3tNMetI0bAwBlTpzpnU5a2nFV2iZSHnFOb202ftCMoIRlKzaMuR5hKk7bW9omemdpYQCgTLElvRNnpR13yiNqYGoWNPyu5/v6Z+Hmh3ajMqKHvc9wtQZU/f+/BP08eWtp24oBgDIlyfROJ+UI0wKPM+URNTC1Cxp+1/PTS4/HjRt3YcXaAZRF8MeDYxeRlUU6ytvnqaVtK6PrAERkioisFpHHROTXIvI2k+ej/Aub3jE1v7rdbpVhNkCLuiLUb558lHvtBp3f3ng9p03sxaeWHof7r1yCb33wZPR2jT3vgeEqtj37QsvPkLY8bSsdhekewD8D+Lmqni8iPQCOMHw+yjlb8sPNygEgUgs8bI+lWYs9Sm+i0xTUtIm9WHT8DHx+2Vxc9eNtY5679s4dOHPea61sydu41iBpxgKAiEwGsAjARwBAVYcBDJs6HxWHLfnhuHerDJryaJfmCRsg40pBnTBzMib2lkfXBQB2TN/0Y+tag6SZ7AEcC+A5AP8mIvMBPAzg06p6wHuQiCwHsBwA+vr6DBaH8sSW/HAau1W2a7GHDZCtejNbdu8PHGRnTR2PkYYN5myZvtnI1rUGSTM5BtAF4E0A/lVVTwJwAMCVjQep6ipV7VfV/hkzZhgsDpF5SezwGCTIhB3/qO/Z8/2PnYL7rlgCBULfyMWG3S2DsnmtQZJE9fBpXLG8schrATyoqse4v58O4EpVPbvZa/r7+3XTpk1GykMUVidz6U1vM33H5j2Htdjb5a+DlmlwqIKF160Zc6+Acd0l3HfFksNe5/eerc4T9niTolxDG4nIw6raH+W1xlJAqvpfIrJbRN6gqo8DWApgh6nzUX7YsEd/pwOEplNUcQ0a+wmaHmn2ns0+u9/xCqQ2EGvLWFKajPUAAEBEFgC4AUAPgJ0A/kpVn292PHsAZMPMjDAt4CwI+3mCHB/He/Z2CQAZ3SG03XuQv056AEbXAajqZje/f6Kq/nmryp/Ilj36o8ylt1mUz3Px4jno7Wp+r4Cw7+l3fFlKKJckVLkoXlwJTNZIamZGuxRT3gYIw3webw8MECxfNBsXntJ32HUKe438jq9qDdCxASDL1zmLeEcwskYSFW+QVbpZms0SRNDP09gDq4zUsHLdwOhz3hWzYa+R3/HXnz8f15+fn+ucRUbHAMLiGACZnJkRJW/tdwesrA4Ytiv/lt37cdENG/FSZWT0sUm9Xfj4otn45roB3/8nYa+JTbOA8sLKWUBEUZicmRE2xeSdzWLD4HSn2s1M8uuBDVerWLnWuZ2j34pZv/dsVaH7HW/Lor4iYgqIrGNqE7eoKSYTg9M2bkLml6a55Izj0FNuHLwVrH1sr2/Zw26ER+liD4Ayo9NUQdSN5GzZrz8JjT0wAKPjAHUHhqu45ifb8T9v33ZYOoj762QLAwBlQlyVZqsUU7MAY8N+/Umqp2Tq1+Pqs+fi2rt2oCyCA8PORm/1Dd+8Zef+OtnDAEDWi7vS9Ms5twowcW5BHbSSTHtgtPF6XL1sLnrLJVzzk+1Nd/vM2/TZImAAIOuZblkGCTBxDU4HqSTTThH5XY9r79yBOy85reVun7bcq4GCYwAg65luWQYNMHHMVmlXSdqQImp2PQ4MV9tW8NxfJ1sCBwARGQ+gz93YjSgxjZXmcLWKixfPie39k05dtKokgwQj0+mhVtdj/tFT2lbwnNaZHYGmgYrIuwFsBvBz9/cFInKHyYIRedX3q//4otkABKvW74xtmmEaK3+bTXVtF4y80yxP/fK9+Ma9T8Y+lbTd9TA1TZeSF2glsIg8DGAJgHXuzV0gIo+q6p/GWRiuBKZWTO/SmfbAa12z1dB+nx8AertKuP78+McJbLke1FoSK4EPquoLImM2brJnDwkyzobKwPRgsC2pi2YpIr/PDwCVkZqRcQJbrgeZEzQAbBeRCwGUReQ4AJcCuN9cscgmac9KqSvSNEPvXPz6fXn9Pn9dp4HQhgAflzx9FtOCBoBPAbgKQAXAjQD+A8D/MlUosocNs1LqijbN0C/wfuW8E3HZ6i2ojMR383VbAnwc8vRZktA2AIhIGcBdqnoGnCBABWLb6s6sTzMMc19ev8B73xVLcP+VS3Hjxl1YsXYAPeXOAqFNAb5TefosSWkbAFS1KiI1EZmsqi8kUSiyh41pl6zmpuO6L+/8o6fgU0uPw4Wn9HUcCFudp/58VgKtbY2VLAiaAhoC8KiI3APgQP1BVb3USKnIGkVLu5gStnUaJPDGEQibnWfbnhdwwaoHYrkHQFJsbKzYLmgA+Hf3HxVQ1tMuNohyL4IwgTdqpex3nvrmb37BasPAPmtz7GyshBcoAKjqd0WkB8Dx7kOPq+pBc8Ui22Q17WKLKK3ToIG304HPxvM88/zLKMvhN2vf/uyL1ufY2VgJJ+hK4MUAngSwEsA3ATwhIosMlosyKskbndh4U5Vmpk3sxftOnjXmsff1zxqzvYPfZ2m36jaum9V4z7Ntzwuj2z7XOcFL3ZvFH+IdL7AFVyoHFzQF9DUA76zvAyQixwO4CcDJpgpG2ZPkFLysTfcbHKrgloefGfPYLZuewaeXHh85rTI4VMHax/b6ttajDnwODlVw7V07Dnv86rPnYt5Rk5ljz5mgt4Ts9m4Cp6pPAOg2UyTKIhO3TUzyXKZ7E/UxAK/GtIr3swz8/qWm5RkcquBf7n0Sp375Xlzzk+2+rfWolbJfOSf0lnHCzMmp7JlEZgXtAWwSkRsAfN/9/QMAuGkPjUpyCl7WbtE4OFTBCy8PY7jaPK3i/Sy1ag1nfWMDesuH7wX0g427sGLNkxiuOgvBKiOH3nNCTxlV1Y4qZb+ximpNRwMKc+z5EjQAfBLAxXC2gACAX8AZCyACkOwUvKDnCjIzxvTiIW9wqSnQVQLGd3eNVux+aZXhGoBaDcMjh8rz0isj+NKdO1AZ8d8KYkJvGV989zyc8cbXdFTuIDNpOCEgP4IGgC4A/6yq/wcYXR3MbwCNSnIKXpBzBW3Vm+y5+AWX3q4SVn7gTZh31KtG3//qs+fiqh9va/o+ZRF88c4dowHBT7WmHVf+dWzlF0fQAHAvgLfDWRAGAOMB3A3gVBOFomxKsuJod3P3oK16kz0Xv+DSUy5h8vjuMeU4YeZkTOwtj7nX7pjyVGvo6SpheMT/PL1dEnuwZSu/GIIOAo9T1XrlD/fnI8wUibIsySl4zc7VbMDVb7pi48Bmb5fEdrexoMFl1tTxh91rF3By+uO6S/jCu+f5Pt9TFvzdO47H/VcutXoGFNkraA/ggIi8SVUfAQAR6Qdg1+RfIlfYVn29N/GDjbuwcu0AVq3fiZXrBjoeDA6aFvNdjbtsLk44avJo72bSuC7PLTFruOSMObjwlD620qkjQe8I9mYAPwTwrPvQ6wBcoKoPx1kY3hEs+2zZJ6bZXbWaMXm3sTA7gLY6zpZrS3Yxdkcwt+LfraoPicgbAXwCwF/AuTfwbwMU7CkALwGoAhiJWkjKBpsWZ4UdjzA5GBw0n97uuDB5eQYLCqJdCujbcAZ/AeBtAP4HnJvDLACwCsD5Ac5xhqrui1xCyoQo0ylNV1JhKsw87SRpUyAmu7UbBC6r6h/cny8AsEpVb1XVqwHEM1JGuRBm4BVwKqmF163BRTdsxMLr1uCOzXuSKGZTeVnlmuSKbMq+dj2Asoh0qeoIgKUAlod4LeDcOP5uEVEA31bVVRHLSZZr1oKe0FMevaetd+MzG3eVzMP8d94UhcJoV4nfBOA/RWQfnFk/vwAAEZkDIMjdwU5T1T0i8hoA94jIY6q63nuAiCyHG1j6+vrClp9iEEcqxm8my/tOnoVlKzYcloqwuZJqTBtlLZeep1QWmdcyAKjqP4jIvXBm/dyth6YMleCMBbSkqnvc/+4VkdsAvAXA+oZjVsEZT0B/f3/7KUkUSrsKLM58sbcFPaGnjGUrNvi28rNSSWUxl86bolAYQe4J/KDPY0+0e52ITABQUtWX3J/fCeBLkUpJkbSrwEykYuot6C2797e8p63tlZStaaog8pDKomQEXQgWxZEAbhNnr/IuADeq6s8Nno88glRgJlMx7Vr5tldSNqepguBWDhSEsQCgqjsBzDf1/tRakArMZCom7l0lk87FZyVNRdQJkz0ASlGQCsx0vjiuVn5cufgwQSQrufSsDVKTXQJtBZEUbgURr6DbIdhcicS1RUPUIGLztcniIDXFz9hWEJRtQVvgNueL48jFdzKga+u1yfIgNdmDASDnbK3AgoojF2/TgG69R3FwpIqnBv+IBUdPwZwjJ4V+H5s+E2UXAwABMJvq6PS9L148ByvWPomecjlSLt6WAd16ymakWoP35l4felsfvnTun4Z6L1s+E2VbLgKAzXnaLDCZS+7kvb2vBQTLF82OtAe+DQO63pRNo+89sAsfeusxoXoCNnwmyr7MBwAOhHXGZC65k/f2e+3KdQO48JRo24WYWncQtPHhl7Lx2rx7f+hUkO1rKch+mQ4ASQ6E5bWXYTKX3Ml7myhX3OMhYRoffikbrwVHT4lUhqyP8VC6gt4T2EphtyCOyratiweHKtiye38sW/yazCV38t6257jDbrvs3W66q+Gv7kNv64s0EEzUqUz3AJKoJGybbhd3ystkLrmT97Ytx93YA4zSQ/GmbDqdBUQUh0wHgCQqCZum2wUNRmHTVSZzyZ28ty05br+gu3DO9EiND2/Kpv/YacbKXJfX1CXFI9MBADBfSaSdivD+AQcJRlF7CCb35ekkT512jrtZ0L3viiWjjY+yCA5Wa7j67LlWVbKcIEHtZD4AAGYriTRTEY1/wFcvm9syGCWRrgpbqWS9Bdoq6J6zYCZeemUEX7xzB3q6Srj2rh2YNK7LikrWttQl2SkXAcC0KL2MTis+vz/ga+/cgavPnotr79rhG4xMp6vCVCqDQxX8YOMurGxYwGVD5RhGqx7g4FAF1961A8MjNQyPOM95r0eawc+m1CXZiwEgoDC9jDi63s3+gE+YORn3XbHEt2Ixna4KWqncvnkPLl+9FRV3uWtlxKkds9gCbdUDbHXTmw0D+4ylX4IElrRTl5QNDACuuFprcXW9W/0BNwtGptNVQSqV+uevjBw+5z2rLdBmPcBm12NCT9lY+iVo48K2WVRkJwYAxDtYFlfXO+ofcL2y2v7siwAU846aHOlzRC1TqxWvWW6B+gXdZtfjwHDVSPolbOPClllUZK/CB4C4B8uidL2b9T6i/gGbTD+0K1OzFa+9XWKsBZpmrt3vegwOVVqOG0Qta5TGRdqzqMhuhQ8AcQ+WhW25t+t9tPsDbqxQkpj90apMjZ9/uFrDJWfMibSJWxAmpjp2Os212Xeg08DMvD7FrfABwMQfVdCWe6eVtV/l9/ppE1Kf/ZFU6sFEsIsroDReAwCjdzaLWlbm9SluhQ8Apv6ognS9O+l9DPz+JVz2oy0YruqYCuXOS06zopWYROoh7t5b3AHFew1azRjK4upoyofCBwAgvT+qqL2P2zfvwWWrt2K4OvZ+zt2lEg4MVwvTSoy792Zy7nycZWVen+LCAOBK448qSu+j3kod9plmWa9Q5h89pRCtxLh7byZz7EzfkI0YAFIWtvfRbJplT3nsLJuitBLj7r11evvJJMtK1CkGAAuEqaxnTR2P4Wp1zGM9XSX89FOnFXZb4TiCXVy3n2ynKIGZsiHTN4Qpog0D+1DzpP67SsBXzz+xsJV/HBpv7lIZqWHluoGO3zOum/YQmcIeQIbUK6qDnsHfcqmEhXOmp1iq7It78JfbMFNWsAeQIX63wOwpx38LzLjZ3hqOc/A37K0iidLEAGCJIJVkFleC2nY/ZT/1GTrjukuY1NuFcd2lyIO/Sd2nmigOTAFZIK87PGbppiRxzdDJYpCm4mIASFmed3jM2k1J4pihk7UgTcVmPACISBnAJgB7VHWZ6fNlTZ53eLSlNZz0bqFZCtJUbEn0AD4N4NcAXpXAuTLHlkrSBBtaw2nNyMlKkKZiMxoARGQWgLMB/AOAz5o8V1i23Ky8XkletnoLylJCVfOVMkizNZylMQiiNJjuAfwTgMsBWLVKybZ52gpAFahCodr28MxJqzWctTEIoqQZmwYqIssA7FXVh9sct1xENonIpueee85UcUbZNk97cKiCv7tlM4arispIDcNVxWdv2cx54zHIc3qNKA4m1wEsBHCOiDwF4IcAlojI9xsPUtVVqtqvqv0zZswwWByHbfO0tz/7Iho39hypwb2nL3Uizvn9RHlkLAWkqp8D8DkAEJHFAP5eVS8ydb6g7GsVNsv55DAXlALOyCFqrnArgW1rFc47ajK6yzLmse6yYN5Rk1MpTx5Nm9iL+UdPYeVP1CCRhWCqug7AuiTOFYRNrcJpE3vxtffOx2Wrt6JcElRriuvPZ5qCiMwr7Epgm+Zp2xSQ/NgyZZaI4lWIAJCFCsymgORl25RZIopP7gMAK7DouJCKKN9yPQhs25z/rLFtyiwRxSvXAYAVWGfsmzJLRHHKdQAoWgUW9523bJsyS0TxyvUYgA27USbF1FiH7TOUiCi6XAcAoBgVmOnBWltnKBFRZ3IfAID8VGDNprNy10siiqIQASAPWqV4ijbWQUTxyPUgcF60m87KwVoiioI9gAwIkuIpwlgHEcWLASADgqZ48jLWQa1lYWsTygamgDIg7ymeuNcv5Nntm/dg4XVrcNENG7HwujW4Y/OetItEGcYeQEbkNcXDvZqC495MFDf2ADIkbzc24V5N4XBrE4obA0CMmMoIhxVaOJzuS3FjAIhJnLnZogQSVmjh5H0siJLHMYAYxJmbLVJOvEh7NcUlr2NBlA4GgBjEtRVDJ4Ekq1MDWaGFx+m+FBcGgBjElcqIGkiy3mtghUaUDo4BxCCu3GyUQMKZNEQUFXsAMYkjlRElJ86dQIkoKgaAGMWRyggbSEzOpMnquAIRBcMAYKGwgeTixXOwYu2T6CmXY5tJk/VxBSJqjwEgw7yVNCBYvmg2Ljylr+PKn1sOEBUDB4EzqnHwtzJSw8p1A7G8N1foEhUDA0BGmaykuUKXqBgYADLKZCXNLQeIiiGXYwBFmL1iehsFrtAlyr/cBYAizV4xXUlzhS5RvhkLACIyDsB6AL3ueVar6hdMnQ8o5uwVVtJEFJXJMYAKgCWqOh/AAgBnishbDZ6Ps1eIiEIw1gNQVQUw5P7a7f5TU+cDOHuFiCgMo7OARKQsIpsB7AVwj6puNHk+zl4hIgrO6CCwqlYBLBCRKQBuE5ETVHWb9xgRWQ5gOQD09fV1fE7OXiEiCiaRdQCquh/AWgBn+jy3SlX7VbV/xowZsZwvbzdPJyIywVgAEJEZbssfIjIewDsAPGbqfEREFI7JFNDrAHxXRMpwAs0tqnqnwfPlUhEWtRFROkzOAtoK4CRT718ERVrURkTJ415AluKtHonINAYAS3FRGxGZxgBgKS5qIyLTGAAsxUVtRGRa7nYDzRMuaiMikxgALMfdPonIFKaAiIgKigGAiKigGACIiAqKAYCIqKAYAIiICkqcG3fZQUSeA/B0xJdPB7AvxuIkgWVORhbLDGSz3CxzMrxlfr2qRtpL36oA0AkR2aSq/WmXIwyWORlZLDOQzXKzzMmIq8xMARERFRQDABFRQeUpAKxKuwARsMzJyGKZgWyWm2VORixlzs0YABERhZOnHgAREYVgfQAQkTNF5HERGRCRK32e7xWRm93nN4rIMZ7nPuc+/riI/JlFZf6siOwQka0icq+IvN7zXFVENrv/7kiqzAHL/RERec5Tvo95nlieK/8AAAf8SURBVPuwiDzp/vuwRWX+uqe8T4jIfs9zqVxrEfmOiOwVkW1NnhcR+Rf3M20VkTd5nkvrOrcr8wfcsj4qIveLyHzPc0+5j28WkU0WlXmxiLzg+Q583vNcy+9VimW+zFPebe53+NXuc+Gvs6pa+w9AGcBvAMwG0ANgC4C5Dcf8LYBvuT+/H8DN7s9z3eN7ARzrvk/ZkjKfAeAI9+dP1svs/j5k8bX+CIAVPq99NYCd7n+nuj9PtaHMDcd/CsB3LLjWiwC8CcC2Js+fBeBnAATAWwFsTPM6ByzzqfWyAHhXvczu708BmG7hdV4M4M5Ov1dJlrnh2HcDWNPJdba9B/AWAAOqulNVhwH8EMC5DcecC+C77s+rASwVEXEf/6GqVlT1twAG3PdLvcyqulZV/+j++iCAWQmUq50g17qZPwNwj6r+QVWfB3APgDMNldMrbJn/EsBNCZSrJVVdD+APLQ45F8D31PEggCki8jqkd53blllV73fLBFjynQ5wnZvp5G+hIyHL3PH32fYAMBPAbs/vz7iP+R6jqiMAXgAwLeBrTQh73o/Cae3VjRORTSLyoIj8uYkCNhG03Oe5Xf3VInJ0yNfGLfB53TTbsQDWeB5O61q30+xzpXWdw2r8TiuAu0XkYRFZnlKZmnmbiGwRkZ+JyDz3Meuvs4gcASf43+p5OPR15g1hUiQiFwHoB/DfPQ+/XlX3iMhsAGtE5FFV/U06JTzMTwDcpKoVEfkEnJ7XkpTLFNT7AaxW1arnMZuvdSaJyBlwAsBpnodPc6/zawDcIyKPuS3dtD0C5zswJCJnAfgxgONSLlNQ7wZwn6p6ewuhr7PtPYA9AI72/D7Lfcz3GBHpAjAZwGDA15oQ6Lwi8nYAVwE4R1Ur9cdVdY/7350A1gE4yWRhPdqWW1UHPWW9AcDJQV9rSJjzvh8N3eUUr3U7zT5XWtc5EBE5Ec734lxVHaw/7rnOewHchmRSsW2p6ouqOuT+/FMA3SIyHZZfZ1er73Pw65zEwEYHAyJdcAa6jsWhwZh5DcdcjLGDwLe4P8/D2EHgnUhmEDhImU+CM8h0XMPjUwH0uj9PB/Akkht8ClLu13l+fg+AB92fXw3gt275p7o/v9qGMrvHvRHOAJnYcK3dcx6D5oOTZ2PsIPAv07zOAcvcB2ec7dSGxycAmOT5+X4AZ1pS5tfWvxNwKstd7jUP9L1Ko8zu85PhjBNM6PQ6J/KBOrwYZwF4wq0wr3If+xKcljMAjAPwI/fL90sAsz2vvcp93eMA3mVRmf8fgN8D2Oz+u8N9/FQAj7pfuEcBfNSya/2PALa75VsL4I2e1/61+/9gAMBf2VJm9/drAHy54XWpXWs4LbffATgIJ7/8UQB/A+Bv3OcFwEr3Mz0KoN+C69yuzDcAeN7znd7kPj7bvcZb3O/OVRaV+RLP9/lBeIKX3/fKhjK7x3wEzgQX7+siXWeuBCYiKijbxwCIiMgQBgAiooJiACAiKigGACKigmIAICIqKAYAso6IHCkiN4rITndZ+wMi8h73ufoOjr9yd2tcLyLLPK+9RkT2eHZLPCe9TxKOiPxURKa4//427fJQ/jEAkFXcjfx+DGC9qs5W1ZPhLPDzbi72C1U9SVXfAOBSACtEZKnn+a+r6gIA7wXwHRGJ7XvubtVs5O9GVc9S1f0ApsDZ5ZbIKAYAss0SAMOq+q36A6r6tKp+w+9gVd0MZ+HXJT7P/RrACJyVvqPcXsL/dXsWT4rIxz3PXSYiD7kb3n3RfewYt7fxPQDbMHabAIjIm9098LeIyC9FZJL7ml+IyCPuv1PdYxe7vZa73Pf8Vj2guPu5TwfwZQB/4vZirheRieLcN+IRd7/3RHampPzjZnBkm3lwNukK4xEAlzU+KCKnAKgBeM7nNSfC2WZhAoBfichdAE6AsxnYW+Csxr1DRBbB2SLgOAAfVmd7Zu85egDcDOACVX1IRF4F4GUAewG8Q1VfEZHj4Kzw7Hdf9hY496t4GsDPAfwFnK3M664EcILbi6nvcfUeVX3RDRAPisgdylWc1CEGALKaiKyEs7PksKq+udlhDb9/xt1p9SU4FbNfRXm7qr4M4GURWQunUj4NwDsB/Mo9ZiKcin8XgKcbK3/XGwD8TlUfApwNxtxyT4CTmloAoArgeM9rfqnOBnQQkZvc865GcwLgf7vBqAZna+IjAfxXi9cQtcUAQLbZDuC8+i+qerHb6m11i7uTAPza8/vXVfWrbc7TGBQUTkX7j6r6be8T4txm9ECb92v0GTj7Pc2Hk2p9pc25W/kAgBkATlbVgyLyFJw9sIg6wjEAss0aODdq+aTnsSOaHexuQXw1nM3TwjhXRMaJyDQ4twZ8CMB/APhrEZnovvdMd2/1Vh4H8DoRebP7mkmebcl/p6o1AB+Ec5vBureIyLFu7v8CABsa3vMlAJM8v08GsNet/M8A8HoQxYA9ALKKqqp7d66vi8jlcPL3BwBc4TnsdBH5FZzAsBfApap6b8hTbYWzo+l0ANeq6rMAnhWR/wbgAWcyEoYAXAQnhdOsvMMicgGAb4jIeDj5/7cD+CaAW0XkQ3Dy/N4exEMAVgCY45bhtob3HBSR+8S5MfjPAFwH4Cci8iicntBjIT8rkS/uBkqFIyLXwLkhfLs0kYlzLwbw96q6rN2xRKYxBUREVFDsARARFRR7AEREBcUAQERUUAwAREQFxQBARFRQDABERAXFAEBEVFD/HyH5SrkwdqAcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy1530ik8b1T"
      },
      "source": [
        "The relationship between GDP per capita and happiness Score seems relatively linear. Let's build a linear model to predict happiness score using the GDP per capita feature. Before we do, we need to prepare the training and test dataset our model will use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEf5NMjYkGCB"
      },
      "source": [
        "## Prepare the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_zSR0HP9CHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7918edd8-e13b-4cfa-814a-28ef1852b54f"
      },
      "source": [
        "# define the x and y variables \n",
        "x_col = 'GDP per capita'\n",
        "y_col = 'Score'\n",
        "\n",
        "# split the dataset into a training set and a test set.\n",
        "# we will use the test set in the final evaluation of our model.\n",
        "train = happy2019.sample(frac=0.8, random_state=0)\n",
        "test = happy2019.drop(train.index)\n",
        "\n",
        "# Splitting training data into validation data\n",
        "valid = train.sample(frac=0.1, random_state=0)\n",
        "train = train.drop(valid.index) # Deleting rows sampled for validation data\n",
        "\n",
        "# separate the x (features) and y (labels) in the train/valid/test datasets\n",
        "train_features = torch.tensor(train[x_col].values.reshape(-1, 1)).float()\n",
        "test_features = torch.tensor(test[x_col].values.reshape(-1, 1)).float()\n",
        "valid_features = torch.tensor(valid[x_col].values.reshape(-1, 1)).float()\n",
        "\n",
        "train_labels = torch.tensor(train[y_col].values.reshape(-1, 1)).float()\n",
        "test_labels = torch.tensor(test[y_col].values.reshape(-1, 1)).float()\n",
        "valid_labels = torch.tensor(valid[y_col].values.reshape(-1, 1)).float()\n",
        "\n",
        "print('train features shape:', train_features.shape)\n",
        "print('train labels shape:', train_labels.shape)\n",
        "\n",
        "print('validation features shape:', valid_features.shape)\n",
        "print('validation labels shape:', valid_labels.shape)\n",
        "\n",
        "print('test features shape:', test_features.shape)\n",
        "print('test labels shape:', test_labels.shape)\n",
        "\n",
        "print('first 5 test labels:\\n', test_labels[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train features shape: torch.Size([113, 1])\n",
            "train labels shape: torch.Size([113, 1])\n",
            "validation features shape: torch.Size([12, 1])\n",
            "validation labels shape: torch.Size([12, 1])\n",
            "test features shape: torch.Size([31, 1])\n",
            "test labels shape: torch.Size([31, 1])\n",
            "first 5 test labels:\n",
            " tensor([[7.2460],\n",
            "        [6.7260],\n",
            "        [6.4440],\n",
            "        [6.3540],\n",
            "        [6.3000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fnwk72hSBj"
      },
      "source": [
        "The above code returns a training and test dataset. The GDP per capita variable represents the  *features* data and the happiness Score represents the *labels*. There aretwo datasets--a *training dataset* and a *test dataset*. The `train_features` and `train_labels` arrays represent the features and labels of the training dataset, each containing 125 rows and 1 column. The `test_features` and `test_labels` arrays represent the features and labels of the test dataset, each containing 31 rows and 1 column.  \n",
        "\n",
        "Now that we have the *features* and *labels* separated, we are ready to build our model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qod9zI2I4iw"
      },
      "source": [
        "## 2. Building a model\n",
        "\n",
        "Before we model the relationship between happiness Score and GDP per capita, let's write what we know about single-variable linear regression. In short, single-variable linear regression tries to find a function that best fits our data (i.e., between an $x$ and $y$ variable). It is defined by the following formula: \n",
        "$$\n",
        "y = wx + b\n",
        "$$\n",
        "\n",
        "We can translate this function to our problem to model the relationship between GDP per capita ($x$) and happiness Score ($y$) as follows:\n",
        "\n",
        "$$ \n",
        "\\text{score} = w_{\\text{GDP per capita}} \\cdot \\text{GDP per capita} + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlaNcYLMJz9n"
      },
      "source": [
        "Coding linear regression from scratch can be tedious: we'd need to manually define the parameters (weights and bias), compute gradients, and update the parameters. Fortunately, there are amazing open source libraries we can use to make this process a bit easier.\n",
        "\n",
        "We'll be using [PyTorch](https://pytorch.org/), a Deep Learning library to build and evaluate our linear regression model in the form of neural network. We will create our own `LR_Model` class to define a container for the *layers* of our model. There are two sections to the class, the constructor and the forward method. The constructor is used define the layers, we use using `nn.Linear` class to define those layers. The `forward` method is used to take your input and then you pass that input through your layers to return an output. We don't really need to use this model structure for linear regression (as you saw last lesson). Nonetheless, nearly every model we build in this series will be similar to this lesson so we will use it from here on out.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNFNhNUAtBhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d7114f-60af-4d30-c840-898195002d6d"
      },
      "source": [
        "# build the linear model \n",
        "class LR_Model(nn.Module):\n",
        "    # Defining Constructor\n",
        "    def __init__(self):\n",
        "        super(LR_Model, self).__init__()\n",
        "\n",
        "        # Defining Layers\n",
        "        self.fc1 = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc1(x)\n",
        "\n",
        "# Initializing model\n",
        "model = LR_Model()\n",
        "\n",
        "print('Model Summary')\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Summary\n",
            "LR_Model(\n",
            "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4JD6_eLv3IX"
      },
      "source": [
        "<!-- TODO: fix figure to one node -->\n",
        "<figure>\n",
        "<img src='https://d2l.ai/_images/singleneuron.svg' width='50%'></img><figcaption>Linear Regression: a single-layer neural network</figcaption>\n",
        "</figure>\n",
        "\n",
        "The model we defined above is a linear model, we could also call it a single-layer *fully-connected* neural network. We defined it using the [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) class. Note that we passed two arguments into the `torch.nn.Linear` class. The first one specifies the input feature dimension, which is 1 (GDP per capita), and the second one is the output feature dimension, which is a single scalar and therefore 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLfbaRI5Dbk"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "After defining the model, we need to configure the *loss function*. We will use the mean squared loss, which returns the averaged loss over samples. Here we use PyTorch built-in Mean Squared Error loss function defined as the class [torch.nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyPXRk6j1ErK"
      },
      "source": [
        "loss_fn = nn.MSELoss()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrT8n3sg2jMf"
      },
      "source": [
        "### Optimization Algorithm\n",
        "Now that we have a loss function, we need to define an *opimization algorithm*. Specifically, we will use *stochastic gradient descent* to optimize our model. In other words, we use *stochastic gradient descent* to update the model parameters. We also define the *learning rate* as 0.01. We use [`torch.optim.SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) class to be used as the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k1zwXU53RX9"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9EvNw5L5m66"
      },
      "source": [
        "## 4. Train the model\n",
        "Now that we have a model, it's time to train it. We will train the model for 100 *epochs* (i.e., iterations), and record the training losses for every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL64Vo7K6eNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc8edfd-38f4-427d-c83d-0476d15f7ead"
      },
      "source": [
        "epochs = 100\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # Setting model to train mode\n",
        "    model.train()\n",
        "    for train_sample, train_label in zip(train_features, train_labels):\n",
        "        # Setting all gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate Output\n",
        "        output = model(train_sample)\n",
        "        \n",
        "        # Calculate Loss\n",
        "        loss = loss_fn(output, train_label)\n",
        "\n",
        "        # Calculate Gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform Gradient Descent Step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Saving Loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Setting model to evaluation mode, no parameters will change\n",
        "    model.eval()\n",
        "    for valid_sample, valid_label in zip(valid_features, valid_labels):\n",
        "\n",
        "        # Calculate Output\n",
        "        output = model(valid_sample)\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = loss_fn(output, valid_label)\n",
        "\n",
        "        # Saving Loss\n",
        "        valid_loss += loss.item()\n",
        "\n",
        "    # Averaging losses and saving it\n",
        "    train_loss /= len(train_features)\n",
        "    valid_loss /= len(valid_features)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 5.416364 \tValidation Loss: 0.861685\n",
            "Epoch: 2 \tTraining Loss: 0.559854 \tValidation Loss: 0.774692\n",
            "Epoch: 3 \tTraining Loss: 0.533726 \tValidation Loss: 0.721894\n",
            "Epoch: 4 \tTraining Loss: 0.517354 \tValidation Loss: 0.682115\n",
            "Epoch: 5 \tTraining Loss: 0.506323 \tValidation Loss: 0.651801\n",
            "Epoch: 6 \tTraining Loss: 0.498887 \tValidation Loss: 0.628494\n",
            "Epoch: 7 \tTraining Loss: 0.493876 \tValidation Loss: 0.610425\n",
            "Epoch: 8 \tTraining Loss: 0.490500 \tValidation Loss: 0.596307\n",
            "Epoch: 9 \tTraining Loss: 0.488226 \tValidation Loss: 0.585200\n",
            "Epoch: 10 \tTraining Loss: 0.486695 \tValidation Loss: 0.576407\n",
            "Epoch: 11 \tTraining Loss: 0.485665 \tValidation Loss: 0.569406\n",
            "Epoch: 12 \tTraining Loss: 0.484973 \tValidation Loss: 0.563806\n",
            "Epoch: 13 \tTraining Loss: 0.484508 \tValidation Loss: 0.559307\n",
            "Epoch: 14 \tTraining Loss: 0.484196 \tValidation Loss: 0.555680\n",
            "Epoch: 15 \tTraining Loss: 0.483986 \tValidation Loss: 0.552746\n",
            "Epoch: 16 \tTraining Loss: 0.483847 \tValidation Loss: 0.550368\n",
            "Epoch: 17 \tTraining Loss: 0.483753 \tValidation Loss: 0.548435\n",
            "Epoch: 18 \tTraining Loss: 0.483691 \tValidation Loss: 0.546861\n",
            "Epoch: 19 \tTraining Loss: 0.483649 \tValidation Loss: 0.545578\n",
            "Epoch: 20 \tTraining Loss: 0.483622 \tValidation Loss: 0.544531\n",
            "Epoch: 21 \tTraining Loss: 0.483604 \tValidation Loss: 0.543674\n",
            "Epoch: 22 \tTraining Loss: 0.483592 \tValidation Loss: 0.542973\n",
            "Epoch: 23 \tTraining Loss: 0.483585 \tValidation Loss: 0.542400\n",
            "Epoch: 24 \tTraining Loss: 0.483580 \tValidation Loss: 0.541930\n",
            "Epoch: 25 \tTraining Loss: 0.483577 \tValidation Loss: 0.541545\n",
            "Epoch: 26 \tTraining Loss: 0.483575 \tValidation Loss: 0.541229\n",
            "Epoch: 27 \tTraining Loss: 0.483574 \tValidation Loss: 0.540971\n",
            "Epoch: 28 \tTraining Loss: 0.483573 \tValidation Loss: 0.540758\n",
            "Epoch: 29 \tTraining Loss: 0.483572 \tValidation Loss: 0.540584\n",
            "Epoch: 30 \tTraining Loss: 0.483572 \tValidation Loss: 0.540441\n",
            "Epoch: 31 \tTraining Loss: 0.483572 \tValidation Loss: 0.540323\n",
            "Epoch: 32 \tTraining Loss: 0.483572 \tValidation Loss: 0.540227\n",
            "Epoch: 33 \tTraining Loss: 0.483572 \tValidation Loss: 0.540148\n",
            "Epoch: 34 \tTraining Loss: 0.483572 \tValidation Loss: 0.540083\n",
            "Epoch: 35 \tTraining Loss: 0.483572 \tValidation Loss: 0.540029\n",
            "Epoch: 36 \tTraining Loss: 0.483572 \tValidation Loss: 0.539986\n",
            "Epoch: 37 \tTraining Loss: 0.483573 \tValidation Loss: 0.539950\n",
            "Epoch: 38 \tTraining Loss: 0.483573 \tValidation Loss: 0.539920\n",
            "Epoch: 39 \tTraining Loss: 0.483573 \tValidation Loss: 0.539895\n",
            "Epoch: 40 \tTraining Loss: 0.483573 \tValidation Loss: 0.539876\n",
            "Epoch: 41 \tTraining Loss: 0.483573 \tValidation Loss: 0.539859\n",
            "Epoch: 42 \tTraining Loss: 0.483573 \tValidation Loss: 0.539846\n",
            "Epoch: 43 \tTraining Loss: 0.483573 \tValidation Loss: 0.539835\n",
            "Epoch: 44 \tTraining Loss: 0.483573 \tValidation Loss: 0.539825\n",
            "Epoch: 45 \tTraining Loss: 0.483573 \tValidation Loss: 0.539818\n",
            "Epoch: 46 \tTraining Loss: 0.483573 \tValidation Loss: 0.539812\n",
            "Epoch: 47 \tTraining Loss: 0.483573 \tValidation Loss: 0.539807\n",
            "Epoch: 48 \tTraining Loss: 0.483573 \tValidation Loss: 0.539803\n",
            "Epoch: 49 \tTraining Loss: 0.483573 \tValidation Loss: 0.539799\n",
            "Epoch: 50 \tTraining Loss: 0.483573 \tValidation Loss: 0.539796\n",
            "Epoch: 51 \tTraining Loss: 0.483573 \tValidation Loss: 0.539794\n",
            "Epoch: 52 \tTraining Loss: 0.483573 \tValidation Loss: 0.539792\n",
            "Epoch: 53 \tTraining Loss: 0.483573 \tValidation Loss: 0.539790\n",
            "Epoch: 54 \tTraining Loss: 0.483573 \tValidation Loss: 0.539789\n",
            "Epoch: 55 \tTraining Loss: 0.483573 \tValidation Loss: 0.539788\n",
            "Epoch: 56 \tTraining Loss: 0.483573 \tValidation Loss: 0.539788\n",
            "Epoch: 57 \tTraining Loss: 0.483573 \tValidation Loss: 0.539787\n",
            "Epoch: 58 \tTraining Loss: 0.483573 \tValidation Loss: 0.539787\n",
            "Epoch: 59 \tTraining Loss: 0.483573 \tValidation Loss: 0.539786\n",
            "Epoch: 60 \tTraining Loss: 0.483573 \tValidation Loss: 0.539786\n",
            "Epoch: 61 \tTraining Loss: 0.483573 \tValidation Loss: 0.539785\n",
            "Epoch: 62 \tTraining Loss: 0.483573 \tValidation Loss: 0.539785\n",
            "Epoch: 63 \tTraining Loss: 0.483573 \tValidation Loss: 0.539785\n",
            "Epoch: 64 \tTraining Loss: 0.483573 \tValidation Loss: 0.539785\n",
            "Epoch: 65 \tTraining Loss: 0.483573 \tValidation Loss: 0.539785\n",
            "Epoch: 66 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 67 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 68 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 69 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 70 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 71 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 72 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 73 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 74 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 75 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 76 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 77 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 78 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 79 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 80 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 81 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 82 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 83 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 84 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 85 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 86 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 87 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 88 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 89 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 90 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 91 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 92 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 93 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 94 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 95 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 96 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 97 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 98 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 99 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n",
            "Epoch: 100 \tTraining Loss: 0.483573 \tValidation Loss: 0.539784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xv6IaPv8FcV"
      },
      "source": [
        "We get to ~0.539784 validation mean squared error after training for 100 epochs on the training dataset. Let's check the model's training progress by looking at a plot of the validation loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSZuns88fhs"
      },
      "source": [
        "Let's visualize it too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuNpvE5C8eOr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a6f9f81f-34d5-4b97-c2ea-6f26e1478ff4"
      },
      "source": [
        "#hist.plot.line(x='epoch', y='val_mean_squared_error');\n",
        "plt.plot(valid_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqDbYQc-b1m"
      },
      "source": [
        "From the plot we can see that our model *converged* just before the 30th epoch. In other words, the most optimal parameters (weights and bias)were found ofter 30 training iterations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de62RpCv_ion"
      },
      "source": [
        "## 5. Evaluate the model\n",
        "Now that we trained our model, it's time to evaluate it by using the *test* dataset, which we did not use when training the model. This gives us a sense of how well our model predicts unseen data, which is the case when we use it in the real world. We will use the `evaluate` method to test the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn9i35lI_h6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb1a18a-62d0-4818-827d-39914e42da55"
      },
      "source": [
        "# Setting model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Getting Predictions\n",
        "predictions = model(test_features)\n",
        "\n",
        "# Calculating loss, which is the Mean Squared Error\n",
        "loss = loss_fn(predictions, test_labels)\n",
        "\n",
        "print('Test set Mean Absolute Error: ', round(loss.item(), 4))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set Mean Absolute Error:  0.3836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKdfF6PeLq1-",
        "outputId": "8abf3eb1-7233-4f59-e2f3-82b0d355e50a"
      },
      "source": [
        "predictions.flatten()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.5079, 6.3342, 6.0119, 6.3022, 5.6577, 5.9319, 6.4759, 6.1193, 6.0188,\n",
              "        4.8303, 6.0668, 4.9286, 5.7651, 6.0028, 5.5228, 6.1536, 6.0622, 5.5297,\n",
              "        5.6531, 5.1937, 4.3824, 5.7788, 5.3057, 4.2316, 4.2430, 4.9858, 5.4497,\n",
              "        3.5299, 4.1013, 4.7778, 4.1836], grad_fn=<ViewBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oex24IXB8Ku"
      },
      "source": [
        "The mean squared error is 0.3836 for happiness Score. Is this good? We'll leave that decision up to you. Let's also visualize the prediction and real happiness Score values using data in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfYGBlJOCgkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9dc01e0f-8fee-4010-b99c-126e84e6b522"
      },
      "source": [
        "# Flattening test predictions\n",
        "predictions = predictions.flatten().detach().numpy()\n",
        "\n",
        "ax = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, predictions)\n",
        "plt.xlabel('True Values [Happiness Score]')\n",
        "plt.ylabel('Predictions [Happiness Score]')\n",
        "lims = [0, max(test_labels) + 1] # [0, 31]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5c_PyRzDdL9"
      },
      "source": [
        "It looks like our model predicts reasonably well. Let's take a look at the error distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XijR03DrET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "544c1d34-a6dd-44a6-a798-4586b1b04a7d"
      },
      "source": [
        "error = predictions - test_labels.flatten().detach().numpy()\n",
        "plt.hist(error, bins = 10)\n",
        "plt.xlabel(\"Prediction Error [Happiness Score]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij1MDhAbEpZ6"
      },
      "source": [
        "The histogram shows that the errors aren't quite *Normally distributed* (also called *gaussian*), but we might expect that because the number of samples is very small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd6RuVz5FDZM"
      },
      "source": [
        "## 6. Draw Conclusions\n",
        "We built a single-layer fully-connected neural network model to predict happiness Score given a country's GDP per capita. The model converged after about 30 epochs of training, and it achieved a mean squared error of 0.384. We expect that a *deeper* model or more data samples or features could lead to better results on unseen data.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTQXVOX3GITZ"
      },
      "source": [
        "# Summary\n",
        "In this lesson we took a deeper dive into regression, translating traditional linear  regression into a single-layer fully-connected neural network. We covered several important techniques to handle regression problems:\n",
        "- Introduced *loss functions* and *optimization algorithms*.\n",
        "- Demonstrated preparing data for a model.\n",
        "- Used PyTorch to build and train a model. \n",
        "- Showed how to evaluate a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOUYOD8VExr"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}