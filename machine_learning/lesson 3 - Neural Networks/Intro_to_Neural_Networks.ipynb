{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Neural_Networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-bugs-fixes/machine_learning/lesson%203%20-%20Neural%20Networks/Intro_to_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_FtPZToNWxR"
      },
      "source": [
        "> Note: Always open in Colab for the best learning experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0mauKRSBpNE"
      },
      "source": [
        "# Intro to Neural Networks\n",
        "<figure><img src='https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/images/cat-dog-ml-gif.gif?raw=true' width='70%'></img><figcaption>A Feed Forward Neural Network</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "In the previous lesson, we introduced the softmax regression method to solve multi-class classification tasks, implementing a classifer to recognize 10 handwritten digits from the MNIST digits dataset. \n",
        "\n",
        "We've come a long way and covered many concepts throughout this series, with each lesson building on the previous material. We've learned how to clean data, create linear models (via linear regression), coerce model outputs into a valid probability distribution (via logistic and softmax regression), train models using Sklearn and PyTorch, apply the appropriate loss function, and to minimize it with respect to our model's parameters (via optimization algorithms). Now that we have a healthy understanding of these concepts in the context of simple linear models, we are ready to explore neural networks--one of the most exciting and successful methods in modern machine learning! \n",
        "\n",
        "In this lesson, we describe deep linear neural networks at a high level, focusing on their structure, and demonstrate how to build one using PyTorch. \n",
        "\n",
        "To make this lesson more approachable, we don't cover every detail about neural networks here, but we aim to provide enough information for you to create your own  neural networks and to inspire you to explore deep learning in more detail.  \n",
        " \n",
        "Lesson roadmap: \n",
        "- High level introduction to *neural networks*.\n",
        "- Building neural networks in Python - recreating the feed forward neural network model in 3Blue1Brown's excellent video [But what is a Neural Network? | Deep learning, chapter 1](https://www.youtube.com/watch?v=aircAruvnKk&t=436s) and training it to classify handwritten digits. As you will see, this simple feed forward neural network achieves impressive results. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vNvRWXQPJ-"
      },
      "source": [
        "## Neural Networks\n",
        "Although neural networks only recently became popular, they've been around for quite some time. In fact, they first appeared in machine learning research way back in the late 1950s! But they didn't become popular until after 2012, when researchers built a neural network to classify different kinds of labeled images, achieving groundbreaking results (see [ImageNet Classification with Deep Convolutional\n",
        "Neural Networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)). Since then, neural networks have become widely used in machine learning. Neural networks are successful, in part, because they can effectively learn representations of complex data (e.g., images, text, sound, tabular, etc.), especially given enough data and computing power.    \n",
        "\n",
        "At a high level, there are three fundemental types of neural networks: 1) encoders, 2) decoders, or 3) a combination of both. We will focus on *encoders*. \n",
        "\n",
        "Encoder networks take in some input data (i.e., images, texts, sounds, etc.) and output *predictions*, just like the linear models we've been working with. The simplest type of neural networks are called feed forward neural networks (FFNNs), and they consist of many *layers* of *neurons* each *fully-connected* to those in the layer below (from which they receive input) and those above (which they, in turn, influence). \n",
        "\n",
        "FFNNs may sound complex right now, but hang in there. In many ways FFNNs are the superpowered version of the linear models we already know about. Like the linear models we've discussed (linear/logistic/softmax regression), neural networks can be configured to solve different kinds of tasks: either *regression* or *classification*. \n",
        "\n",
        "\n",
        "Here are some quick facts about neural networks:\n",
        "- They are effective models for learning to represent complex data (like images, text, sound, tabular, etc.).\n",
        "- Encoder-based networks, which take input data and output predictions, are probably the most common neural networks - they are useful for classification and regression tasks\n",
        "- Feed forward neural networks (FFNNs) are the simplest type of neural network. They consist of many *layers* of *neurons* each *fully-connected* to those in the layer below (from which they receive input) and those above (which they, in turn, influence). \n",
        "- FFNNs are like linear models on steriods. They have many more parameters than simple linear models, which enables them to learn more complex relationships from the input data. \n",
        "- Even though FFNNs are the simplest kind of neural network, they can be very effective. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig4f4QOYdvNM"
      },
      "source": [
        "**Challenge:** What are two tasks that you think encoder networks might be at good at solving?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3jWYZoLbjV"
      },
      "source": [
        "### Feed Forward Neural Networks\n",
        "<figure><img src='https://thumbs.gfycat.com/WeepyConcreteGemsbok-size_restricted.gif' width='100%'></img><figcaption>A Feed Forward Neural Network | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "Did you watch the [3Blue1Brown video on neural networks](https://www.youtube.com/watch?v=aircAruvnKk&t=436s)? If you haven't yet, I highly recommend checking it out (feel free to rewatch it too, it's a great overview of neural networks). I'll frequently be referencing important concepts that the video talks about. \n",
        "\n",
        "In the following sections, we will summarize the key concepts behind neural networks. First, we describe the motivation and inspiration behind neural networks. Then, we dive into the structure of neural networks, outlining a few critical pieces that make them work. \n",
        "\n",
        "*Note, we describe these concepts from the perspective of a feed forward neural network. That said, the fundemental ideas discussed generalize to almost every type of neural network.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMetO8ANP0Ft"
      },
      "source": [
        "#### Neural Networks: Neural Network $=$ Brain?\n",
        "<figure><img src='https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/images/combined-pizza-brain-neural-network-analogy.png?raw=true' width='75%'></img><figcaption>\"Pizza, eat I must.\" - Yoda</figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "No, neural networks $\\neq$ brains.\n",
        "While neural networks don't actually operate like brains, they were inspired by them. \n",
        "\n",
        "Let's consider an extremely oversimplified version of the brain. The brain is an organ that uses neurons to process information and make decisions. The neurons are what the brain uses to process data (i.e., information about the world). When some piece of data is sent to a neuron it activates (or dpesn't). The magnitude/strength (i.e., positive or negative) of the activation triggers other groups of neurons to activate (or not). Eventually, this process outputs a decision--based on a combination of the prior triggers and activations--as a response to the input data. As an example, let's say there is a pizza in the kitchen and my nose picks up the scent. The smell of freshly baked dough and melted cheese activates my \"I'm hungry neurons\". Eventually, I can't ignore these neurons any longer, so I run to the kitchen and eat some pizza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjoDiltUbVTg"
      },
      "source": [
        "#### Neural Networks: Neurons\n",
        "<figure><img src='https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/images/neuron-3blue1brown.png?raw=true' width='75%'></img><figcaption>Neural Networks: Neuron | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "**Neurons** are at the core of neural networks (after all, they are practically in the name). At a high level, a neuron holds a corresponding value (i.e., number) called an **activation**. The activation can be represented by a tiny value, a large value, or a value somewhere in between. A neuron is \"lit up\" (i.e., activated) when its corresponding activation is large, and it is \"dim\" (i.e., not very activated) when its activation is small. Connecting this to the pizza example, my \"I'm hungry neurons\" lit up after I smelled the pizza in the kitchen.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCxJiSdYOGjl"
      },
      "source": [
        "#### Neural Networks: Layers\n",
        "<figure><img src='https://miro.medium.com/max/1280/1*_nTmA2RowzQBCqI9BVtmEQ.gif' width='75%'></img><figcaption>The Neural Network's Secret Sauce: Stacking Layers | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "The secret sauce driving neural networks is the technique of *stacking layers*. At a high level, this method enables the neural network to learn an effective representation of the data. The layers that are in between the input layer and the output layer are called *hidden layers*.\n",
        "\n",
        "A **layer** is composed of a set of **neurons**. We can manually configure the number of neurons we want to have in each layer, except for in the first and last ones. When we add more neurons and layers to the model, we add more parameters (weights and biases) to it. As a result, larger models (models with many parameters) can be computationally expensive, but very effective. This creates a trade-off between computation effeciency and model representation ability (making smaller models as effective as bigger ones is an active area of research). \n",
        "\n",
        "For classification tasks, the number of neurons in the last layer is determined by the number of categories/classes in the dataset. While in regression tasks, there is generally only one neurons in the final layer, since we are predicting a continuous value (e.g., the happiness score for a particular country). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlPlPHMIiQMb"
      },
      "source": [
        "**Challenge:** In the above figure (from previous cell), how many layers are in the neural network? How many are hidden layers? How many neurons are in the first layer? How many are in the last layer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTaJK53oefzY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoGtSuj-h7D9"
      },
      "source": [
        "#### Neural Networks: Weights & Activation Functions \n",
        "<figure><img src='https://thumbs.gfycat.com/BabyishGeneralFruitfly-size_restricted.gif' width='65%'></img><figcaption>Calculating a Neuron's Activation: Connections and Weights (1) | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "<figure><img src='https://thumbs.gfycat.com/GlitteringCavernousGoosefish-small.gif' width='65%'></img><figcaption>Calculating a Neuron's Activation: Connections and Weights (2)| <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "Neural networks pass information through the network using connections between pairs of neurons in adjacent layers. Each connection has a corresponding **weight** parameter that is learned during the model training phase. As shown in the figure above, the activation of a neuron in a subsequent layer is determined by the *weighted sum* of the weights and activations of the neurons in the previous layer (i.e., connections). A **bias** term is added at the end of the weighted sum to control how large/small a neuron's weighted sum must be to activate. Before the neuron receives a final activation value, the weighted sum is *squeezed* by an **activation function**. \n",
        "\n",
        "Activation functions and parameters (weights and biases)may sound intimidating. Fortunately, you already know a lot about these concepts: 1) the *sigmoid* and *softmax* logit functions are examples of activation functions, 2) linear models (linear/logistic/softmax) use the same *weighted sum* method to activate neurons in subsequent layers, the difference is these networks only have one layer after the input. \n",
        "\n",
        "As you may remember from the logistic and softmax lessons, these logit functions convert the inputs to a valid probability space. An activation function, more generally, can be defined as any function that transforms the neuron output. It is common to choose an activation function that normalizes the input between 0 and 1 or -1 and 1. \n",
        "\n",
        "\n",
        "Activation functions play a critical role in building effective deep neural networks. They can help the network converge quickly (find the right parameters) and improve the model's overall performance. \n",
        "\n",
        "In the diagrams above, the second layer has one neuron. This neuron is connected to every other neuron in the previous layer. Consequently, it has 784 connections plus one bias term. That's a lot of number crunching! For this reason, we generally select activation functions that can be computed effeciently (quickly). \n",
        "\n",
        "<figure><img src='https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/images/sigmoid-activation-3Blue1Brown.png?raw=true' width='65%'></img><figcaption>Calculating a Neuron's Activation: Sigmoid Activation Function (2)| <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "So far we've only discussed connections and activations in the context of one neuron in a subsequent layer. But, most layers have many neurons. The good news is, we calculate neuron activations in the same way as before. The bad news is, we have to repeat the calculation process many times over. For example, in the diagrams below we see that all 16 neurons in the 2nd layer are connected to every other neuron in the 1st layer (i.e., 784 neurons). Thus, we need to  perform $784\\times16$ weights $ + 16$ biases calculations to get the activations for the 16 neurons in the 2nd layer. Doing this by hand would be way too difficult, but luckily, we can make computers do most of the heavy lifting. \n",
        "\n",
        "<figure><img src='https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/main/images/2-layer-weights-biases-connections-3Blue1Brown.png?raw=true' width='65%'></img><figcaption>Calculating a Neuron's Activation: Sigmoid Activation Function (2) | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRgYYTTyiI1_"
      },
      "source": [
        "**Challenge:** In the below neural network diagram, how many weights and biases are there between the 2nd layer and the 3rd layer? How many total weights and biases are there in the entire network? Hint: all neurons are connected to every other neuron in the previous layer. \n",
        "\n",
        "<figure><img src='https://thumbs.gfycat.com/DeadlyDeafeningAtlanticblackgoby-poster.jpg' width='65%'></img><figcaption>A Neural Network: Total Weights & Biases | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt1EV_1rXaj8"
      },
      "source": [
        "## Building a Neural Network: Summary\n",
        "Now that we know a little about neural networks, it's time to make our own! In this section, we demonstrate how to build a neural network in Python using PyTorch. Specifically, we implement the neural network from 3Blue1Brown's video [But what is a Neural Network? Deep Learning Part 1](https://www.youtube.com/watch?v=aircAruvnKk&t=436s) to classify 10 types of handwritten digits from the MNIST dataset. Before we start, let's summarize what we know so far about neural networks:\n",
        "- *Stacking layers* is their secret sauce - enabling the model to learn an effective representations of the data (most of the time).\n",
        "- Layers are comprised of *neurons*. We configure the number of neurons in *hidden layers*. \n",
        "- Neurons hold a corresponding *activation* - large activations \"light up\" neurons.   \n",
        "- The activations of neurons are determined by the weighted sum of their *connections* with the previous layer's neurons - quantified by *weights* and a *bias* term. The resulting output is then squeezed by an *activation function* such as the *sigmoid* function.\n",
        "- For classification tasks, the number of neurons in the last layer corresponds to the number of classes/categories in the dataset.    \n",
        "\n",
        "Now, it's time to make our first neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJK_aPDqWWV4"
      },
      "source": [
        "### Classification of Handwritten Digits with a Feed Forward Neural Network\n",
        "<figure><img src='https://thumbs.gfycat.com/ViciousUnnaturalAmethystsunbird-max-1mb.gif' width='75%'></img><figcaption>A Neural Network: Total Weights & Biases | <em>Source: <a href='https://www.youtube.com/watch?v=aircAruvnKk&t=436s'>3Blue1Brown - But what is a Neural Network? Deep Learning Part 1</a></em></figcaption>\n",
        "</figure>\n",
        "\n",
        "In this section, we will recreate the feed forward neural network (FFNN) from 3Blue1Brown's video [But what is a Neural Network? Deep Learning Part 1](https://www.youtube.com/watch?v=aircAruvnKk&t=436s) and use it to classify handwritten digits from the MNIST dataset. This process involves several steps: 1) [loading the dataset](#-Step-1:-Loading-the-Dataset), 2) [building the model](#-Step-2:-Building-the-Model), 3) [training the model](#-Step-3:-Training-the-Model), 4) [testing the model](#-Step-4:-Testing-the-Model).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHnGsX_4X_HN"
      },
      "source": [
        "### Prerequisites: Google Colab + building neural networks in python \n",
        "We recommend that you run this this notebook in the cloud on Google Colab, if you're not already doing so. It's the simplest way to get started. Google Colab gives you free access to specialized compute resources called [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) and [TPUs](https://en.wikipedia.org/wiki/Tensor_processing_unit). In modern machine learning these resources are frequently used because they significantly speed up model training compared to using [CPUs](https://en.wikipedia.org/wiki/Central_processing_unit) (your computer is probably using CPUs). At a high level, GPUs and TPUs are special types of computer chips that excel at performing computations on large matrices. They perform mathematical matrix operations like multiplication, addition, subtraction, etc. at a much higher rate (i.e., speed) than CPUs.    \n",
        "\n",
        "Native Python code won't run on GPUs and TPUs because they use specialized operating system *kernels*. We could convert our code to a language that these kernals can understand, but that would be a very tedious and frustrating process. Fortunately, there are several open-source Python libraries exist that do the heavy lifting for us. In particular, the two most popular open-source libraries are [PyTorch](https://pytorch.org/) and [Tensorflow](https://www.tensorflow.org/). These libraries enable us to build custom neural networks in Python that can run on GPUs and TPUs! \n",
        "\n",
        "In this lesson we will use PyTorch because it is a bit easier to use (while you are learning about neural networks) and it comes preinstalled in Google Colab. It is also possible to [install PyTorch locally](https://pytorch.org/get-started/locally/). But, the simple solution is normally best (i.e., use Google Colab).\n",
        "\n",
        "Lastly, to accelerate model training time, you may want to run this notebook on a GPU in Google Colab. To do this, click on the \"Runtime\" tab in the top left corner of the notebook, click \"Change runtime type\", and select the \"GPU\" option under \"Hardware accelerator\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ZEitUdbQJo"
      },
      "source": [
        "# Importing PyTorch and torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu7E8vdNnetM"
      },
      "source": [
        "## 1. Finding and preparing the dataset\n",
        "For step 1, we found the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The dataset contains 70k standardized grayscale images of handwritten digits at a resolution of $28 \\times 28$ pixels. Our goal is to build a classification model to take one of these images as input and predict the most likely digit contained in the image (along with a relative confidence about the prediction):\n",
        "\n",
        "<figure><img src=\"https://i.imgur.com/ITrm9x4.png\" width=\"65%\"><figcaption><em>Source: <a href=\"https://deeplearning.mit.edu/\">MIT Deep Learning</a></em></figcaption></figure>\n",
        "\n",
        "\n",
        "Loading the dataset will return two PyTorch Datasets:\n",
        "* The `training_data` dataset contains both matching training images and their labels-—the data the model uses to learn.\n",
        "* The `test_data` dataset contains both matching test images and their labels--the data the model is tested on.\n",
        "\n",
        "The images are $1\\times28\\times28$ PyTorch tensors (i.e., the x variables), with pixel values ranging between 0 and 1(usually 0-255 but the pixels were already standardized). The *labels* (i.e., $y$) are an array of integers, ranging from 0 to 9. Usually we have to use *one-hot encoding* (the technique we learned about in the logistic regression lesson) to convert these labels to vectors (i.e., arrays with mostly 0s and a 1 at the index that corresponds to the data sample's digit category), however PyTorch does this for us with the loss function. The images are *standardized* already by PyTorch. This is achieved by dividing the pixels of each image by 255 (i.e., the max pixel value). Standardizing the data encourages our model to learn more generalizable features and helps it perform better on outside data. The final data processing step is \"flattening\" the $28\\times28$ image pixel matrices into 784 image pixel arrays, and this is done when the image is passed in the model. We reshape the image matrices into arrays because our model expects the input to be a vector/array with 784 features (i.e., values). \n",
        "\n",
        "Now, let's load the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoRQV2SJOUux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a18eb81-198e-4495-dcaa-c0f465524f16"
      },
      "source": [
        "# Downloading the data\n",
        "root = '/content/MNIST'\n",
        "training_data = torchvision.datasets.MNIST(root, \n",
        "                                           train=True, \n",
        "                                           download=True,\n",
        "                                           transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.MNIST(root, \n",
        "                                           train=False, \n",
        "                                           download=True,\n",
        "                                           transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "# Loading Data\n",
        "training_dataloader = torch.utils.data.DataLoader(training_data,\n",
        "                                                  batch_size=128,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                                  batch_size=128,\n",
        "                                                  shuffle=False)\n",
        "\n",
        "print('Length of training dataset: {}'.format(len(training_data)))\n",
        "print('Length of test dataset: {}'.format(len(test_data)))\n",
        "images, labels = next(iter(training_dataloader))\n",
        "\n",
        "print('\\nTraining batch feature dimension: {}'.format(images.shape))\n",
        "print('Testing batch feature dimension: {}'.format(labels.shape))\n",
        "print('\\nFirst 5 labels:', labels[:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training dataset: 60000\n",
            "Length of test dataset: 10000\n",
            "\n",
            "Training batch feature dimension: torch.Size([128, 1, 28, 28])\n",
            "Testing batch feature dimension: torch.Size([128])\n",
            "\n",
            "First 5 labels: tensor([2, 8, 8, 2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnGClpLKpbsP"
      },
      "source": [
        "Let's display the first 5 images from the *training set* and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe6oeXCBpY9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "48bdb803-9b49-40e3-e870-772761044f43"
      },
      "source": [
        "plt.figure(figsize=(10,2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(training_data[i][0].numpy().reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(training_data[i][1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H65HEL3dnKJ"
      },
      "source": [
        "#### Step 2: Building the Model\n",
        "Remember that the secret sauce of neural networks is *stacking layers*? In code, we take advantage of this secret sauce by constructing several layers and combining them to create a neural network model. Building the model is a two step process that involves 1) stacking layers together using `torch.nn.Linear`, 2) Define the loss function and optimizer to have the model converge. \n",
        "\n",
        "* **Loss function** - measures how accurate the model is during training, we want to minimize the value this function returns using an optimization method.\n",
        "* **Optimizer** - defines the optimization method to use to update the model's weights based on the data it sees and its loss function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNAeKxvdBzPS"
      },
      "source": [
        "**Building the Model - Step 1: Stacking Layers with `torch.nn.Linear`**\n",
        "\n",
        "The [3Blue1Brown video](https://www.youtube.com/watch?v=aircAruvnKk&t=436s) used a feed forward neural network with 2 hidden layers to classify handwritten digits. To recreate this neural network, first we need to build a model that 1) takes 784 image pixel feature vectors as input, 2) has 2 hidden layers with 16 neurons and the sigmoid activation function, and 3) includes a final layer with 10 neurons (i.e., there are 10 digit classes so we need 10 neurons) and the *softmax* activation function. The softmax activation function normalizes the activations for the output neurons such that:\n",
        "- every activation is between 0 and 1\n",
        "- the sum of all activations is 1\n",
        "\n",
        "Notice that the softmax activation is similar to the sigmoid activation--neuron activations are squeezed between 0 and 1. Softmax differs from sigmoid by constraining the sum of all activations to 1. For multi-class classification problems, where multiple categories/classes are present in the y variable, it is common to use the softmax activation (or a varient) in the final layer. This is because the softmax activation enables us to treat the final neuron activations as confidence values (i.e., probabilities). The neuron with the largest activation is selected as the category/class prediction.       \n",
        "\n",
        "Let's see what this looks like in Python code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ty7RVQcnkHM",
        "outputId": "bd986d40-ebc9-404c-d2bb-5ca5f5e19442"
      },
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    # Contructor\n",
        "    def __init__(self, num_classes):\n",
        "        super(Neural_Network, self).__init__()\n",
        "\n",
        "        # Defining Fully-Connected Layers\n",
        "        self.fc1 = nn.Linear(28*28, 16) # 28*28 since each image is 28*28\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, num_classes)\n",
        "        \n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Need to flatten each image in the batch\n",
        "        x = x.flatten(start_dim=1)\n",
        "\n",
        "        # Input it into the Fully connected layers\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "num_classes = 10\n",
        "model = Neural_Network(num_classes)\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neural_Network(\n",
            "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SCDKeEKPCgf"
      },
      "source": [
        "**Building the Model - Step 2: Defining the Loss Function and Optimizer\n",
        "\n",
        "The model structure is defined in step 1, so most of the building process is finished. We will use categorical cross entropy for the loss function and an Adam optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9R_3BWjpGPM"
      },
      "source": [
        "# Defining loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVrlp2oKVRvT"
      },
      "source": [
        "Now, we can train the model! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiCTup_LfIrt"
      },
      "source": [
        "#### Step 3: Training the Model \n",
        "\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "1. Feed the training data to the model—in this example, the `train_images` and `train_labels` batch in `train_dataloader`.\n",
        "2. The model learns to associate images and labels.\n",
        "3. We ask the model to make predictions on a test set—in this example, the `test_dataloader` Dataloader. We verify that the predictions match the labels from the `test_dataloader` Dataloader. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXfAcQkOrTXR",
        "outputId": "e9ffaf2b-5638-410c-9d81-bacd85f58ea5"
      },
      "source": [
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Moving model to use GPU\n",
        "model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neural_Network(\n",
              "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
              "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXHuzSh7rNUv",
        "outputId": "9703fe26-0795-4f89-f70f-bb906b42ccf2"
      },
      "source": [
        "def get_preds_from_logits(logits):\n",
        "  # Using softmax to get an array that sums to 1, and then getting the index with the highest value\n",
        "  return torch.nn.functional.softmax(logits, dim=1).argmax(dim=1)\n",
        "\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = 0.0\n",
        "\n",
        "    train_counts = 0\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "\n",
        "    # Setting model to train mode\n",
        "    model.train()\n",
        "\n",
        "    for images, labels in training_dataloader:\n",
        "\n",
        "        # Moving data to GPU if available\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Setting all gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate Output\n",
        "        output = model(images)\n",
        "            \n",
        "        # Calculate Loss\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # Calculate Gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform Gradient Descent Step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Saving loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Get Predictions\n",
        "        train_preds = get_preds_from_logits(output)\n",
        "\n",
        "        # Saving number of right predictions for accuracy\n",
        "        train_counts += train_preds.eq(labels).sum().item()\n",
        "\n",
        "    # Averaging and Saving Losses\n",
        "    train_loss/=len(training_data)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Getting accuracies and saving them\n",
        "    train_acc = train_counts/len(training_data)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}%'.format(epoch, train_loss, train_acc*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.005718 \tTraining Accuracy: 79.69%\n",
            "Epoch: 2 \tTraining Loss: 0.002463 \tTraining Accuracy: 90.82%\n",
            "Epoch: 3 \tTraining Loss: 0.002069 \tTraining Accuracy: 92.44%\n",
            "Epoch: 4 \tTraining Loss: 0.001810 \tTraining Accuracy: 93.35%\n",
            "Epoch: 5 \tTraining Loss: 0.001646 \tTraining Accuracy: 93.99%\n",
            "Epoch: 6 \tTraining Loss: 0.001531 \tTraining Accuracy: 94.36%\n",
            "Epoch: 7 \tTraining Loss: 0.001450 \tTraining Accuracy: 94.66%\n",
            "Epoch: 8 \tTraining Loss: 0.001381 \tTraining Accuracy: 94.91%\n",
            "Epoch: 9 \tTraining Loss: 0.001332 \tTraining Accuracy: 95.06%\n",
            "Epoch: 10 \tTraining Loss: 0.001274 \tTraining Accuracy: 95.26%\n",
            "Epoch: 11 \tTraining Loss: 0.001237 \tTraining Accuracy: 95.35%\n",
            "Epoch: 12 \tTraining Loss: 0.001188 \tTraining Accuracy: 95.58%\n",
            "Epoch: 13 \tTraining Loss: 0.001154 \tTraining Accuracy: 95.67%\n",
            "Epoch: 14 \tTraining Loss: 0.001123 \tTraining Accuracy: 95.79%\n",
            "Epoch: 15 \tTraining Loss: 0.001090 \tTraining Accuracy: 95.95%\n",
            "Epoch: 16 \tTraining Loss: 0.001063 \tTraining Accuracy: 96.03%\n",
            "Epoch: 17 \tTraining Loss: 0.001044 \tTraining Accuracy: 96.12%\n",
            "Epoch: 18 \tTraining Loss: 0.001014 \tTraining Accuracy: 96.09%\n",
            "Epoch: 19 \tTraining Loss: 0.000990 \tTraining Accuracy: 96.30%\n",
            "Epoch: 20 \tTraining Loss: 0.000978 \tTraining Accuracy: 96.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAu0kWT4sDFj"
      },
      "source": [
        "**Challenge:** As the model is trained, the loss and metrics are displayed. What is the final accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVOPpkYjp74"
      },
      "source": [
        "Let's plot the loss function measure on the training dataset. However, because our network is small, the training converges (i.e., reaches an optimal loss value) without noticeably overfitting the data as the plot shows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMR71TCgirCr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0492158c-19a0-4a1d-c5e7-70b65361886c"
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcZZ3v8c+vq/e1utOdpTsdkkAkBBDQsAjoIKgsg2RmxDHKMIyiqBMcvG4D15FxmOtcnY0ZR5wRRQ2LAiI4uQ6KQhB0ZAsQwJAgbRImHbKn01s6vf7uH+fpTqXTS1XSVdXd9X2/XvWqU895zqlfVbr7l/Ms5zF3R0REJFl52Q5ARESmFiUOERFJiRKHiIikRIlDRERSosQhIiIpUeIQEZGUKHGIpMDMfmJmV010XZGpxDSPQ6Y7M+tIeFkKdAP94fVH3f2uzEd15MzsPOBOd5+b7VgkN+VnOwCRdHP38sFtM9sMfNjdHx5ez8zy3b0vk7GJTEVqqpKcZWbnmVmzmf2lmW0HvmNm1Wb2YzPbZWYtYXtuwjG/MLMPh+0/M7Nfmdk/hrqbzOziI6y7wMweN7N2M3vYzG4xszuP4DOdEN53n5mtM7PLEvZdYmYvh/fYamafCeW14XPuM7O9ZvZLM9PfBhmVfjgk180GaoBjgGuIfie+E17PA7qAr41x/JnAK0At8PfAbWZmR1D3e8DTwAzgi8CVqX4QMysA/h/wM2Am8AngLjM7PlS5jahprgI4CVgdyj8NNAN1wCzgfwNqw5ZRKXFIrhsA/trdu929y933uPsP3X2/u7cDXwJ+b4zjX3P3b7p7P7ASmEP0xzfpumY2DzgduNHde9z9V8CqI/gsZwHlwJfDeVYDPwbeH/b3AkvMrNLdW9z9uYTyOcAx7t7r7r90dX7KGJQ4JNftcvcDgy/MrNTMvmFmr5lZG/A4EDez2CjHbx/ccPf9YbM8xbr1wN6EMoAtKX4Ownm2uPtAQtlrQEPYfg9wCfCamT1mZm8J5f8ANAE/M7ONZnb9Eby35BAlDsl1w/9n/WngeOBMd68E3hbKR2t+mgjbgBozK00oazyC87wONA7rn5gHbAVw92fcfRlRM9aPgHtDebu7f9rdFwKXAZ8yswuO4P0lRyhxiByqgqhfY5+Z1QB/ne43dPfXgDXAF82sMFwJvHu848ysOPFB1EeyH/icmRWEYbvvBu4O573CzKrcvRdoI2qmw8wuNbPjQn9LK9FQ5YER31QEJQ6R4f4FKAF2A08CP83Q+14BvAXYA/wf4B6i+SajaSBKcImPRqJEcTFR/F8H/tTdN4RjrgQ2hya4j4X3BFgEPAx0AE8AX3f3Ryfsk8m0owmAIpOQmd0DbHD3tF/xiKRKVxwik4CZnW5mx5pZnpldBCwj6ocQmXQ0c1xkcpgN3E80j6MZ+Li7P5/dkERGpqYqERFJiZqqREQkJTnRVFVbW+vz58/PdhgiIlPGs88+u9vd60balxOJY/78+axZsybbYYiITBlm9tpo+9RUJSIiKVHiEBGRlChxiIhISpQ4REQkJUocIiKSEiUOERFJiRKHiIikRIljFAMDztdWv8rjv92V7VBERCYVJY5R5OUZtz6+kYfX78h2KCIik4oSxxjq4yW8vq8r22GIiEwqShxjaIiXsHXfgWyHISIyqShxjKGhWlccIiLDKXGMoT5eQmtXLx3dfdkORURk0lDiGEN9vARAVx0iIgmUOMbQEC8GYKsSh4jIECWOMeiKQ0TkcEocY5hZUUx+nilxiIgkUOIYQyzPmF1VzOsakisiMkSJYxz18RK2tuiKQ0RkkBLHOKJJgEocIiKDlDjG0RAvYXvbAfoHPNuhiIhMCkoc46iPl9A/4OxsVz+HiAgocYyrfnAuh/o5REQAJY5xNYS5HOrnEBGJKHGM4+AkQDVViYiAEse4yoryiZcWaBKgiEigxJGE+irdXl1EZJASRxLqNZdDRGSIEkcSGuLFShwiIoESRxLq4yW0H+ij7UBvtkMREck6JY4kNFRHI6u2aWSViIgSRzK0LoeIyEFKHEkYnATYrMQhIqLEkYy68iIKYlrQSUQElDiSkje0oJMSh4hIWhOHmV1kZq+YWZOZXT/C/iIzuyfsf8rM5ifsuyGUv2JmFyaUbzazl8xsrZmtSWf8iRrimgQoIgJpTBxmFgNuAS4GlgDvN7Mlw6pdDbS4+3HAzcBXwrFLgOXAicBFwNfD+Qa93d1Pdfel6Yp/uPp4ie5XJSJCeq84zgCa3H2ju/cAdwPLhtVZBqwM2/cBF5iZhfK73b3b3TcBTeF8WTO4oFNf/0A2wxARybp0Jo4GYEvC6+ZQNmIdd+8DWoEZ4xzrwM/M7Fkzu2a0Nzeza8xsjZmt2bVr11F9EDi4oNOO9u6jPpeIyFQ2FTvHz3X3NxE1ga0ws7eNVMndb3X3pe6+tK6u7qjfVHM5REQi6UwcW4HGhNdzQ9mIdcwsH6gC9ox1rLsPPu8EHiBDTVgNShwiIkB6E8czwCIzW2BmhUSd3auG1VkFXBW2LwdWu7uH8uVh1NUCYBHwtJmVmVkFgJmVAe8CfpPGzzBkcAnZZi0hKyI5Lj9dJ3b3PjO7FngIiAHfdvd1ZnYTsMbdVwG3AXeYWROwlyi5EOrdC7wM9AEr3L3fzGYBD0T95+QD33P3n6brMyQqLcynWgs6iYikL3EAuPuDwIPDym5M2D4AvHeUY78EfGlY2UbglImPNDn1msshIjIlO8ezRnM5RESUOFKi2eMiIkocKWmIl9De3UdrlxZ0EpHcpcSRAs3lEBFR4kjJ4JBcJQ4RyWVKHCkYXEJWiUNEcpkSRwpqy4oojOWxVSOrRCSHKXGkIC/PmBMvZquuOEQkhylxpKi+SkNyRSS3KXGkSLPHRSTXKXGkqKG6hB1tB+jVgk4ikqOUOFLUEC9mwGF7qzrIRSQ3KXGkSJMARSTXKXGkaChxtCpxiEhuUuJIUX3V4BWHmqpEJDeNmTjMLM/Mzs5UMFNBSWGMGWWFmsshIjlrzMTh7gPALRmKZcqoj5ewVUvIikiOSqap6hEze4+F9VolutmhOsdFJFclkzg+CvwA6DGzNjNrN7O2NMc1qQ1OAnT3bIciIpJx46457u4VmQhkKmmIl9DZ009bVx9VpQXZDkdEJKPGTRwAZnYZ8Lbw8hfu/uP0hTT5NYQhuVv3dSlxiEjOGbepysy+DFwHvBwe15nZ/013YJNZfULiEBHJNclccVwCnBpGWGFmK4HngRvSGdhkptnjIpLLkp0AGE/YrkpHIFPJjLJCCvPzlDhEJCclc8Xxd8DzZvYoYER9HdenNapJLi/PqK/Sgk4ikpvGTBxmlgcMAGcBp4fiv3T37ekObLJrqC5R4hCRnJTMzPHPufs2d18VHjmfNEArAYpI7kqmj+NhM/uMmTWaWc3gI+2RTXL18RJ2tnfT06cFnUQktyTTx/G+8LwiocyBhRMfztTREC/BHXa0HaCxpjTb4YiIZEwyfRzXu/s9GYpnymioPjiXQ4lDRHJJMn0cn81QLFPK0CRA3SVXRHKM+jiO0JyqYkCTAEUk96iP4wgVF8SoLS/UErIiknPGveJw9wUjPJJKGmZ2kZm9YmZNZnbYpEEzKzKze8L+p8xsfsK+G0L5K2Z24bDjYmb2vJll9WaL9fEStmoJWRHJMaMmDjP7XML2e4ft+7vxTmxmMaLVAy8GlgDvN7Mlw6pdDbS4+3HAzcBXwrFLgOXAicBFwNfD+QZdB6wfL4Z0a4hrLoeI5J6xrjiWJ2wPv6HhRUmc+wygyd03unsPcDewbFidZcDKsH0fcEFYaXAZcLe7d7v7JqApnA8zmwv8PvCtJGJIq8ElZLWgk4jkkrESh42yPdLrkTQAWxJeN4eyEeu4ex/QCswY59h/AT5HdCuUUZnZNWa2xszW7Nq1K4lwU1cfL6Grt599+3vTcn4RkclorMTho2yP9DojzOxSYKe7PzteXXe/1d2XuvvSurq6tMTTEI9GVumeVSKSS8ZKHKcMrjEOvDFsD74+OYlzbwUaE17PDWUj1jGzfKJbtu8Z49hzgMvMbDNR09f5ZnZnErGkhdblEJFcNGricPeYu1e6e4W754ftwdfJrJf6DLDIzBaYWSFRn8mqYXVWAVeF7cuB1R51GKwClodRVwuARcDT7n6Du8919/nhfKvd/U9S+sQTqEGJQ0RyUFJrjh8Jd+8zs2uBh4AY8G13X2dmNwFr3H0VcBtwh5k1AXsJHfKh3r1ES9X2ASvcvT9dsR6pmrJCivLz1FQlIjklbYkDwN0fBB4cVnZjwvYB4L3Djwv7vgR8aYxz/wL4xUTEeaTMLAzJ1VwOEckdyS4dK6OIJgHqikNEcocSx1Gqjxerj0NEcsqoTVVh9NSow27dvTItEU0xDfFSdrZ3093XT1F+bPwDRESmuFETh7tXAJjZ3wLbgDuIJv5dAczJSHRTQH2Yy7G99QDHzCjLcjQiIumXTFPVZe7+dXdvd/c2d/93Dr91SM4aHJKrfg4RyRXJJI5OM7si3JE2z8yuADrTHdhUcXASoEZWiUhuSCZxfAD4Y2BHeLw3lAkwWws6iUiOGXceh7tvRk1ToyouiFFXUaQlZEUkZ4x7xWFmbzCzR8zsN+H1G83sr9If2tRRHy/RSoAikjOSaar6JtF6HL0A7v4ih67VkfMa4sXqHBeRnJFM4ih196eHlfWlI5ipqr4qWglQCzqJSC5IJnHsNrNjCZMBzexyonkdEtTHSzjQO0CLFnQSkRyQzE0OVwC3AovNbCuwiWgSoAQN1WEuR0sXNWWFWY5GRCS9xkwcZhYD/tzd32FmZUCeu7dnJrSpI3ES4Mlzq7IcjYhIeo2ZONy938zODdua9DcKrQQoIrkkmaaq581sFfADEmaMu/v9aYtqiqkuLaC4IE+JQ0RyQjKJo5hoHfDzE8ocUOIIBhd00pBcEckFycwc/2AmApnq6uMluuIQkZwwbuIws2LgauBEoqsPANz9Q2mMa8ppiJewfpvGDYjI9JfMPI47gNnAhcBjwFxAfyGHqY+XsLujmwO9/dkORUQkrZJJHMe5+xeATndfCfw+cGZ6w5p6BkdWbW/V7dVFZHpLJnEMTofeZ2YnAVXAzPSFNDVpQScRyRXJjKq61cyqgS8Aq4By4Ma0RjUFKXGISK5IZlTVt8LmY8DC9IYzdc2qKsJMkwBFZPpLZlTViFcX7n7TxIczdRXlx6grL1LiEJFpL5mmqsRbjRQDlwLr0xPO1BbN5VDnuIhMb8k0Vf1T4msz+0fgobRFNIU1VJfw8utt2Q5DRCStkhlVNVwp0VwOGWbwtiNa0ElEprNk+jheIiziBMSAOkD9GyOoryqmp2+APZ091JYXZTscEZG0SKaP49KE7T5gh7tr6dgRJN5eXYlDRKarZJqq2hMeXUClmdUMPtIa3RSjdTlEJBckc8XxHNAItAAGxIH/Cfscze0YMjcsIdvcosQhItNXMlccPwfe7e617j6DqOnqZ+6+wN3HTBpmdpGZvWJmTWZ2/Qj7i8zsnrD/KTObn7DvhlD+ipldGMqKzexpM3vBzNaZ2d+k8mHTraqkgNLCmIbkisi0lkziOMvdHxx84e4/Ac4e76CwXvktwMXAEuD9ZrZkWLWrgRZ3Pw64GfhKOHYJsJzoVu4XAV8P5+sGznf3U4BTgYvM7KwkPkNGmJnW5RCRaS+ZxPG6mf2Vmc0Pj88Drydx3BlAk7tvdPce4G5g2bA6y4CVYfs+4AIzs1B+t7t3u/smoAk4wyMdoX5BeEyqsa/18RJeb1XiEJHpK5nE8X6iIbgPhMfMUDaeBmBLwuvmUDZinTBSqxWYMdaxZhYzs7XATuDn7v5UErFkTEO8mK3q4xCRaSyZmeN7gesAwl1y93kWZ7i5ez9wqpnFgQfM7CR3/83wemZ2DXANwLx58zIWX0O8hD2dPRzo7ae4IJax9xURyZRRrzjM7EYzWxy2i8xsNVGT0Q4ze0cS595KNBpr0NxQNmIdM8snWutjTzLHuvs+4FGiPpDDuPut7r7U3ZfW1dUlEe7E0JBcEZnuxmqqeh/wSti+KtSdCfwe8HdJnPsZYJGZLTCzQqLO7lXD6qwK5wa4HFgdrmZWActDwloALAKeNrO6cKWBmZUA7wQ2JBFLxhxMHBpZJSLT01hNVT0JTVIXAt8PzUTrw9XBmNy9z8yuJbohYgz4truvM7ObgDXuvgq4DbjDzJqAvUTJhVDvXuBlotnqK9y938zmACvDCKs84F53//GRfPB0adAVh4hMc2MlgO6wVOwO4O3AZxL2lSZz8jCM98FhZTcmbB8A3jvKsV8CvjSs7EXgtGTeO1tmVxVjBs1KHCIyTY2VOK4jGiJbB9wchsViZpcAz2cgtimpIJbHrIpiXXGIyLQ1auIIw1wXj1B+2FWEHKo+rsQhItPXkazHIePQ7HERmc6UONKgIV7C660HGBiYVJPaRUQmhBJHGjRUl9DTN8Duzu5shyIiMuGSua06ZnY2MD+xvrvfnqaYprz6qoNzOWZWFGc5GhGRiZXM0rF3AMcCa4H+UOyAEscoEmePn9oYz3I0IiITK5krjqXAkmzen2qq0SRAEZnOkunj+A0wO92BTCeVJfmUFca0EqCITEvJXHHUAi+b2dNECykB4O6XpS2qKc7MaKjWkFwRmZ6SSRxfTHcQ05EWdBKR6SqZmxU+lolAppv6eAkvNrdmOwwRkQk3bh+HmZ1lZs+YWYeZ9ZhZv5m1ZSK4qawhXsLezh66evrHrywiMoUk0zn+NaKlYl8FSoAPA7ekM6jpoD4ezd/Yqn4OEZlmkpo57u5NQMzd+939O4yy6p4c1BCP7jyvDnIRmW6S6RzfH1bwW2tmfw9sQ7cqGdfgFYcSh4hMN8kkgCtDvWuBTqK1wN+TzqCmg1mVxeQZbNjenu1QREQmVDKjql4L63vPcfe/yUBM00JBLI8LT5zNyic2c1JDFZe/eW62QxIRmRDJjKp6N9F9qn4aXp9qZqvSHdh0cPP7TuWcY2v57H0v8J9rt2Y7HBGRCZFMU9UXgTOAfQDuvhZYkMaYpo3ighjf/NOlnLmghk/d+wIPvrQt2yGJiBy1ZBJHr7sPn8mmGx4mqaQwxm1Xnc5pjXH+4vvP87N127MdkojIUUkmcawzsw8AMTNbZGb/Bvw6zXFNK2VF+Xzng6dzUkMVK773HI9u2JntkEREjlgyieMTwIlENzj8PtAGfDKdQU1HFcUFrPzQGRw/u4KP3vksv3x1V7ZDEhE5IuMmDnff7+6fd/fT3X1p2D6QieCmm6qSAu740JksrC3jwyvX8Ovf7c52SCIiKbPR1mcab+TUVLqt+tKlS33NmjXZDmPIno5ult/6JM0tXdx+9RmcPr8m2yGJiBzCzJ5196Uj7RtrHsdbgC1EzVNPAZaG2HLSjPIi7vrImSz/xpN88DvPcPvVZ/CmedXZDktEJCljNVXNBv43cBLwr8A7gd3u/phutX70ZlYU872PnMWM8kKu+vbTvNi8L9shiYgkZdTEEW5o+FN3vwo4C2gCfmFm12YsumludlWUPKpKCrjytqdZ97rW7xCRyW/MznEzKzKzPwLuBFYAXwUeyERguaIhXsL3P3IWpYUxrrztaV7Rva1EZJIbNXGY2e3AE8CbgL8Jo6r+1t1174wJ1lhTyvc/chb5ecYV33qSpp0d2Q5JRGRUY11x/AmwCLgO+LWZtYVHu1YAnHjza8v43kfOAowPfPNJNu3uzHZIIiIjGquPI8/dK8KjMuFR4e6VmQwyVxw3s5y7PnwmfQPOB775JFv27s92SCIih9GCTJPM8bMruPPqM9nf08/yW5U8RGTySWviMLOLzOwVM2sys+tH2F9kZveE/U+Z2fyEfTeE8lfM7MJQ1mhmj5rZy2a2zsyuS2f82bKkvpI7rz6TtgO9XPLVX3Lfs82MNlFTRCTT0pY4zCwG3AJcDCwB3m9mS4ZVuxpocffjgJuBr4RjlwDLie6RdRHw9XC+PuDT7r6EaIjwihHOOS2cPLeKH3/iXE6YXclnfvACH7l9DTvbdKcXEcm+dF5xnAE0uftGd+8B7gaWDauzDFgZtu8DLjAzC+V3u3u3u28imkNyhrtvc/fnANy9HVgPNKTxM2TVMTPKuPuas/jCpUv45au7eefNj/Ofa7fq6kNEsiqdiaOB6JYlg5o5/I/8UB137wNagRnJHBuatU4juh3KYczsGjNbY2Zrdu2auneizcszrj53AQ9e91YW1pVx3d1r+fidz7G7ozvboYlIjpqSneNmVg78EPiku484NNjdbw13811aV1eX2QDT4Ni6cu772NnccPFiVr+yk3fd/Dj/9aJWFBSRzEtn4tgKNCa8nhvKRqxjZvlAFbBnrGPNrIAoadzl7venJfJJKpZnfPT3juW/PnEujdUlrPjec1z7vefY29mT7dBEJIekM3E8AywyswVmVkjU2T38Vu2rgKvC9uXAao8a8FcBy8OoqwVEExGfDv0ftwHr3f2f0xj7pLZoVgU//PjZfPbC43lo3XbedfNjPKQlaUUkQ9KWOEKfxbXAQ0Sd2Pe6+zozu8nMBtfyuA2YYWZNwKeA68Ox64B7gZeBnwIr3L0fOAe4EjjfzNaGxyXp+gyTWX4sjxVvP45V157LrMpiPnrHs/yve9bSur8326GJyDQ36kJO08lkW8hpovX2D3DLo018bXUTNWWFfPk9J3P+4lnZDktEprCxFnKakp3jcqiCWB6ffMcb+NGKc6gpK+RD313DZ3/wAm0HdPUhIhNPiWMaOamhilXXnsu1bz+O+5/fyoVh3kdv/0C2QxORaUSJY5opzM/jMxcez/0fP5vK4gKuu3st53x5NV995FV2tWvuh4gcPfVxTGMDA84vfruT7/76NR7/7S4KY3lc+sY5XHX2fE5pjGc7PBGZxMbq48jPdDCSOXl5xvmLZ3H+4ln8blcHdzzxGj9Ys4X7n9/KqY1xPnjOfC4+aQ6F+brwFJHk6Yojx7Qf6OWHzzaz8onX2LS7k7qKIq44cx4fOHMeMyuKsx2eiEwSY11xKHHkqIEB5/FXd7Hy15t59JVdFMSM3z85asY6bV51tsMTkSxTU5UcJi/POO/4mZx3/Ew27e7k9ic2c9+aZn609nVOmVvFn50zn0tOnkNRfizboYrIJKMrDhnS0d3H/c81s/LXm/ndrk5qywtZdmoDFyyeyekLaiiIqS9EJFeoqUqJIyXuzq+adrMyjMbq6R+goiiftx1fxztOmMl5b5hJdVlhtsMUkTRSU5WkxMx466I63rqojs7uPn7VtJvV63fyyIad/NeL28gzePMx1Zy/eBbvOGEmx80sJ7r/pIjkAl1xSNIGBpyXtrbyyPodPLJhJ+tej5ZCaawp4YLFs7jghJmcsaBG/SIi04CaqpQ40mJbaxerN+zkkfU7+e+m3XT3DVBWGONtb6jj/MUzefvimdSWF2U7TBE5AkocShxp19XTz3837eaRDTtZvWEHO9q6MYPjZ1Vw2rw4p8yNc+q8OItmVhDLU7OWyGSnxKHEkVHuzrrX23hk/U7WvLaXF7bso+1AHwClhTFOaqjitMY4pzTGObUxzpyqYvWRiEwy6hyXjDIzTmqo4qSGKiBKJJt2d/JC8z5e2NLK81v28Z3/3kxPuGtvXUURp8yND12ZvLGxisrigmx+BBEZgxKHpJ2ZsbCunIV15fzhaXMB6O7rZ8O2dl5o3sfa/9nH2uZ9PLx+x9Axx9aVcUpjnJMbqlg8u5LFsys0BFhkklBTlUwarV29vNTcytotLazd0sraLfvY3XHwVvCzK4tZPKeC42dXcMLsShbPqWBhbblu0iiSBmqqkimhqqSAcxfVcu6i2qGyXe3dbNjexoZt7awPz79u2jPUzFUQM46tK+eEOZUcP7uCxbMrOGFOJTMritRvIpImShwyqdVVFFFXEU1GHNTbP8Cm3Z1s2N7Ohm1tbNjezlMb9/DA81uH6lSXFrB4diUL68porCmlsbqUudUlNNaUUl1aoKQichSUOGTKKYjl8YZZFbxhVgWXnVI/VN66vze6Otnezobt7azf1saDL22jZf+ha6+XFcaYW11KY00JcxMSSmN1KXNrStQxLzIOJQ6ZNqpKCzhz4QzOXDjjkPL2A700t3TR3NLFlr372dKyny17u2hu2c+TG/fS0d136HlKCqKkEi/lmNpSFtaWsbCunAW1ZcwoK9TViuQ8JQ6Z9iqKCzhhTgEnzKk8bJ+7s29/lFiihLJ/aPvVne2s3rBzqD8FoLI4nwV15RxbW8aC2jIW1JWxsDZKKiWFutWK5AYlDslpZkZ1WSHVZYWcPLfqsP39A87Wli427u5g465ONu2OHk9u3MP9CX0qAPVVxYckkoV1ZcytLmVmZREVRfm6UpFpQ4lDZAyxPGPejFLmzSjlvOMP3dfV0z+USDbu6mDT7k5+t7uTH63dSvuBQ5u/igvyqKsoYmZFMXXlRcysLBp6nllRHPYVUVNWSL7WPZFJTolD5AiVFMZYUl/JkvpDm8DcnT2dPWzc1cm21i52tnWzq6ObnW0H2Nneze92dfDExj20dvUeds48g5qyKInUVRQxp6qYxpqDHfhzq0uoK9dQY8kuJQ6RCWZm1JYXjXtn4O6+fna1d7OrvZud4RG9PjBUtu71VnZ39BxyXHFBXjQqLCGZNFaXDo0MqyxRs5iklxKHSJYU5cfCcODSMet19fTT3HLoaLAte6MO/Gdfaxm6geSgiqJ85tZEiaU+XsKMskJqK4pCMiuktjy6mikuUGe+HBklDpFJrqQwxqJZFSyaVTHi/tau3qFk0pwwMmzznqgTf3hiGVRelD+USGrLi6itSNguL6KuopAZZUVUlxVSWayrGDlIiUNkiqsqKaCqpIoT6w8fFQZRk9iejh52d3RHj/Yedg1ud/SwO/S7PLWp+7DJkoMKYkZ1aSE1ZQcfM8oKqSkroqasIDwf3FddWqBO/mlMiUNkmivKj1Efj5qtxtPbP8Dezp6hpLKno5u9nT1Djz3h+eXX29jT2TNiB/+geGkBNWWF1JYVMaO8MHqURc1lM8JVzYzyaL/6ZaYWJQ4RGVIQy2NWZTGzKpvL1EoAAAp/SURBVIuTqt/bP0DL/h5aOnvZ0xklmZaEBLOnM0o+TTs7eGpTDy37exjphtz5eTaUWGaE5rMZYX5NvLSAeEn0HF1dFRAvLaBcc2OyRolDRI5YQSyPmRXFzKwoBkbug0nU1z/A3v097OkIj86DVzaJrzfv6WRPRw/7e/pHPVcsz4iHRFJVWkC8pIB4aeEhyaWyuICyohhlRfnRozA/el0YvdYt+Y9MWhOHmV0E/CsQA77l7l8etr8IuB14M7AHeJ+7bw77bgCuBvqBv3D3h0L5t4FLgZ3uflI64xeRiZV/SKIZ34Heflq7etm3v5d9+3vY19VL6/7eqKyrJyoPZbs6unl1ZwetXb2HTcAcTUHMDkkopYX5lBcdTC4VxflUD/XbRM+DTXDVpYU5OzItbYnDzGLALcA7gWbgGTNb5e4vJ1S7Gmhx9+PMbDnwFeB9ZrYEWA6cCNQDD5vZG9y9H/gu8DWihCMi01hxQYzigljSTWeD+voHaDvQR1tXL509fXR294fnPvYnbHf29EfP3eE5lO/u6KajOzp+tFFpAKWFMapLC6kuKxhKLNWlg0kmugKqDFdAlcX50XNJAQVTfOBAOq84zgCa3H0jgJndDSwDEhPHMuCLYfs+4GsWNVouA+52925gk5k1hfM94e6Pm9n8NMYtIlNcfixvaITX0errH2BfVy8tod+mZX8vLft7hvpz9u6Prnz2dvbwP3v3s7ezZ9wrntLCGJXFIaGUhIRSHCWVxERTUZxPUX6Movw8igryDm7nx8LraLswP49YXub6e9KZOBqALQmvm4EzR6vj7n1m1grMCOVPDju2IZU3N7NrgGsA5s2bl1LgIiKD8mN5Sd0JIFFv/8BQ81rbgahprbWrl7auvvAcXod9r+87wPqudtoOJN/MdliceRYSzGByiZoF7/3YW47ofGO+14SfcZJw91uBWyFaczzL4YhIDimI5YXVK5NPNoP6B5yOA1GCae/upadvgJ6+AbqHHv109x7c7hmlvLtvgJI09cGkM3FsBRoTXs8NZSPVaTazfKCKqJM8mWNFRKadWJ5RVRqNFJus0tlD8wywyMwWmFkhUWf3qmF1VgFXhe3LgdXu7qF8uZkVmdkCYBHwdBpjFRGRJKUtcbh7H3At8BCwHrjX3deZ2U1mdlmodhswI3R+fwq4Phy7DriXqCP9p8CKMKIKM/s+8ARwvJk1m9nV6foMIiJyOPORpnFOM0uXLvU1a9ZkOwwRkSnDzJ5196Uj7Zvag4lFRCTjlDhERCQlShwiIpISJQ4REUmJEoeIiKQkJ0ZVmdku4LUjPLwW2D2B4Uw0xXd0FN/RUXxHZzLHd4y71420IycSx9EwszWjDUmbDBTf0VF8R0fxHZ3JHt9o1FQlIiIpUeIQEZGUKHGM79ZsBzAOxXd0FN/RUXxHZ7LHNyL1cYiISEp0xSEiIilR4hARkZQocQRmdpGZvWJmTWZ2/Qj7i8zsnrD/qUyue25mjWb2qJm9bGbrzOy6EeqcZ2atZrY2PG7MVHzh/Teb2UvhvQ+7FbFFvhq+vxfN7E0ZjO34hO9lrZm1mdknh9XJ6PdnZt82s51m9puEshoz+7mZvRqeq0c59qpQ51Uzu2qkOmmK7x/MbEP493vAzOKjHDvmz0Ia4/uimW1N+De8ZJRjx/xdT2N89yTEttnM1o5ybNq/v6Pm7jn/AGLA74CFQCHwArBkWJ0/B/4jbC8H7slgfHOAN4XtCuC3I8R3HvDjLH6Hm4HaMfZfAvwEMOAs4Kks/ltvJ5rclLXvD3gb8CbgNwllfw9cH7avB74ywnE1wMbwXB22qzMU37uA/LD9lZHiS+ZnIY3xfRH4TBL//mP+rqcrvmH7/wm4MVvf39E+dMUROQNocveN7t4D3A0sG1ZnGbAybN8HXGBmlong3H2buz8XttuJFsZqyMR7T6BlwO0eeRKIm9mcLMRxAfA7dz/SOwlMCHd/HNg7rDjxZ2wl8AcjHHoh8HN33+vuLcDPgYsyEZ+7/8yjBdoAniRa0jkrRvn+kpHM7/pRGyu+8Hfjj4HvT/T7ZooSR6QB2JLwupnD/zAP1Qm/PK3AjIxElyA0kZ0GPDXC7reY2Qtm9hMzOzGjgYEDPzOzZ83smhH2J/MdZ8JyRv+Fzeb3BzDL3beF7e3ArBHqTJbv8UNEV5AjGe9nIZ2uDU1p3x6lqW8yfH9vBXa4+6uj7M/m95cUJY4pxMzKgR8Cn3T3tmG7nyNqfjkF+DfgRxkO71x3fxNwMbDCzN6W4fcfl5kVApcBPxhhd7a/v0N41GYxKcfKm9nngT7grlGqZOtn4d+BY4FTgW1EzUGT0fsZ+2pj0v8uKXFEtgKNCa/nhrIR65hZPlAF7MlIdNF7FhAljbvc/f7h+929zd07wvaDQIGZ1WYqPnffGp53Ag8QNQkkSuY7TreLgefcfcfwHdn+/oIdg8134XnnCHWy+j2a2Z8BlwJXhOR2mCR+FtLC3Xe4e7+7DwDfHOV9s/395QN/BNwzWp1sfX+pUOKIPAMsMrMF4X+ly4FVw+qsAgZHsFwOrB7tF2eihTbR24D17v7Po9SZPdjnYmZnEP3bZiSxmVmZmVUMbhN1ov5mWLVVwJ+G0VVnAa0JzTKZMur/9LL5/SVI/Bm7CvjPEeo8BLzLzKpDU8y7QlnamdlFwOeAy9x9/yh1kvlZSFd8iX1mfzjK+ybzu55O7wA2uHvzSDuz+f2lJNu985PlQTTq57dEIy4+H8puIvolASgmauJoAp4GFmYwtnOJmi1eBNaGxyXAx4CPhTrXAuuIRok8CZydwfgWhvd9IcQw+P0lxmfALeH7fQlYmuF/3zKiRFCVUJa1748ogW0Deona2a8m6jN7BHgVeBioCXWXAt9KOPZD4eewCfhgBuNrIuofGPwZHBxlWA88ONbPQobiuyP8bL1IlAzmDI8vvD7sdz0T8YXy7w7+zCXUzfj3d7QP3XJERERSoqYqERFJiRKHiIikRIlDRERSosQhIiIpUeIQEZGUKHGITGLhrr0/znYcIomUOEREJCVKHCITwMz+xMyeDmsofMPMYmbWYWY3W7SGyiNmVhfqnmpmTyasa1Edyo8zs4fDjRafM7Njw+nLzey+sBbGXZm6K7PIaJQ4RI6SmZ0AvA84x91PBfqBK4hmq69x9xOBx4C/DofcDvylu7+RaKbzYPldwC0e3WjxbKKZxxDdDfmTwBKimcXnpP1DiYwhP9sBiEwDFwBvBp4JFwMlRDcoHODgzezuBO43syog7u6PhfKVwA/C/Yka3P0BAHc/ABDO97SHexuFVePmA79K/8cSGZkSh8jRM2Clu99wSKHZF4bVO9L7+3QnbPej31vJMjVViRy9R4DLzWwmDK0dfgzR79floc4HgF+5eyvQYmZvDeVXAo95tLJjs5n9QThHkZmVZvRTiCRJ/3MROUru/rKZ/RXRqm15RHdEXQF0AmeEfTuJ+kEgumX6f4TEsBH4YCi/EviGmd0UzvHeDH4MkaTp7rgiaWJmHe5enu04RCaamqpERCQluuIQEZGU6IpDRERSosQhIiIpUeIQEZGUKHGIiEhKlDhERCQl/x9E4saN/EkRuAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR_91UyCZC3I"
      },
      "source": [
        "Now, let's plot accuracy metrics on the training data. If the validation accuracy is noticeably different than the training one, we might want to do some more analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ltdcaeAa6YM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d0be9eab-d529-4cf2-828a-cceb1bcbe9eb"
      },
      "source": [
        "plt.plot(train_accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyddZ33/9c7SdN0ydI2ge4blqWAFIgsgshYZQrKoriArA4jMopzO6Nziz+9lZvRnzOOv1tnHBbBQZZBAUGwv7lhGEQQnRuGpuxLgbZsPV1IadJ0SdIsn/uP60p7GtLmpM3JaXLez8fjPM61fK/rfK7TJJ9+t+tSRGBmZparkkIHYGZmw4sTh5mZDYgTh5mZDYgTh5mZDYgTh5mZDYgTh5mZDYgThxUlSfdLumiwy5oVA3kehw0XkjZnrY4F2oGudP0LEXHb0Ee19yTNAVYAP42Ivyh0PGb9cY3Dho2IGN/zAt4ETs/atj1pSCorXJR75EKgCfiMpNFD+cGSSofy82xkcOKwYU/SyZJWSfq6pLXAzyVNkPRvkholNaXL07OOeUTSn6fLF0v6o6QfpmVfk3TqHpadI+lRSZsk/VbS1ZL+dTexiyRxfAvoAE7vtf9MSU9LapG0QtKidPtEST+XtDqN497s+HqdIyS9J12+SdK1ku6TtAX4E0kflfRU+hlvSbqy1/EnSvo/kprT/RdLep+kddmJR9InJD2T0z+aDWtOHDZSTAYmArOAS0l+tn+ers8EWoF/3s3xxwIvA7XAD4B/Sf+oD7TsL4AngEnAlcAF/cR9IjAduB24E9jelyLpGOAW4G+AGuAk4PV0960kzXWHAvsBP+rnc7J9FvgeUAn8EdhCkrxqgI8CfyHprDSGWcD9wE+AOmAB8HRELAHeAU7JOu8Fabw2wg23Kr3ZrnQD34mI9nS9Fbi7Z6ek7wEP7+b4NyLihrTszcA1wP7A2lzLSioH3gcsjIhtwB8lLe4n7ouA+yOiSdIvgEcl7RcRbwOXADdGxINp2Uz6mVOAU4FJEdGU7vt9P5+T7TcR8Z/pchvwSNa+ZyX9EvggcC9JkvltRPwy3f9O+gK4GTgfuF/SROBPgS8OIA4bplzjsJGiMSLaelYkjZX0U0lvSGoBHgVqdtOmvz1BRMTWdHH8AMtOBTZkbQN4a1cBSxoDfAq4LT3XYyR9N59Ni8wg6TTvbUb6OU197MvFTjFJOlbSw2mz3kbgMpLa1O5iAPhX4HRJ44BPA3+IiDV7GJMNI04cNlL0Hh74VeAg4NiIqCJp5gHYVfPTYFgDTJQ0NmvbjN2U/zhQBVwjaW3aPzONHc1VbwEH9HHcW+nn1PSxbwtJExYAkib3Uab3d/ULYDEwIyKqgevY8T3tKgYiIgM8BnyCpJnq1r7K2cjjxGEjVSVJc1Vz2ozynXx/YES8ATQAV0oql3Q8vTq7e7kIuBE4nKTvYAFwAnCEpMOBfwE+J2mhpBJJ0yQdnP6v/n6ShDNB0ihJPYnxGeBQSQskVZD0s/SnkqQG05b2q3w2a99twIclfVpSmaRJkhZk7b8F+O/pNfw6h8+yEcCJw0aqHwNjgPXA48C/D9HnngccT9IP8F3gDpL5JjuRNA1YCPw4ItZmvZamsV4UEU8AnyPp+N5I0o8xKz3FBSSjsJYBbwNfAYiIV4CrgN8Cr5J0fvfni8BVkjYB3ybppCc935vAaSQ1uA3A08ARWcfek8Z0T68mOhvBPAHQLI8k3QEsi4i813gKRdIKkgmYvy10LDY0XOMwG0Tp/IYD0qalRcCZJKOTRiRJZ5P0mfyu0LHY0PFwXLPBNZmkrX8SsAr4i4h4qrAh5YekR4D5wAUR0V3gcGwIuanKzMwGxE1VZmY2IEXRVFVbWxuzZ88udBhmZsPK0qVL10dEXe/tRZE4Zs+eTUNDQ6HDMDMbViS90dd2N1WZmdmAOHGYmdmAOHGYmdmAOHGYmdmAOHGYmdmAOHGYmdmAOHGYmdmAFMU8DjOz4aSzq5tVTa2samqlo6ubzu6gK311dndvX07Wo4/1brq6oau7m4tPmMPEceWDGp8Th5lZgWxq62Bl4xZWNG7e/r6icTOvr9/Ktq7BuW/kGQumOnGYmQ2Fjq5utrZ3UVoqykqSV2mJkAb29OHu7mBNSxsr3t7MysbNrMhKEOtadjzjq7REzJo0lgPqxvOhg/dnbt04Zk4cy+iyEspKSigtEWWlokQ7YikrFaVKl0tKtsfaU6akJD9PSnbiMLMRKSJo7+xmY2vHjtfWDlraOnba1tLamb6n6+n+rdu6+jzvqNLkD/WokhLKSkVZaUmSWEp3bCstKWFUqejoCl5fv4XWjh3nqqwo4z37jefE99RxwH7jOKBuPAfUjWfmxLGUlw2PbmcnDjPbJ3V3B01bt9HS1smmtg42tXXS0pq+p+s7lnuvJ8d0dO3+sRHjR5dRPWYUlRXJ+6xJY6keM2r7a0x5KRHQ0d1NZ1fQmfY3dHZH0vfQlSz3bO/oSvofOrqSvogSiePnTtopQdSOLx9wrWVf48RhZgXR3tnFmuY2Ms2tZJpak/d0efXGVtY0t/Xbzj+uvJSq9A9/ZcUoJo0vZ3btOKrS9Z6E0POqyl6uKKOsdHj8D39f48RhZoOup7awrqWd1c1ZSSErSTRuat/pGAn2qxzNtJoxvHd6DYsOq2BKVUWaGJIkUJX1Pr6ijNI8teHb7jlxmFlOuruDja0dNG5uZ/2mdho3t9O4qZ31m7el7+3b39/Zso2u7p2bicrLSphWM4ZpNWP4k4PqmFYzlmkTxjC1poLpNWOZXF0xbNr4i50Th1kR6ekwbmlLOoU3tXVs70PYsb6jP6G5tYP1m9tZv2kb6ze309n97j6DUaWibvxoaitHM6W6gsOnVVNbWU7d+NHUVVYwbUKSLCaNK8/bKB8bWk4cZiPIxtYOXl67iZfXtvDS2k28+c7WnRLBprbOfvsNSsT2foPqMaOoGz+aQyZXUVc5mto0QSRJoZy68RVUjSkb9p29NjBOHGbD0LbOblY0bubltZtYliaKZWs3sWZj2/YyVRVlzK0bz4Sx5cyaNG7nPoK0czh7vWf/2PJSJwLbLScOs31YRLB6Y1tSg1izKa1NbGJF4+btzUajSsUBdeM5ds5EDppcxcFTKjl4ciWTqyqcACwvnDjMhkhbR9e7JqPttN7Ha11LG5vaOrefY1rNGA6eXMnCQ/bjoMmVHDy5irl14xjlYaU2hJw4zAZBz20lXmvcwmvrN7Ny/RZeW7+FTFPr9iTQ3rn7voXK0WXb5xnUjB3FvP3Gc/zcSWmCqOTAyZVUVYwaoisy27W8Jg5Ji4B/BEqBn0XE3/XaPwu4EagDNgDnR8SqdF8X8Fxa9M2IOCPdPge4HZgELAUuiIht+bwOM0iajTZs2cZr67dsTwxJotjC6+9s2SkxjC0vZU7tOObWjWPC2PJ3TT7r/ar0ZDQbRvKWOCSVAlcDHwFWAUskLY6IF7OK/RC4JSJulvQh4PvABem+1ohY0Mep/x74UUTcLuk64BLg2nxdhxWXto4u1m5sY83GNtZsTG5rvT1RNG6mJavZqKxEzJw0lrm14zjpwFrm1I7fniz2qxzt/gUbsfJZ4zgGWB4RKwEk3Q6cCWQnjvnAX6fLDwP37u6ESn4TPwR8Nt10M3AlThyWg7aOLta1tLG6uY21La3Je5og1qTJYsOWd1dep1ZXMKduHGcsmMqc2vHMrR3HnNpxTJ8wxrUEK0r5TBzTgLey1lcBx/Yq8wzwCZLmrI8DlZImRcQ7QIWkBqAT+LuIuJekeao5Ijqzzjmtrw+XdClwKcDMmTMH54psn9fe2cWKt7ewbG1LOvpoC2s2trJ2Yxvv9JEUqseMYkp1BVOqKzhiRg1TqiqYUjNm+7Yp1WMYU15agCsx23cVunP8a8A/S7oYeBTIAD33H54VERlJc4HfSXoO2JjriSPieuB6gPr6+t3fItOGnYhgXUs7L61tYdmaTSxL37OHqZaXljCndhxTayp47/QaplZXMLm6gqk1Y5icJoax5YX+FTAbfvL5W5MBZmStT0+3bRcRq0lqHEgaD5wdEc3pvkz6vlLSI8CRwN1AjaSytNbxrnPayLN1WyevrNvMsjXJJLeX0veNrR3by/QMU/3w/P04eHIVh0ypZPakcW5KMsuDfCaOJcC8dBRUBjiHHX0TAEiqBTZERDfwDZIRVkiaAGyNiPa0zAnADyIiJD0MfJJkZNVFwG/yeA02xLq6g2VrW1j6RhMNrzfxXGYjr7+zhUjrjOPKSzlociUffe8UDk7nMRw0uZLqMR6majZU8pY4IqJT0uXAAyTDcW+MiBckXQU0RMRi4GTg+5KCpKnqS+nhhwA/ldQNlJD0cfR0qn8duF3Sd4GngH/J1zVY/m1u7+SpN5MksfSNJp56s4kt6ZPX9q8azZEzJnDWgmkcPKWSQyZXMX3CGN8oz6zAFDHym//r6+ujoaGh0GEUvYgg09zK0jeattcolq1toTuSZzEcPLmK+lkTqJ89gaNnTWBazRgPaTUrIElLI6K+93b3DFredHZ189KaTTS8sYGGN5pY+noTa1uSm/CNLS/lyJk1XP6hedTPmsCRM2uo9Kxos2HBicMGTUTw+jtb+eOrjfzh1fU8tvKd7fdZmlJdQf3sCWmNYiIHT650x7XZMOXEYXulacs2/nPFev746nr+8Op6Ms2tQDLK6bTDpvD+90zifbMnMrVmTIEjNbPB4sRhA9Le2cXS15v4w/IkWTy/eiMRyQ36jj9gEpd9cC4nzqtj9qSx7p8wG6GcOGy3IoJlazclNYrl63nitXdo6+imtEQcOaOGryw8kBPn1XLE9Go3PZkVCScO69Pq5lZ+9ofXWPzMatZvbgdgbt04PlM/gxPn1XHc3InuzDYrUk4ctpPX1m/hukdW8OunVhEBpxy6PycfuB8nzqt1P4WZAU4clnpxdQvXPLKc+55bw6jSEj57zEw+f9Jcpk8YW+jQzGwf48RR5Bpe38A1j6zgd8veZvzoMr7wwQP4sxPmUFc5utChmdk+yomjCEUEj766nqsfXs4Tr21g4rhyvnbKgVxw/Gzf88nM+uXEUUS6u4MHXljL1Y8s5/lMC1OqK/jO6fP5zPtm+PbiZpYz/7UoAh1d3dz7VIZrf7+ClY1bmFM7jh+c/V7OOnIa5WUeQmtmA+PEMYK1dXRxx5K3uP7RlWSaWzlkShX//NkjOfWwKZT6DrNmtoecOEaoJ17bwNd+9QxvbthK/awJfPfjh3HygXWezW1me82JY4Rp6+jiHx54mRv/8zVmTBjLv15yLCfOqy10WGY2gjhxjCBPvtnE1+58hpXrt3DBcbO44tSDGTfa/8RmNrj8V2UEaOvo4se/fZXrH13BlOox3Pbnx3LCe1zLMLP8cOIY5p5d1cxX73yGV9/ezDnvm8E3P3qI7yFlZnnlxDFMbevs5ie/e5VrHllB3fjR3PS593HyQfsVOiwzKwJOHMPQi6tb+OqvnuGlNS2cfdR0vn36fM/4NrMh48QxjHR0dXPtIyv4p4depWZsOTdcWM9H5u9f6LDMrMjkddqwpEWSXpa0XNIVfeyfJekhSc9KekTS9HT7AkmPSXoh3feZrGNukvSapKfT14J8XsO+4pV1m/jENf+H//XgK5x2+BQe/KuTnDTMrCDyVuOQVApcDXwEWAUskbQ4Il7MKvZD4JaIuFnSh4DvAxcAW4ELI+JVSVOBpZIeiIjm9Li/iYi78hX7vqSrO7j+0ZX86MFXGF9RxrXnHcWph08pdFhmVsTy2VR1DLA8IlYCSLodOBPIThzzgb9Olx8G7gWIiFd6CkTEaklvA3VAM0XktfVb+Os7n+apN5s59bDJ/O1Zh1E73rc7N7PCymdT1TTgraz1Vem2bM8An0iXPw5USpqUXUDSMUA5sCJr8/fSJqwfSerzL6mkSyU1SGpobGzcm+soiLdb2jj3+sdZ2biFfzxnAdecd5SThpntEwp9a9SvAR+U9BTwQSADdPXslDQFuBX4XER0p5u/ARwMvA+YCHy9rxNHxPURUR8R9XV1dXm8hMHX1tHF529dysbWDn7x+WM5c8E032PKzPYZ+WyqygAzstanp9u2i4jVpDUOSeOBs3v6MSRVAf8b+GZEPJ51zJp0sV3Sz0mSz4gREXz97md55q1mrjv/aA6dWl3okMzMdpLPGscSYJ6kOZLKgXOAxdkFJNVK6onhG8CN6fZy4B6SjvO7eh0zJX0XcBbwfB6vYchd88gKfvP0ar52yoEsOmxyocMxM3uXvCWOiOgELgceAF4C7oyIFyRdJemMtNjJwMuSXgH2B76Xbv80cBJwcR/Dbm+T9BzwHFALfDdf1zDU/v35tfzDAy9z5oKpfOlP3lPocMzM+qSIKHQMeVdfXx8NDQ2FDmO3Xli9kU9e+xgHTq7kjkuPo2JUaaFDMrMiJ2lpRNT33l7oznEDGje18/mbG6geM4obLjjaScPM9mm+5UiBtXV08YVbG9iwdRt3XfZ+9quqKHRIZma75cRRQBHB//Pr53jyzWauOe8oDpvmEVRmtu9zU1UBXff7lfz6qQx/9eEDOc23ETGzYcKJo0AefHEdP3hgGR977xT+cqFHUJnZ8OHEUQAvrWnhv93+FIdPq+aHnzrCs8LNbFhx4hhi6ze38+c3NzB+dBnXX1DvEVRmNuy4c3wItXd2cdmtS1m/uZ07v3A8k6s9gsrMhh8njiESEXzznudpeKOJn5x7JEfMqCl0SGZme8RNVUPkZ394jbuWruIvF87j9COmFjocM7M95sQxBH63bB3/7/0vcdrhk/nKwnmFDsfMbK84ceTZK+s28Ze/fJr5U6r44aeOoKTEI6jMbHhz4sijDVu2ccnNSxhTXsrPLqpnbLm7lMxs+PNfsjz6/n0vsa6lnTsuPY4p1WMKHY6Z2aBwjSOPlq3dxHFzJ3HkzAmFDsXMbNA4ceRRprmVaTWuaZjZyOLEkSdbt3WyYcs2pk9w4jCzkcWJI09WN7cCuMZhZiOOE0eevNWUJg7XOMxshHHiyJNMk2scZjYy5TVxSFok6WVJyyVd0cf+WZIekvSspEckTc/ad5GkV9PXRVnbj5b0XHrOf9I+ek/yTHMrZSVifz8K1sxGmLwlDkmlwNXAqcB84FxJ83sV+yFwS0S8F7gK+H567ETgO8CxwDHAdyT1jGm9Fvg8MC99LcrXNeyNTFMrk6srKPVMcTMbYfJZ4zgGWB4RKyNiG3A7cGavMvOB36XLD2ft/1PgwYjYEBFNwIPAIklTgKqIeDwiArgFOCuP17DHPBTXzEaqfCaOacBbWeur0m3ZngE+kS5/HKiUNGk3x05Ll3d3TgAkXSqpQVJDY2PjHl/Enso0tbpj3MxGpEJ3jn8N+KCkp4APAhmgazBOHBHXR0R9RNTX1dUNxilztq2zm3Wb2pjuGoeZjUD5vFdVBpiRtT493bZdRKwmrXFIGg+cHRHNkjLAyb2OfSQ9fnqv7Tudc1+wdmMbER6Ka2YjUz5rHEuAeZLmSCoHzgEWZxeQVCupJ4ZvADemyw8Ap0iakHaKnwI8EBFrgBZJx6WjqS4EfpPHa9gjq5q3AjCtZmyBIzEzG3z9Jg5Jp2f9cc9ZRHQCl5MkgZeAOyPiBUlXSTojLXYy8LKkV4D9ge+lx24A/pYk+SwBrkq3AXwR+BmwHFgB3D/Q2PIt48l/ZjaC5dJU9Rngx5LuBm6MiGW5njwi7gPu67Xt21nLdwF37eLYG9lRA8ne3gAclmsMhZBJbzcypdpzOMxs5Om3JhER5wNHkvzv/iZJj6UjlirzHt0wlWlqpa5yNBWjSgsdipnZoMupCSoiWkhqBrcDU0iGzj4p6ct5jG3Y8hwOMxvJcunjOEPSPSSjmkYBx0TEqcARwFfzG97wlGn2HA4zG7ly6eM4G/hRRDyavTEitkq6JD9hDV/d3cGa5jYWHTq50KGYmeVFLonjSmBNz4qkMcD+EfF6RDyUr8CGq8bN7Wzr6naNw8xGrFz6OH4FdGetd6XbrA+rfDt1MxvhckkcZelNCgFIl8vzF9Lw1jMU1zUOMxupckkcjVkT9pB0JrA+fyENb36Ak5mNdLn0cVwG3CbpnwGR3LX2wrxGNYxlmrdSVVFGZcWoQodiZpYX/SaOiFgBHJfehJCI2Jz3qIax5HbqvkeVmY1cOd0dV9JHgUOBip4ntUbEVXmMa9jKNLcyc+K4QodhZpY3uUwAvI7kflVfJmmq+hQwK89xDUsRQaaplenuGDezESyXzvH3R8SFQFNE/E/geODA/IY1PG1s7WDLti53jJvZiJZL4mhL37dKmgp0kNyvynpZ5dupm1kRyKWP4/+XVAP8A/AkEMANeY1qmNo+h8M1DjMbwXabONIHOD0UEc3A3ZL+DaiIiI1DEt0w4wc4mVkx2G1TVUR0A1dnrbc7aexaprmVilElTBrnifVmNnLl0sfxkKSz1TMO13Yp09TK1Jox+Ksys5Esl8TxBZKbGrZLapG0SVJLnuMalvwAJzMrBrnMHPcjYnOUaW7lsGlVhQ7DzCyv+k0ckk7qa3vvBzsVu63bOtmwZZtrHGY24uUyHPdvspYrgGOApcCH+jtQ0iLgH4FS4GcR8Xe99s8EbgZq0jJXRMR9ks7r9bnvBY6KiKclPUIyj6Q13XdKRLydw3Xk1WrfTt3MikQuTVWnZ69LmgH8uL/jJJWSjMj6CLAKWCJpcUS8mFXsW8CdEXGtpPnAfcDsiLgNuC09z+HAvRHxdNZx50VEQ38xDKUdD3DyDQ7NbGTLpXO8t1XAITmUOwZYHhEr04c/3Q6c2atMAD2dAtXA6j7Oc2567D7ND3Ays2KRSx/HT0j+wEOSaBaQzCDvzzSSZ3f0WAUc26vMlcB/SPoyMA74cB/n+QzvTjg/l9QF3A18NyKi90GSLgUuBZg5c2YO4e6dTFMrpSVi/8rRef8sM7NCyqXG0UDSp7EUeAz4ekScP0iffy5wU0RMB04Dbk1nqwMg6Vhga0Q8n3XMeRFxOPCB9HVBXyeOiOsjoj4i6uvq6gYp3F3LNLcyuaqCstI9qcSZmQ0fuXSO3wW0RUQXJH0XksZGxNZ+jssAM7LWp6fbsl0CLAKIiMckVQC1QE9n9znAL7MPiIhM+r5J0i9ImsRuyeE68ip5gJObqcxs5Mtp5jiQ/RdxDPDbHI5bAsyTNEdSOUkSWNyrzJvAQgBJh5CM2mpM10uAT5PVvyGpTFJtujwK+BjwPPuATHMr0z0U18yKQC41jorsx8VGxGZJ/Q4diohOSZcDD5AMtb0xIl6QdBXQEBGLga8CN0j6K5J+lIuz+itOAt6KiJVZpx0NPJAmjVKSBFbwO/V2dHWzrqXNNQ4zKwq5JI4tko6KiCcBJB3NjjkUuxUR95EMsc3e9u2s5ReBE3Zx7CPAcb22bQGOzuWzh9LajW10h2+nbmbFIZfE8RXgV5JWkzw6djLJSCdL9czhmD7BczjMbOTLZQLgEkkHAwelm16OiI78hjW8eA6HmRWTfjvHJX0JGBcRz6fDYsdL+mL+Qxs+eh7gNKW6osCRmJnlXy6jqj6fPgEQgIhoAj6fv5CGn0zzVuoqR1MxqrTQoZiZ5V0uiaM0+yFO6T2o/Ii7LH4Oh5kVk1wSx78Dd0haKGkhyYS8+/Mb1vDiyX9mVkxySRxfB34HXJa+nmPnCYFFrbs7WN3c5sl/ZlY0+k0cEdEN/BfwOsntPT4EvJTfsIaP9Zvb2dbV7RqHmRWNXQ7HlXQgyU0IzwXWA3cARMSfDE1ow8OqnqG4rnGYWZHY3TyOZcAfgI9FxHKA9NYglqVnKK5rHGZWLHbXVPUJYA3wsKQb0o5x7aZ8Ucq4xmFmRWaXiSMi7o2Ic4CDgYdJbj2yn6RrJZ0yVAHu6zJNrVRVlFFZMarQoZiZDYlcOse3RMQv0mePTweeIhlpZaRzOHyPKjMrIgN6XF1ENKVP1luYr4CGm0yTJ/+ZWXHxc073QkQkD3Byx7iZFREnjr3Q0trJ5vZO1zjMrKg4ceyFVc3JY9c9FNfMiokTx17YPofDNQ4zKyJOHHvBD3Ays2LkxLEXMk2tVIwqYdI432XezIqHE8deyDS3MrVmDFmPKzEzG/HymjgkLZL0sqTlkq7oY/9MSQ9LekrSs5JOS7fPltQq6en0dV3WMUdLei495z+pgH+1/QAnMytGeUsc6ZMCrwZOBeYD50qa36vYt4A7I+JI4Bzgmqx9KyJiQfq6LGv7tSSPrp2Xvhbl6xr6k2nyHA4zKz75rHEcAyyPiJURsQ24HTizV5kAqtLlamD17k4oaQpQFRGPR0QAtwBnDW7YuWnd1sU7W7a5xmFmRSefiWMa8FbW+qp0W7YrgfMlrQLuA76ctW9O2oT1e0kfyDrnqn7OCYCkSyU1SGpobGzci8vom0dUmVmxKnTn+LnATRExHTgNuFVSCcnt3GemTVh/DfxCUtVuzvMu6T216iOivq6ubtAD33E7dd/g0MyKy+4e5LS3MsCMrPXp6bZsl5D2UUTEY5IqgNqIeBtoT7cvlbQCODA9fno/5xwSfoCTmRWrfNY4lgDzJM2RVE7S+b24V5k3gYUAkg4BKoBGSXVp5zqS5pJ0gq+MiDVAi6Tj0tFUFwK/yeM17FKmeSulJWL/ytGF+Hgzs4LJW40jIjolXQ48AJQCN0bEC5KuAhoiYjHwVeCG9JG0AVwcESHpJOAqSR1AN3BZRGxIT/1F4CZgDHB/+hpymaZWJldVUFZa6NY+M7Ohlc+mKiLiPpJO7+xt385afhE4oY/j7gbu3sU5G4DDBjfSgUse4ORmKjMrPv7v8h7KNLUy3UNxzawIOXHsgY6ubta2tLnGYWZFyYljD6zd2EZ3+HbqZlacnDj2gCf/mVkxc+LYA36Ak5kVMyeOPdBT45jqxGFmRciJYw9kmlqpHT+ailGlhQ7FzGzIOXHsAc/hMLNi5sSxBzLNnsNhZsXLiWOAurvDNQ4zK2pOHAO0fks72zq7PaLKzIqWE8cAeSiumRU7J44B8uQ/Myt2ThwD5Ac4mVmxc+IYoExzK5UVZVRVjCp0KGZmBeHEMUCZplb3b5hZUXPiGKBMcyvT3WzEESEAAAvWSURBVExlZkXMiWOAXOMws2LnxDEAG1s72NTe6Y5xMytqThwDsGMOx9gCR2JmVjh5TRySFkl6WdJySVf0sX+mpIclPSXpWUmnpds/ImmppOfS9w9lHfNIes6n09d++byGbJ7DYWYGZfk6saRS4GrgI8AqYImkxRHxYlaxbwF3RsS1kuYD9wGzgfXA6RGxWtJhwAPAtKzjzouIhnzFviuZpq2AZ42bWXHLZ43jGGB5RKyMiG3A7cCZvcoEUJUuVwOrASLiqYhYnW5/ARgjaXQeY81JprmV0WUl1I4vL3QoZmYFk8/EMQ14K2t9FTvXGgCuBM6XtIqktvHlPs5zNvBkRLRnbft52kz1PyRpEGPerUxzMqJqCD/SzGyfU+jO8XOBmyJiOnAacKuk7TFJOhT4e+ALWcecFxGHAx9IXxf0dWJJl0pqkNTQ2Ng4KMFmmnw7dTOzfCaODDAja316ui3bJcCdABHxGFAB1AJImg7cA1wYESt6DoiITPq+CfgFSZPYu0TE9RFRHxH1dXV1g3NBzZ7DYWaWz8SxBJgnaY6kcuAcYHGvMm8CCwEkHUKSOBol1QD/G7giIv6zp7CkMkk9iWUU8DHg+Txew3ZtHV2s37zNicPMil7eEkdEdAKXk4yIeolk9NQLkq6SdEZa7KvA5yU9A/wSuDgiIj3uPcC3ew27HQ08IOlZ4GmSGswN+bqGbKt8V1wzMyCPw3EBIuI+kk7v7G3fzlp+ETihj+O+C3x3F6c9ejBjzNX2ORyucZhZkSt05/iw4edwmJklnDhylGneSmmJmFxVUehQzMwKyokjR5mmViZXVVBW6q/MzIqb/wrmyENxzcwSThw58uQ/M7OEE0cOOrq6WdvS5hqHmRlOHDlZu7GN7vCIKjMzcOLIiedwmJnt4MSRA8/hMDPbwYkjB65xmJnt4MSRg0xTK7Xjy6kYVVroUMzMCs6JIweew2FmtoMTRw4yzZ7DYWbWw4mjH93d4RqHmVkWJ45+rN/SzrbObicOM7OUE0c/dgzFHVvgSMzM9g1OHP3wUFwzs505cfTDk//MzHbmxNGPTHMrlaPLqB4zqtChmJntE5w4+uHbqZuZ7cyJox8eimtmtrO8Jg5JiyS9LGm5pCv62D9T0sOSnpL0rKTTsvZ9Iz3uZUl/mus5B5trHGZmO8tb4pBUClwNnArMB86VNL9XsW8Bd0bEkcA5wDXpsfPT9UOBRcA1kkpzPOeg2djawab2Ttc4zMyy5LPGcQywPCJWRsQ24HbgzF5lAqhKl6uB1enymcDtEdEeEa8By9Pz5XLOQeMRVWZm75bPxDENeCtrfVW6LduVwPmSVgH3AV/u59hczgmApEslNUhqaGxs3KML8BwOM7N3K3Tn+LnATRExHTgNuFXSoMQUEddHRH1E1NfV1e3ROTJNWwHXOMzMspXl8dwZYEbW+vR0W7ZLSPowiIjHJFUAtf0c2985B02muZXyshJqx43O10eYmQ07+axxLAHmSZojqZyks3txrzJvAgsBJB0CVACNablzJI2WNAeYBzyR4zkHTc9Q3JIS5esjzMyGnbzVOCKiU9LlwANAKXBjRLwg6SqgISIWA18FbpD0VyQd5RdHRAAvSLoTeBHoBL4UEV0AfZ0zX9dw6NRqZk4cl6/Tm5kNS0r+To9s9fX10dDQUOgwzMyGFUlLI6K+9/ZCd46bmdkw48RhZmYD4sRhZmYD4sRhZmYD4sRhZmYD4sRhZmYD4sRhZmYD4sRhZmYDUhQTACU1Am/s4eG1wPpBDGewOb694/j2juPbO/t6fLMi4l13iS2KxLE3JDX0NXNyX+H49o7j2zuOb+/s6/HtipuqzMxsQJw4zMxsQJw4+nd9oQPoh+PbO45v7zi+vbOvx9cn93GYmdmAuMZhZmYD4sRhZmYD4sSRkrRI0suSlku6oo/9oyXdke7/L0mzhzC2GZIelvSipBck/bc+ypwsaaOkp9PXt4cqvvTzX5f0XPrZ73pqlhL/lH5/z0o6aghjOyjre3laUoukr/QqM6Tfn6QbJb0t6fmsbRMlPSjp1fR9wi6OvSgt86qki4Ywvn+QtCz997tHUs0ujt3tz0Ie47tSUibr3/C0XRy729/1PMZ3R1Zsr0t6ehfH5v3722sRUfQvksfQrgDmAuXAM8D8XmW+CFyXLp8D3DGE8U0BjkqXK4FX+ojvZODfCvgdvg7U7mb/acD9gIDjgP8q4L/1WpKJTQX7/oCTgKOA57O2/QC4Il2+Avj7Po6bCKxM3yekyxOGKL5TgLJ0+e/7ii+Xn4U8xncl8LUc/v13+7uer/h67f//gG8X6vvb25drHIljgOURsTIitgG3A2f2KnMmcHO6fBewUJKGIriIWBMRT6bLm4CXgGlD8dmD6Ezglkg8DtRImlKAOBYCKyJiT+8kMCgi4lFgQ6/N2T9jNwNn9XHonwIPRsSGiGgCHgQWDUV8EfEfEdGZrj4OTB/sz83VLr6/XOTyu77Xdhdf+nfj08AvB/tzh4oTR2Ia8FbW+ire/Yd5e5n0l2cjMGlIosuSNpEdCfxXH7uPl/SMpPslHTqkgUEA/yFpqaRL+9ify3c8FM5h17+whfz+APaPiDXp8lpg/z7K7Cvf45+R1CD70t/PQj5dnjal3biLpr594fv7ALAuIl7dxf5Cfn85ceIYRiSNB+4GvhIRLb12P0nS/HIE8BPg3iEO78SIOAo4FfiSpJOG+PP7JakcOAP4VR+7C/397SSSNot9cqy8pG8CncBtuyhSqJ+Fa4EDgAXAGpLmoH3Ruey+trHP/y45cSQywIys9enptj7LSCoDqoF3hiS65DNHkSSN2yLi1733R0RLRGxOl+8DRkmqHar4IiKTvr8N3EPSJJAtl+84304FnoyIdb13FPr7S63rab5L39/uo0xBv0dJFwMfA85Lk9u75PCzkBcRsS4iuiKiG7hhF59b6O+vDPgEcMeuyhTq+xsIJ47EEmCepDnp/0rPARb3KrMY6BnB8kngd7v6xRlsaZvovwAvRcT/2kWZyT19LpKOIfm3HZLEJmmcpMqeZZJO1Od7FVsMXJiOrjoO2JjVLDNUdvk/vUJ+f1myf8YuAn7TR5kHgFMkTUibYk5Jt+WdpEXAfwfOiIituyiTy89CvuLL7jP7+C4+N5ff9Xz6MLAsIlb1tbOQ39+AFLp3fl95kYz6eYVkxMU3021XkfySAFSQNHEsB54A5g5hbCeSNFs8Czydvk4DLgMuS8tcDrxAMkrkceD9Qxjf3PRzn0lj6Pn+suMTcHX6/T4H1A/xv+84kkRQnbWtYN8fSQJbA3SQtLNfQtJn9hDwKvBbYGJath74Wdaxf5b+HC4HPjeE8S0n6R/o+RnsGWU4Fbhvdz8LQxTfrenP1rMkyWBK7/jS9Xf9rg9FfOn2m3p+5rLKDvn3t7cv33LEzMwGxE1VZmY2IE4cZmY2IE4cZmY2IE4cZmY2IE4cZmY2IE4cZvu49M69/1boOMx6OHGYmdmAOHGYDRJJ50t6In2Owk8llUraLOlHSp6j8pCkurTsAkmPZz3bYkK6/T2SfpvebPFJSQekpx8v6a70eRi3DdWdmc364sRhNggkHQJ8BjghIhYAXcB5JDPWGyLiUOD3wHfSQ24Bvh4R7yWZ7dyz/Tbg6khutvh+ktnHkNwR+SvAfJLZxSfk/aLMdqGs0AGYjRALgaOBJWllYAzJTQq72XFDu38Ffi2pGqiJiN+n228GfpXeo2haRNwDEBFtAOn5noj0/kbpk+NmA3/M/2WZvZsTh9ngEHBzRHxjp43S/+hVbk/v8dOetdyFf3etgNxUZTY4HgI+KWk/2P788Fkkv2OfTMt8FvhjRGwEmiR9IN1+AfD7SJ7uuErSWek5RksaO6RXYZYD/6/FbBBExIuSvkXy5LYSkruifgnYAhyT7nubpB8EktumX5cmhpXA59LtFwA/lXRVeo5PDeFlmOXEd8c1yyNJmyNifKHjMBtMbqoyM7MBcY3DzMwGxDUOMzMbECcOMzMbECcOMzMbECcOMzMbECcOMzMbkP8LnQob5zlDl7oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQYPGdGhkFMt"
      },
      "source": [
        "#### Step 4: Testing the Model\n",
        "Our results on the training data looks promising, but we want to know whether our model performs well on unknown data. For this, we compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lznc7jmUwFbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e134ffe1-db63-48c6-e625-8b99bac24848"
      },
      "source": [
        "test_loss = 0.0\n",
        "test_counts = 0\n",
        "\n",
        "# Setting model to evaluation mode, no parameters will change\n",
        "model.eval()\n",
        "\n",
        "for images, labels in test_dataloader:\n",
        "\n",
        "    # Moving to GPU if available\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Calculate Output\n",
        "    output = model(images)\n",
        "\n",
        "    # Calculate Loss\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    # Saving loss\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    # Get Predictions\n",
        "    test_preds = get_preds_from_logits(output)\n",
        "\n",
        "    # Saving number of right predictions for accuracy\n",
        "    test_counts += test_preds.eq(labels).sum().item()\n",
        "\n",
        "# Calculating test accuracy\n",
        "test_acc = test_counts/len(test_data)\n",
        "print('Test Loss: {:.6f} \\tTest Accuracy: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 12.266432 \tTest Accuracy: 95.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSVkEYFxQ7RU"
      },
      "source": [
        "Let's take a look at a few sample that the network classified incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19LudcYkQ6ZF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f87b8e63-e5dc-4bce-8f6f-50f6b0413399"
      },
      "source": [
        "test_images = test_data.data.to(device)/255\n",
        "predictions = get_preds_from_logits(model(test_images))\n",
        "\n",
        "test_labels = test_data.targets.to(device)\n",
        "\n",
        "correct_bools = test_labels.eq(predictions)\n",
        "misclassified_indices = []\n",
        "for i in range(len(correct_bools)):\n",
        "    if correct_bools[i] == False:\n",
        "        misclassified_indices.append(i)\n",
        "\n",
        "def plot_misclassified(imgs, labels, preds, misclassified_indices, n=5):\n",
        "  plt.figure(figsize=(10,3))\n",
        "  for i, idx in enumerate(misclassified_indices[:n]):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(imgs[idx].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(f'True: {labels[idx]}, Pred: {preds[idx]}')\n",
        "\n",
        "plot_misclassified(test_images.cpu().numpy(), test_labels.cpu().numpy(), predictions.cpu().numpy(), misclassified_indices)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC5hu4y2ZtXr"
      },
      "source": [
        "We can see that some of these digits are hard to recognize, even for a human!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUeSBG87wLVo"
      },
      "source": [
        "Often times, the accuracy on the test dataset is a little less than the accuracy on the training dataset. Small differences are ok, but we don't want the test results to differ significantly from the training results--this suggests the model is overfitting/underfitting. \n",
        "\n",
        "**Challenge:** Do you think the difference between the training accuracy and the testing accuracy is significant? Is the model overfitting? Is it underfitting? Are the misclassify images justifiably misclassified (i.e., does it make sense that the model misclassified them)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nssakhiv2OfI"
      },
      "source": [
        "## Recap\n",
        "You made it! We covered a lot of material in this lesson. Don't worry if it doesn't all make sense yet. The concepts will become more intuitive as you practice building, training, and testing your own neural network models. \n",
        "\n",
        "Let's summarize what we learned about neural networks:\n",
        "- Neural Networks are popular and successful machine learning models that can learn effective representations from data (i.e., images, text, sound). They can and *classification* tasks (see [Part 2](#-Part-2:-Classification-of-MNIST-Digits-with-Convolutional-Neural-Networks)), and also to generate images, text, videos, and sound.  \n",
        "- Special libraries like Tensorflow and Pytorch enable us to build neural networks in Python and train them on accelerated hardware like GPUs and TPUs. \n",
        "- Several steps are involved in making an effective neural network: \n",
        "  1. Loading the dataset\n",
        "  2. Building the model--stacking several layers and configuring the loss function and optimizer.\n",
        "  3. Training the model--fitting the model on the training data.\n",
        "  4. Evaluating/Testing the model--evaluating the model on the testing data. \n",
        "- Once a model is trained, it can be used to make predictions on outside data (see [Part 2, Step 5](#-Step-5:-Make-predictions-on-outside-data)).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4s3YeuF1NoV"
      },
      "source": [
        "#### Acknowlegements\n",
        "- [MIT Deep Learning Basics](https://www.youtube.com/watch?v=O5xeyoRL95U&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)\n",
        "- [Dive into Deep Learning](https://d2l.ai/index.html)"
      ]
    }
  ]
}