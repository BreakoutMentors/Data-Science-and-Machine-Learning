{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge 1 - neural networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-bugs-fixes/machine_learning/lesson%203%20-%20Neural%20Networks/challenges/neural_networks_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5tjTDNmgWup"
      },
      "source": [
        "# Feed Forward Neural Network with Fashion-MNIST\n",
        "The goal in this challenge is to build a deep feed forward neural network (like the network we made in the previous example) to recognize 10 different fashion classes from the Fashion-MNIST image dataset. The classes are: t-shirt/top, trouser, pullover, dress, coat, sandal, shirt, sneaker, bag, ankle boot. Also, the classes are mutually exclusive. Use PyTorch to build, train, and evaluate the model.\n",
        "\n",
        "Challenges:\n",
        "1. Load the data into Dataloaders\n",
        "2. Build the model.\n",
        "3. Train the model.\n",
        "4. Evaluate the model.\n",
        "5. Draw conclusions. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foMBp5MTfHNP"
      },
      "source": [
        "# import the libraries we need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pytorch and torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wV0KajHi32V"
      },
      "source": [
        "We load the Fashion-MNIST dataset below using the `torchvision.datasets` from torchvision. The dataset contains 60k $28x28$ grayscale images of 10 fashion categories, along with a test set of 10k images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrJDHQGbii4_",
        "outputId": "70f04ab1-cc77-465f-fe78-944d59ac79cb"
      },
      "source": [
        "\n",
        "# Downloading the data\n",
        "root = '/content/FashionMNIST'\n",
        "training_data = torchvision.datasets.FashionMNIST(root, \n",
        "                                                  train=True, \n",
        "                                                  download=True,\n",
        "                                                  transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.FashionMNIST(root, \n",
        "                                              train=False, \n",
        "                                              download=True,\n",
        "                                              transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "print(f\"training set shape: {training_data.data.shape}\")\n",
        "print(f\"test set shape: {test_data.data.shape}\")\n",
        "\n",
        "print(f'dtypes of training and test set tensors: {training_data.data.dtype}, {test_data.data.dtype}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set shape: torch.Size([60000, 28, 28])\n",
            "test set shape: torch.Size([10000, 28, 28])\n",
            "dtypes of training and test set tensors: torch.uint8, torch.uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci-Ml4fkjx6w"
      },
      "source": [
        "We see that PyTorch Datasets takes care of most of the processing we need to do. We see that there are 60k training images and 10k test images, so 70k total images. We also see that the images are tensors of shape ($28 \\times 28$) with integers of type uint8.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-X1Z9dTANK"
      },
      "source": [
        "# 1. Load the data into Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAjCB4CrggwB"
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5bO4KyxSoy3"
      },
      "source": [
        "# 2. Build your model\n",
        "Build a model to model the relationship between the features $x$ (multiple features) and labels $y$.\n",
        "\n",
        "Hints:\n",
        "- use the `nn.Linear` class to define your linear model layer\n",
        "- use the `nn.ReLU` class as an activation function between each layer except the last layer\n",
        "- define your loss function with the [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) class from PyTorch, which uses `nn.Softmax` activation function built-in so no need to use it in the model.\n",
        "- configure the optimization algorithm with stochastic gradient descent\n",
        "- track the accuracy metric  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgNpVNPylBo0"
      },
      "source": [
        "# your code here\n",
        "class Neural_Network(nn.Module):\n",
        "    # Contructor\n",
        "    def __init__(self, num_classes):\n",
        "        # TODO\n",
        "    \n",
        "    # Forward Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Need to flatten each image in the batch\n",
        "        x = x.flatten(start_dim=1)\n",
        "        \n",
        "        # TODO\n",
        "        return x\n",
        "\n",
        "num_classes = #\n",
        "model = Neural_Network(num_classes)\n",
        "\n",
        "loss_fn = #\n",
        "optimizer = #\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxXkdszdaWOx"
      },
      "source": [
        "# 3. Train your model\n",
        "Now that you have a model, it's time to train it. Train your model for 100 epochs (i.e., iterations), and record the training and validation metrics in lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7ixliHPbBOh"
      },
      "source": [
        "# your code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jIPMBcCbQHh"
      },
      "source": [
        "Visualize the accuracy metric over the training process. Hint: create a line chart with the epoch (x) and the accuracy (y).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnAzMXGIcID_"
      },
      "source": [
        "# your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JYygMTpbJ7y"
      },
      "source": [
        "# 4. Evaluate the model\n",
        "Now that the model is trained, it's time to evaluate it using the test dataset, which you did not use when training the model. This gives you a sense of how well the model predicts unseen data, which is the case when you use it in the real world. Make sure to evaluate the model and visualize it's predictions against the true values.\n",
        "\n",
        "Hints:\n",
        "\n",
        "- Calculate test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz5dKGh2d38y"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN1XYgl-d-be"
      },
      "source": [
        "# 5. Draw conclusions\n",
        "Write up your conclusions about the model. Report the goal, the model design, and the results. Make sure to contextualize the model results as best you can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocjwpN6aesnH"
      },
      "source": [
        ""
      ]
    }
  ]
}