{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning Challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPF/xq0VViZDv2ErV2bPLg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-transfer-learning/machine_learning/lesson%204%20-%20ML%20Apps/Gradio/Finetuning_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPYw8IDDEFxZ"
      },
      "source": [
        "> Note: Always open in Colab for the best learning experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rohZEZbrXyRU"
      },
      "source": [
        "# Challenge: Finetuning your own model!\n",
        "\n",
        "You just saw our lesson of using the concept of Transfer Learning that uses pretrained models to easily finetune them for your purposes. In this challenge, you will choose an image dataset and a pretrained model to then finetune. After training the fully-connected layers, save your model's parameters and download the file, so you can use your model in another colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCQW-vdoRv2h"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUXexeXkafMh"
      },
      "source": [
        "# Find a dataset and download it\n",
        "\n",
        "Find an [Image Dataset on Kaggle](https://www.kaggle.com/datasets?tags=13207-Computer+Vision) and download it directly to this colab notebook. Below is the code needed to upload your `kaggle.json` API key to download the data. To download the dataset, you need to get the API command which can be found by clicking on the â‹® to the right of `New Notebook` button.\n",
        "\n",
        "![Kaggle Help](https://github.com/BreakoutMentors/Data-Science-and-Machine-Learning/blob/adam-transfer-learning/machine_learning/lesson%204%20-%20ML%20Apps/images/Kaggle_Example.png?raw=true)\n",
        "\n",
        "Place the API command into the code below and then unzip any zip files to get the dataset from within."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGgKhWGyXrMS"
      },
      "source": [
        "from google.colab import files\n",
        "from IPython.utils import io\n",
        "import os\n",
        "files.upload()\n",
        "os.system(\"mkdir -p ~/.kaggle\")\n",
        "os.system(\"cp kaggle.json ~/.kaggle/\")\n",
        "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
        "# Place API command below to download your dataset\n",
        "!#API Command\n",
        "\n",
        "# Use this code below to unzip any zip files contained in your dataset\n",
        "with io.capture_output() as captured:\n",
        "    !unzip # Place zip file name here\n",
        "    !rm # Place zip file name here to delete it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJxIfua_PVWm"
      },
      "source": [
        "# Loading Data and Image Processing\n",
        "\n",
        "All the pretrained CNN models take images as input with size 224x224, so please make sure your image transformations end with that image size. I have included the normalization step for you. [Click here for the list of transformations.](https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-and-torch-tensor)\n",
        "\n",
        "Also, load in your dataset using the transforms, it is likely to use [`ImageFolder`](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder) dataset class to load in your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvPAxqinX4xP"
      },
      "source": [
        "# ImageNet means and stds to normalize images in entire dataset\n",
        "means = (0.485, 0.456, 0.406)\n",
        "stds = (0.229, 0.224, 0.225)\n",
        "\n",
        "ImageNet_Normalization = transforms.Normalize(means, stds)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            # TODO\n",
        "            ImageNet_Normalization\n",
        "])\n",
        "\n",
        "# Load Dataset\n",
        "dataset = #TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0opCq0xuakJF"
      },
      "source": [
        "# Split the data\n",
        "\n",
        "Here you will create your train, test, and validation sets using [torch.utils.data.random_split](https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split). Then after splitting the data, load the data in a dataloader with your desired batch_size using [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.DataLoader)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iJJkRyoaemG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQtb4n8Ybm2T"
      },
      "source": [
        "# Loading Pretrained Model and Freezing Parameters\n",
        "\n",
        "Load a pretrained model and freeze the parameters, here is a list of [pretrained models](https://pytorch.org/vision/stable/models.html) you can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3SmsLwzbmDb"
      },
      "source": [
        "model = #TODO\n",
        "\n",
        "# Freeze Parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnugRGt9cMO1"
      },
      "source": [
        "# Finetuning the Model\n",
        "\n",
        "Find the Fully-Connected Layer of your model and use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) to replace that layer with your own for your dataset. Please use the lesson as a guide for this if you are confused."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqJoIFmbqYtm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msD_q-qUqZPQ"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "After changing the Fully-Connected Layer, please save this model so you can load it in another colab notebook to run a Gradio application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc9ihbfEqw1_"
      },
      "source": [
        "# Moving model to GPU if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "# Defining Optimizer\n",
        "optimizer = # TODO\n",
        "\n",
        "# Defining Loss Function\n",
        "criterion = # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otOlocAoq0xo"
      },
      "source": [
        "# Training the Model Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFAbWgZ8q5zC"
      },
      "source": [
        "# Plotting Training and Validation Losses\n",
        "\n",
        "Plot your losses to view if the model converged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4F1bBQRq5FW"
      },
      "source": [
        "# Plot training losses here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA9mryOTrqam"
      },
      "source": [
        "# Plot testing losses here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws8SLhjurr7c"
      },
      "source": [
        "# Evaluating the Model\n",
        "\n",
        "Now use your model to calculate the test loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4fdyj0qxly9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RXBYRBxm6n"
      },
      "source": [
        "# Download the Model\n",
        "\n",
        "You did all the hard work! Now after you are done training and evaluating your finetuned model, you can download it to your computer to then upload it into the next challenge where you make a Gradio Image Classification app for your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbVm7upryGK-"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "file_path = # TODO\n",
        "\n",
        "files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}